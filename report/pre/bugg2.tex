\documentclass[a4paper,12pt]{jsarticle}  % 日本語論文向け（uplatex推奨）

% 基本エンコーディング・フォント
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

% 日本語対応（uplatex + dvipdfmx用）
\usepackage{japanese}
\usepackage[dvipdfmx]{pxjahyper}

% ページ設定
\usepackage{geometry}
\geometry{a4paper, margin=1in}

% 数学・数式
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}

% 表・列制御
\usepackage{booktabs}
\usepackage{array}
\usepackage{longtable}
\usepackage{multirow}
\usepackage{colortbl}

% 図・キャプション
\usepackage[dvipdfmx]{graphicx}
\usepackage{caption}
\usepackage{subcaption}

% アルゴリズム
\usepackage{algorithm}
\usepackage{algorithmic}

% ハイパーリンク
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=red,
    urlcolor=green
}

% コードハイライト
\usepackage{listings}
\lstset{
  language=Python,
  basicstyle=\small\ttfamily,
  breaklines=true,
  columns=fixed,
  keepspaces=true,
  showstringspaces=false,
  frame=single,
  numbers=left,
  numberstyle=\tiny,
  captionpos=b
}

\begin{document}

% ===== 表紙の設定 =====
\title{\vspace{5cm}\Huge \textbf{アジャイルワーク2 \\実験計画書}}
\author{\Large 24G1089 武本 龍}
\date{2025年 10月24日(金)} % 日付は非表示

\begin{document}

% ===== 表紙 =====
\maketitle

\clearpage
\section{実験の概要および目的}
以下に，本実験の基本的な概要を図\ref{fig:実験概要}に示す．
\begin{figure}[h]
    \centering
    \includegraphics[width=16cm]{実験概要.jpg}
    \caption{基本的な実験概要図}
    \label{fig:実験概要}
\end{figure}


本実験では，図\ref{fig:実験概要}に示すように，Arduino Uno R4 WiFiを用いてカラーセンサーを構築し，
授業内で配布された3$\times$3のカラーチャートをセンサで測定する．
主な目的は，測定したカラーチャートと基準のカラーチャートの平均二乗誤差（MSE）を小さくすること，
読み取り時間をできるだけ短くすること，の2点である．
これらの目的を達成するため，特にMSEの低減にニューラルネットワークによる学習を活用し，
ニューラルネットワークの隠れ層で用いるデータの圧縮手法を導入することで，ソフトウェアの品質を向上させることを目指す．
以下では，読み込み品質の測定方法，およびソフトウェア的な改善手法について詳述する．
\clearpage
\subsection{平均二乗誤差（MSE）とは}
MSEは，2枚の画像の対応するピクセル位置における輝度差の2乗の平均値で定義され，以下の式で表される．
\begin{equation}
\text{MSE} = \frac{1}{m \times n} \sum_{i=1}^{m} \sum_{j=1}^{n} \left( I(i,j) - K(i,j) \right)^2
\end{equation}

ここで，$I$と$K$は2枚の画像，$m \times n$は画像サイズを表す．
本実験ではRGB画像を扱うため，各ピクセルについてR, G, Bチャネルの差の2乗を加算し，3で割った値をMSEとして計算する．
また，ソフトウェアの実装例は以下の通りである．
\begin{equation}
\text{mse} = \frac{ r_{\text{diff}} \times r_{\text{diff}} + g_{\text{diff}} \times g_{\text{diff}} + b_{\text{diff}} \times b_{\text{diff}} }{3}
\end{equation}

\subsection{読み込み品質の測定方法}
読み込み品質の評価は，以下の手順で実施する．
\begin{enumerate}
    \item \textbf{2つのボタンプログラムによるカラーチャートの読み取り}\\
    事前に黒と白のサンプルを測定し，最小値・最大値を基準として読み込み精度をキャリブレーションする．これにより，センサの感度を調整し，安定したRGB値を取得する．
    \item \textbf{PPM画像出力}\\
    授業で配布された3$\times$3のカラーチャートをセンサで読み取り，取得したRGBデータをPPM形式の画像ファイルとして出力する．この画像は，後続の品質評価に用いる．
    \item \textbf{平均二乗誤差（MSE）の計算}\\
    出力したPPM画像と基準画像の品質を，専用のMSE測定ソフトウェアで評価する．
\end{enumerate}
\clearpage
\section{実験の目的}
以下に実験の目的を示す．
\subsection{読み込み品質のソフトウェア的改良(ニューラルネットワークを用いた学習)}
サンプル画像と測定画像のMSEを最小限に抑えるために，ニューラルネットワークを用いた学習方法およびニューラルネットワークの圧縮方法を以下に示す．
\subsubsection{ニューラルネットワークの基本構造}
まず，ニューラルネットワークの基本構造について説明する．
ニューラルネットワークの最小単位は「ユニット」と呼ばれ，複数の入力を受け取り，1つの出力を計算する．
各ユニットは，入力値にそれぞれ異なる重み（weight: $w_1, w_2, w_3, \dots$）を掛けて加算し，さらにバイアス（$b$）を加えた総入力$u$を計算する．
具体的には，以下の式で表される．
\begin{equation}
u = w_1 x_1 + w_2 x_2 + w_3 x_3 + \dots + b
\end{equation}
この総入力$u$は，活性化関数$f$に入力され，出力$z = f(u)$が生成される．

\subsubsection{順伝搬型ネットワーク}
次に，ニューラルネットワークの層構造について考える．
層は$l = 1, 2, 3, \dots$で表され，$l = 1$を入力層，$l = 2$を中間層，$l = 3$を出力層と呼ぶ．
各層の計算は以下のようになる．
例えば，層$l=2$では，

\begin{equation}
u^{(2)} = W^{(2)} x^{(2)} + b^{(2)}, \quad z^{(2)} = f(u^{(2)})
\end{equation}
また，層$l=3$では，
\begin{equation}
u^{(3)} = W^{(3)} x^{(3)} + b^{(3)}, \quad z^{(3)} = f(u^{(3)})
\end{equation}
これを任意の層数$L$に一般化すると，層$l+1$のユニットの出力$z^{(l+1)}$は，1つ前の層$l$の出力$z^{(l)}$を用いて以下のように計算される．
\begin{equation}
u^{(l+1)} = W^{(l+1)} x^{(l)} + b^{(l+1)}, \quad z^{(l+1)} = f(u^{(l+1)})
\end{equation}

ここで，入力層の出力は$z^{(1)} = x$とし，$l = 1, 2, 3, \dots, L-1$の順に計算を進めることで，各層の出力$z^{(2)}, z^{(3)}, \dots, z^{(L)}$を順次決定できる．

入力$x$を受け取り，各層の計算を順番に実行して最終的に出力$y = z^{(L)}$を得るネットワークを，順伝搬型ネットワークと呼ぶ．
この入力$x$から出力$y$を得る計算は，各層間の結合の重みパラメータ$W^{(l)}$（$l = 2, \dots, L$）およびユニットのバイアスパラメータ$b^{(l)}$（$l = 2, \dots, L$）によって決定される．
これらすべてのパラメータをまとめて表現するため，$W^{(2)}, \dots, W^{(L)}, b^{(2)}, \dots, b^{(L)}$を成分とするベクトル$w$を定義し，出力は$y(x; w)$と表記する．

順伝搬型ネットワークは，1つの関数$y(x; w)$を表現し，この関数の形状はネットワークのパラメータ$w$に依存して変化する．

\clearpage
\subsubsection{使用するニューラルネットワーク}
本実験では，全結合型の4層ニューラルネットワークを使用する．
入力層はRGBの3次元，2つの隠れ層はそれぞれ40次元（40個のニューロンが全結合），
出力層はRGBの3次元である．
各ニューロンで行われる推論演算は，以下の通りである
入力$x_1 \times w_1 + x_2 \times w_2 + \dots + x_{n-1} \times w_{n-1} + b$ を計算し，
ReLU活性化関数を通した値を次の層へ出力する．
ここで，$w_i$は重み，$b$はバイアスを表す．
モデルはPyTorchを用いて定義・訓練し，L1正則化を導入することで重みを疎化させる．
訓練後，重みとバイアスをC++配列としてエクスポートし，Arduino上で推論を実行する．

\subsubsection{なぜ隠れ層の圧縮が必要なのか}
Arduino Uno R4 WiFiのようなマイクロコントローラーでは，メモリ容量が限定的である
（SRAM: 約32KB，Flash: 256KB）ため，ニューラルネットワークの隠れ層次元を増大させると，
重み・バイアスデータの保存および推論演算に必要なメモリが不足する可能性がある．

例えば，隠れ層次元を40から70以上に拡大した場合，パラメータ総数が急増
（例: 40次元で約1,923パラメータ，70次元で約3,000パラメータ以上）し，
float32形式で10KBを超えると動作不能となる．
この制約を克服するため，重みデータの圧縮が不可欠である．

主な手法として，(1) 量子化（float32 → int8でメモリ1/4化），(2) プルーニング（L1正則化により0に近い重みを0化し，非ゼロ率を低減），
(3) 疎行列表現（CSR形式で非ゼロ要素のみ保存）が有効である．
これにより，次元を100-200まで拡張しつつ，MSE誤差をできるだけ抑え，画像復元の品質を向上させることができる．
最終的に，読み取り時間の短縮（演算量低減）とMSEの低減を両立させる．
\clearpage
\section{実験理論}
以下に実験理論を示す．

\subsection{圧縮方法1:量子化とは}
量子化とは，ニューラルネットワークの重みや活性化値を高精度の浮動小数点数（例: 32-bit float）から低精度の整数（例: 8-bit uint8）
へ変換する手法である．これにより，整数演算のみで推論が可能となり，組み込みデバイスのメモリ使用量と計算コストを大幅に削減する．
論文では，アフィン変換スキーム$r = S(q - Z)$（$S$: scale, $Z$: zero-point）を提案し，
畳み込み層の入力，出力，重みを8-bit整数で表現し，蓄積器を32-bit整数で扱うことで，浮動小数点演算を回避した\cite{jacob2018quantization}．
本実験では，このスキームをRGB画像復元ニューラルネットワーク（入力3$\to$隠れ40$\to$40$\to$出力3）に適用し，重み・
活性化をuint8へ量子化，バイアスをint32で保持する予定である．

量子化の主なメリットとして，メモリ使用量の約4倍削減と，整数演算（uint8 $\times$ uint8 $\to$ int32蓄積）による
計算高速化が挙げられる．これにより，Arduino Uno R4 WiFiのようなリソース制約デバイスでの効率的なデプロイが可能となり，
画像復元タスクのリアルタイム処理を促進する．

一方で，デメリットとしては，小規模モデルにおける精度低下のリスクと実装の複雑さが指摘される．特に，チャネル間の範囲差
が大きい場合に相対誤差が増大しやすく，スケーリングやゼロポイントのオフライン事前計算，Arduino上での32-bit整数蓄積
および固定小数点乗算の処理が追加の負担となる可能性がある．

\subsection{圧縮方法2:プルーニングとは}
プルーニングとは，ニューラルネットワークの重みを閾値以下で0にし，不要な接続を削除して疎行列化する手法である．
これにより，過剰パラメータを削減し，メモリ・計算コストを低減できる．
論文では，3ステッププロセス（初期訓練で重要接続学習 → 低重み接続削除 → 残存接続再訓練）を提案し，複数回適用することで
畳み込みニューラルネットワークモデルであるAlexNetを精度損失なしに9倍圧縮している\cite{han2015deep}．

プルーニングの主なメリットとして，
重みの非ゼロ要素を8-11％に減らすことでメモリを大幅に節約し，疎行列演算により不要部分をスキップして計算量を30-50％低減できる点が挙げられる．
これにより，Arduino Uno R4 WiFiのような組み込みデバイスでのリアルタイム画像復元が効率化される．

一方で，デメリットとしては，再訓練なしでは精度が急落するリスクや，疎表現のオーバーヘッド（非ゼロ位置のインデックス保存でメモリが15.6％
増加し，疎演算が非効率となる可能性），さらに複数回のイテレーションが必要な訓練コスト増が指摘される．

\clearpage
\subsection{圧縮方法3: COO（COOrdinate）形式}
COO（Coordinate List）形式は，疎行列を非ゼロ要素の座標（行番号，列番号）と値のリスト（triples: (row, col, value)）として表現するシンプルな圧縮手法である．
授業のヒント通り，非ゼロ成分の値・列番号・行番号を列挙し，L1正則化により重みが0に近い成分が多くなる本研究のニューラルネットワークでは，
0に近い成分（例: ±0.01未満）を0としてプルーニングした後，非ゼロ要素のみをリスト化することで，重み行列（例: 40×40）を効率的に保存する．
重複エントリ（同一位置の複数値）は加算して扱うことが可能で，中間表現としてCSR形式への変換に適している．

COO形式の主なメリットとして，非ゼロ要素を直接リスト化するため構築・変換が容易で，メモリ削減効果が高い点が挙げられる．特に，非ゼロ率が50％の場合，
データ量を約1/2に抑えられるため，Arduino Uno R4 WiFiのメモリ制約下で軽量な重み保存が可能となる．

一方で，デメリットとしては，アクセス効率の低さが指摘される．行列-ベクトル乗算時に全非ゼロ要素を走査する必要があり，
CSR形式に比べて高速化しにくいため，推論時間の最適化が限定的となる可能性がある．

\subsection{圧縮方法4: CRS/CSR（Compressed Row Storage/Compressed Sparse Row）形式とは}
CRS/CSR（Compressed Sparse Row）形式は，疎行列を値配列（data），列インデックス配列（indices），
行ポインタ配列（indptr）で表現する行指向の圧縮手法である．非ゼロ要素を列順にソートし，
各行の非ゼロ開始位置をindptrで記録するため，行アクセスが高速である．
授業の参考通り，L1正則化で生じた0成分をプルーニング後，40×40重み行列をCSRで保存し，Arduinoのメモリ（SRAM 32KB）制約をクリアする．

CSR形式の主なメリットとして，行列-ベクトル乗算がO(NNZ)で効率的である点が挙げられ，推論速度がCOO形式の1.5-2倍向上する．
また，インデックス共有による優れた圧縮率（非ゼロ率30％でデータ量1/10，40次元モデルで1KB未満可能）と，Arduino適合性（固定サイズ配列（indptr: 41要素）で
実装しやすく，Flash保存（PROGMEM）でRAM節約，複数層対応）も大きな利点である．
これにより，メモリ制約下での高次元隠れ層の実現が容易となる．

一方で，デメリットとしては，列アクセスの遅さ（列方向スキャンが必要で，転置行列使用時非効率，CNNのような畳み込み層には不向き），
変換コスト（COOからCSRへのソートが必要（SciPyのtocsr()），動的NNZ変更で再構築），およびデッドコードリスク（完全0行が発生
するとindptrが無駄を生むが，プルーニングで稀）が指摘される．これらを考慮し，本実験では全結合層中心に適用する．

\clearpage
\subsection{重み圧縮手法の比較}
以下に，量子化，プルーニング+COO，CSRの手法を比較した表を示す．本研究の文脈（Arduino上RGB復元ニューラルネットワーク，L1疎化）を考慮し，
定性的基準で評価する．この比較から，CSRの行アクセス効率と圧縮率の高さから基盤採用を決定し，
追加で量子化を組み合わせることでメモリ/速度の両立を図る．

\begin{table}[h]
\centering
\small
\caption{重み圧縮手法の比較（CSR基盤+量子化追加で最適化）}
\begin{tabular}{l|c|c|c}
\hline
\textbf{手法} & \textbf{メモリ削減} & \textbf{計算効率} & \textbf{精度影響} \\
\hline
量子化 (int8) & 高 (4倍) & 高 (2-3× latency低減) & 低 ($<$2-4％) \\
\hline
プルーニング+COO & 中-高 (2-5倍) & 中 (全走査) & 低 ($<$3％) \\
\hline
プルーニング+CSR & 高 (9-13倍) & 高 (FLOP 3-5倍低減) & 低 (0％) \\
\hline
CSR + 量子化 & 最高 (36-52倍) & 最高 (50％時間短縮) & 低 ($<$5％) \\
\hline
\end{tabular}
\label{tab:compression_compare}
\end{table}

数値は論文のベンチマークを基にしたものであり、Table 4.1-4.3(4倍メモリ削減，精度低下$<$2-4％，COCOで50％時間短縮)\cite{jacob2018quantization} ，
Table 1/4/5 (9-13×圧縮，非ゼロ率7.5-11％，FLOP 3-5×低減，精度損失0％)\cite{han2015deep} ．
これらを小規模ニューラルネットワークにスケールダウンした推定値である．
次節では，CSR+量子化の実装を詳細に記述し，MSE検証で確認する．

\clearpage
\section{実験方法}
本節では，重み圧縮手法としてCSR（Compressed Sparse Row）形式を第一優先とし，次にCSR圧縮モデルに対する量子化を適用してさらなる圧縮を検討する．
実験は，隠れ層次元40から開始し，「非圧縮」「CSR圧縮」「CSR+量子化」のMSEを比較して品質影響を評価する．
全体の流れは，PyTorchによる訓練・圧縮生成，Arduino Uno R4 WiFiへのデプロイ，センサーデータによる推論・MSE計算である．
これにより，L1正則化による疎化を活かし，メモリ制約下での画像復元品質向上と読み取り時間短縮を実現する．目標は，MSE相対誤差を可能な限り抑えつつ，
次元を100-200へ拡張可能とすることである．

\subsection{全体実験フロー}
実験の全体フローは以下の通りである．
\begin{enumerate}
\item \textbf{データ準備:} 授業配布の3$\times$3カラーチャートRGB値を訓練データ（9サンプル，ノイズ付加）とし，基準画像を評価用とし，
カラーセンサーで実測データを収集する．
\item \textbf{モデル訓練:} PyTorchでColorNet（入力3$\to$隠れ$d_1\to d_2\to$出力3，$d_1=d_2=40$初期）を訓練する
（epochs=50,000，Adam lr=0.01，$\lambda_{L1}=10^{-6}$）．L1正則化で非ゼロ率50\%以下を目指す．
\item \textbf{圧縮生成:} プルーニング（閾値0.01）後，CSR変換（SciPy）し，\texttt{model\_parameters.h}をエクスポートする．
\item \textbf{Arduinoデプロイ:} RGB入力$\to$推論$\to$PPM出力する．
\item \textbf{評価基準:} MSE/PSNR（PCソフト）とレイテンシ（millis()）を測定し，相対誤差を可能な限り抑え，次元拡張を増加させる（40$\to$60$\to$100$\to$200）．
\end{enumerate}

また，結果は表にまとめ，圧縮率・誤差・時間のトレードオフを分析する．
\clearpage
\subsection{CSR形式の実験方法及び評価方法}
CSR形式を優先的に採用する理由は，L1正則化による重みの疎化を最大限に活かした高い圧縮率（3-10倍）と，
行指向のmatvec演算による推論高速化にある．これにより，Arduinoのメモリ制約をクリアしつつ，画像復元のリアルタイム性を確保できる．
以下に，具体的な手順を示す．
\begin{enumerate}
    \item \textbf{モデル訓練（Python）:}PyTorchを用いてColorNetを訓練し，L1正則化により重みを疎化（非ゼロ率$<$50％）する．
    活性化関数としてReLU関数を採用し，全体の表現力を維持する．
    \item \textbf{プルーニングとCSR生成:}  閾値0.01で重みを0化する（\texttt{torch.abs(w) $<$ 0.01}）．
    SciPyの\texttt{sparse.csr\_matrix}でCSR形式に変換する（data, indices, indptrをNumPy配列として出力）．
    これをC配列形式で\texttt{model\_parameters.h}にエクスポートする．
    \item \textbf{Arduino実装:}  CSR matvec関数を実装し，カラーセンサーからのRGB入力をCSR forwardパス（ReLU統合）で処理し，出力RGBをPPM形式で生成する．
    \item \textbf{評価:}  生成したPPM画像と基準画像のMSE算出し，非圧縮モデルとの相対誤差を算出する．
    40次元での確認後，次元を増加させて再訓練・再評価を行い，拡張性を検証する．
\end{enumerate}
この一連のプロセスにより，CSR形式の有効性を定量的に確認し，さらなる量子化との組み合わせへの基盤を築く．

\subsection{CSR+量子化による追加圧縮の実験方法及び評価方法}
CSR形式を適用した後，8-bit量子化（uint8重み/活性化，int32バイアス）を組み合わせることで，メモリをさらに約4倍削減する．
論文のスキーム（$r = S(q - Z)$）を基に，CSRの疎性を維持しつつ200次元対応を目指す\cite{jacob2018quantization} ．
量子化感知訓練（QAT）により精度を保ち，全体の効率を向上させる．以下に，手順を示す．

\begin{enumerate}
    \item \textbf{量子化感知訓練（Python）:}
    訓練グラフにfake quantizationを挿入する（$\hat{r} = \round(\clamp(r; a, b) / S) \cdot S + Z$，$S=(b-a)/255$，範囲$[a,b]$をEMAで学習）．
    初期50kステップで量子化を無効化し，ReLU6活性化で範囲を安定化させる．
    \item \textbf{量子化実行（Python）:}  
    CSRデータ（float32）をuint8へ変換する（$q = \round((r - Z)/S)$，scale=$max(|r|)/127$）．
    バイアスは$S_w S_a$スケールでint32とし，multiplier $M = S_w S_a / S_o$をfixed-pointでオフライン計算する．
    indptr/indicesをint16で圧縮し，\texttt{model\_parameters.h}を更新する．
    \item \textbf{Arduino実装:}  
    matvec内でuint8乗算+int32蓄積+スケーリングを実装する．ReLUをint8 clamp(0,127)に対応させ，EloquentTinyMLライブラリを活用してint8演算を効率化させる．
    \item \textbf{評価:}  
    CSR単独 vs CSR+量子化のMSEを比較する．また，200次元への拡張を検証する．
\end{enumerate}
この一連の実験により，CSR基盤上で量子化を積層し，MSE低減と時間短縮を両立させる．
プルーニングとの相乗効果で，非ゼロ率の低減と整数演算の効率を定量的に確認する．




\clearpage
\begin{thebibliography}{9}
\bibitem{jacob2018quantization} B. Jacob et al., ``Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference,'' CVPR, 2018.
\bibitem{han2015deep} Song Han et al., ``Learning both Weights and Connections for Efficient Neural Networks,'' NeurIPS, 2015.
\end{thebibliography}


\end{document}