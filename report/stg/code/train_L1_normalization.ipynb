{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in ./.venv/lib/python3.12/site-packages (2.9.1)\n",
            "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (2.2.4)\n",
            "Requirement already satisfied: matplotlib in ./.venv/lib/python3.12/site-packages (3.10.1)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.12/site-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch) (78.1.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.12/site-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in ./.venv/lib/python3.12/site-packages (from torch) (2025.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        " !pip install torch numpy matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in ./.venv/lib/python3.12/site-packages (2.9.1)\n",
            "Requirement already satisfied: torchvision in ./.venv/lib/python3.12/site-packages (0.24.1)\n",
            "Requirement already satisfied: torchaudio in ./.venv/lib/python3.12/site-packages (2.9.1)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.12/site-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch) (78.1.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.12/site-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in ./.venv/lib/python3.12/site-packages (from torch) (2025.9.0)\n",
            "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (from torchvision) (2.2.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.venv/lib/python3.12/site-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -U torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "([\n",
            "  [\n",
            "    [0.79, 0.29, 0.22],\n",
            "    [0.38, 0.71, 0.42],\n",
            "    [0.24, 0.26, 0.45],\n",
            "    [0.92, 0.99, 0.49],\n",
            "    [0.48, 0.79, 0.93],\n",
            "    [0.73, 0.38, 0.45],\n",
            "    [0.24, 0.21, 0.21],\n",
            "    [0.48, 0.52, 0.52],\n",
            "    [1.0, 0.99, 1.0],\n",
            "  ],\n",
            "  [\n",
            "    [0.36, 0.19, 0.17],\n",
            "    [0.62, 0.5, 0.44],\n",
            "    [0.26, 0.37, 0.49],\n",
            "    [0.35, 0.32, 0.2],\n",
            "    [0.64, 0.49, 0.63],\n",
            "    [0.3, 0.89, 0.93],\n",
            "  ],\n",
            "  [\n",
            "    [0.6, 0.32, 0.17],\n",
            "    [0.07, 0.24, 0.5],\n",
            "    [0.69, 0.35, 0.36],\n",
            "    [0.29, 0.09, 0.2],\n",
            "    [0.73, 0.85, 0.5],\n",
            "    [0.91, 0.54, 0.33],\n",
            "  ],\n",
            "  [\n",
            "    [0.06, 0.09, 0.29],\n",
            "    [0.19, 0.45, 0.33],\n",
            "    [0.52, 0.08, 0.09],\n",
            "    [1.0, 0.9, 0.57],\n",
            "    [0.7, 0.16, 0.26],\n",
            "    [0.14, 0.32, 0.55],\n",
            "  ],\n",
            "  [\n",
            "    [1.0, 1.0, 1.0],\n",
            "    [0.68, 0.69, 0.67],\n",
            "    [0.68, 0.65, 0.73],\n",
            "    [0.42, 0.4, 0.46],\n",
            "    [0.2, 0.19, 0.23],\n",
            "    [0.04, 0.04, 0.07],\n",
            "  ]\n",
            "])\n",
            "\n",
            "保存しました -> formatted_arrays.txt\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "def load_ppm_p3(path: str) -> np.ndarray:\n",
        "\t\"\"\"\n",
        "\tP3(ASCII)形式のPPMを読み込み、(H, W, 3) の uint8 配列を返す。\n",
        "\t- Arduino側が「高さ 幅」の順で出すケースにも対応（画素数から自動判定）。\n",
        "\t- Max値は255のみ対応。\n",
        "\t\"\"\"\n",
        "\ttext = Path(path).read_text(encoding=\"utf-8\").split()\n",
        "\tassert text[0] == \"P3\", \"P3(ASCII)形式のPPMのみ対応しています\"\n",
        "\ta, b = int(text[1]), int(text[2])\n",
        "\tmaxv = int(text[3])\n",
        "\tassert maxv == 255, \"255以外のmax値は未対応です\"\n",
        "\tpix = list(map(int, text[4:]))\n",
        "\n",
        "\tif len(pix) == a * b * 3:\n",
        "\t\th, w = a, b\n",
        "\telif len(pix) == b * a * 3:\n",
        "\t\th, w = b, a\n",
        "\telse:\n",
        "\t\traise ValueError(f\"ヘッダと画素数が一致しません: (a,b,len)={(a,b,len(pix))}\")\n",
        "\n",
        "\timg = np.array(pix, dtype=np.uint8).reshape(h, w, 3)\n",
        "\treturn img\n",
        "\n",
        "def build_marked_arrays(small_ppm_path: str, large_ppm_path: str):\n",
        "\t\"\"\"\n",
        "\t表示用の配列を作る。\n",
        "\t- 1個目: 小PPM(3x3)を行優先で9画素分を並べた 9x3 配列（0-1正規化）\n",
        "\t- 2〜5個目: 大PPM(例:6x6)の先頭4行を、各行ごとに 6x3 配列（0-1正規化）\n",
        "\t戻り値: [ small_9x3, large_row1, large_row2, large_row3, large_row4 ]\n",
        "\t\"\"\"\n",
        "\t# 小PPM（3x3）→ 9x3（行優先でフラット）\n",
        "\timg_s = load_ppm_p3(small_ppm_path)  # 期待: (3,3,3)\n",
        "\tHs, Ws, _ = img_s.shape\n",
        "\tassert Hs == 3 and Ws == 3, f\"small PPMは3x3を想定していますが: {img_s.shape}\"\n",
        "\tsmall_9x3 = []\n",
        "\tfor r in range(3):\n",
        "\t\tfor c in range(3):\n",
        "\t\t\tR, G, B = img_s[r, c].astype(np.float32) / 255.0\n",
        "\t\t\tsmall_9x3.append([float(R), float(G), float(B)])\n",
        "\n",
        "\t# 大PPM（例:6x6）→ 先頭4行 各 6x3\n",
        "\timg_l = load_ppm_p3(large_ppm_path)\n",
        "\tHl, Wl, _ = img_l.shape\n",
        "\tassert Hl >= 4, f\"大きいPPMは少なくとも4行必要です: {img_l.shape}\"\n",
        "\tlarge_rows = []\n",
        "\tfor r in range(4):  # 先頭4行のみ\n",
        "\t\trow_list = []\n",
        "\t\tfor c in range(Wl):\n",
        "\t\t\tR, G, B = img_l[r, c].astype(np.float32) / 255.0\n",
        "\t\t\trow_list.append([float(R), float(G), float(B)])\n",
        "\t\tlarge_rows.append(row_list)\n",
        "\n",
        "\t# 仕様どおりのリスト構造で返す（合計5つの配列）\n",
        "\treturn [small_9x3, large_rows[0], large_rows[1], large_rows[2], large_rows[3]]\n",
        "\n",
        "# ========== 使い方（ここだけファイル名を変えて実行） ==========\n",
        "def round2(v: float) -> float:\n",
        "\treturn float(f\"{v:.2f}\")\n",
        "\n",
        "def round2(v: float) -> float:\n",
        "\treturn float(f\"{v:.2f}\")\n",
        "\n",
        "def format_nested_five(arrays: list[list[list[float]]]) -> str:\n",
        "\t\"\"\"\n",
        "\t5つの配列（[9x3, 6x3, 6x3, 6x3, 6x3]）を\n",
        "\t- 小数第2位に丸め\n",
        "\t- 縦書き（各行を1行ずつ）\n",
        "\t- 外側を ([ ... ]) で囲む\n",
        "\t文字列として組み立てて返す\n",
        "\t\"\"\"\n",
        "\tlines = []\n",
        "\tlines.append(\"([\")\n",
        "\tfor i, block in enumerate(arrays):\n",
        "\t\tlines.append(\"  [\")\n",
        "\t\tfor row in block:\n",
        "\t\t\trounded = [round2(x) for x in row]\n",
        "\t\t\tlines.append(f\"    {rounded},\")\n",
        "\t\tlines.append(\"  ]\" + (\",\" if i < len(arrays) - 1 else \"\"))\n",
        "\tlines.append(\"])\")\n",
        "\treturn \"\\n\".join(lines)\n",
        "\n",
        "# ========== 使い方（このブロックだけ実行） ==========\n",
        "# PPMファイルのパス（ppm/ディレクトリ内のファイルを指定）\n",
        "small_ppm = \"ppm/result38.ppm\"   # 3x3\n",
        "large_ppm = \"ppm/R.ppm\"   # 6x6（先頭4行を使用）\n",
        "\n",
        "arrays = build_marked_arrays(small_ppm, large_ppm)\n",
        "\n",
        "# 1) 画面に縦書きで完全表示（丸め済み）\n",
        "out = format_nested_five(arrays)\n",
        "print(out)\n",
        "\n",
        "# 2) 同じ内容をファイルにも保存（途切れ対策）\n",
        "with open(\"formatted_arrays.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "\tf.write(out)\n",
        "\n",
        "print(\"\\n保存しました -> formatted_arrays.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 推論データold\n",
        "X =  np.array([[0.63, 0.12, 0.07],\n",
        "               [0.24, 0.88, 0.22],\n",
        "               [0.07, 0.28, 0.40],\n",
        "               [0.88, 0.99, 0.28],\n",
        "               [0.40, 0.98, 0.91],\n",
        "               [0.56, 0.20, 0.27],\n",
        "               [0.00, 0.00, 0.00],\n",
        "               [0.28, 0.53, 0.36], \n",
        "               [0.97, 1.00, 0.99],\n",
        "               \n",
        "               [0.22, 0.13, 0.06],\n",
        "               [0.65, 0.64, 0.36],\n",
        "               [0.15, 0.43, 0.42],\n",
        "               [0.15, 0.37, 0.10],\n",
        "               [0.34, 0.55, 0.55],\n",
        "               [0.28, 0.96, 0.68],\n",
        "\n",
        "               [0.68, 0.38, 0.08],\n",
        "               [0.02, 0.25, 0.37],\n",
        "               [0.60, 0.14, 0.11],\n",
        "               [0.11, 0.05, 0.10],\n",
        "               [0.49, 0.97, 0.22],\n",
        "               [0.76, 0.74, 0.16],\n",
        "               \n",
        "               [0.01, 0.08, 0.18],\n",
        "               [0.08, 0.59, 0.16],\n",
        "               [0.49, 0.09, 0.03],\n",
        "               [0.83, 0.97, 0.23],\n",
        "               [0.59, 0.16, 0.19],\n",
        "               [0.09, 0.57, 0.57],\n",
        "               \n",
        "               [1.00, 1.00, 1.00],\n",
        "               [0.68, 0.97, 0.74],\n",
        "               [0.44, 0.71, 0.49],\n",
        "               [0.25, 0.45, 0.30],\n",
        "               [0.11, 0.17, 0.13],\n",
        "               [0.00, 0.03, 0.01],], dtype=np.float32)\n",
        "\n",
        "img1 = cv2.resize(cv2.imread(\"img/reference_image1_cmyk_large.png\", cv2.IMREAD_COLOR_RGB), (3,3), interpolation=cv2.INTER_NEAREST)\n",
        "img2 = cv2.resize(cv2.imread(\"img/reference_image2_cmyk_large.png\", cv2.IMREAD_COLOR_RGB), (6,4), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "plt.imshow(img1)\n",
        "plt.show()\n",
        "plt.imshow(img2)\n",
        "plt.show()\n",
        "\n",
        "# 正解データ\n",
        "Y = np.concatenate([img1.reshape([-1, 3])/255, img2.reshape([-1, 3])/255], axis=0).astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# このセルは削除されました。Cell 4（推論データold）を使用してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "モデル定義完了: 隠れ層次元 = 40\n",
            "Epoch [0/50000]  MSE: 0.458537  L1: 166.16  Loss: 0.458703\n",
            "Epoch [500/50000]  MSE: 0.001930  L1: 126.19  Loss: 0.002056\n",
            "Epoch [1000/50000]  MSE: 0.001137  L1: 133.98  Loss: 0.001271\n",
            "Epoch [1500/50000]  MSE: 0.000707  L1: 134.93  Loss: 0.000841\n",
            "Epoch [2000/50000]  MSE: 0.000579  L1: 134.43  Loss: 0.000714\n",
            "Epoch [2500/50000]  MSE: 0.000438  L1: 133.75  Loss: 0.000572\n",
            "Epoch [3000/50000]  MSE: 0.000367  L1: 130.27  Loss: 0.000497\n",
            "Epoch [3500/50000]  MSE: 0.000277  L1: 128.11  Loss: 0.000405\n",
            "Epoch [4000/50000]  MSE: 0.000211  L1: 128.06  Loss: 0.000339\n",
            "Epoch [4500/50000]  MSE: 0.000209  L1: 127.95  Loss: 0.000337\n",
            "Epoch [5000/50000]  MSE: 0.000163  L1: 126.26  Loss: 0.000290\n",
            "Epoch [5500/50000]  MSE: 0.000146  L1: 124.93  Loss: 0.000271\n",
            "Epoch [6000/50000]  MSE: 0.000141  L1: 124.36  Loss: 0.000265\n",
            "Epoch [6500/50000]  MSE: 0.000212  L1: 124.38  Loss: 0.000336\n",
            "Epoch [7000/50000]  MSE: 0.000094  L1: 123.84  Loss: 0.000218\n",
            "Epoch [7500/50000]  MSE: 0.000078  L1: 123.33  Loss: 0.000201\n",
            "Epoch [8000/50000]  MSE: 0.000065  L1: 122.93  Loss: 0.000188\n",
            "Epoch [8500/50000]  MSE: 0.000032  L1: 121.89  Loss: 0.000154\n",
            "Epoch [9000/50000]  MSE: 0.000043  L1: 120.35  Loss: 0.000164\n",
            "Epoch [9500/50000]  MSE: 0.000033  L1: 118.57  Loss: 0.000151\n",
            "Epoch [10000/50000]  MSE: 0.000026  L1: 116.50  Loss: 0.000142\n",
            "Epoch [10500/50000]  MSE: 0.000081  L1: 114.60  Loss: 0.000196\n",
            "Epoch [11000/50000]  MSE: 0.000025  L1: 112.72  Loss: 0.000138\n",
            "Epoch [11500/50000]  MSE: 0.000042  L1: 111.02  Loss: 0.000153\n",
            "Epoch [12000/50000]  MSE: 0.000018  L1: 109.72  Loss: 0.000127\n",
            "Epoch [12500/50000]  MSE: 0.000066  L1: 108.38  Loss: 0.000174\n",
            "Epoch [13000/50000]  MSE: 0.000045  L1: 107.07  Loss: 0.000152\n",
            "Epoch [13500/50000]  MSE: 0.000043  L1: 105.98  Loss: 0.000148\n",
            "Epoch [14000/50000]  MSE: 0.000032  L1: 104.97  Loss: 0.000137\n",
            "Epoch [14500/50000]  MSE: 0.000298  L1: 104.00  Loss: 0.000402\n",
            "Epoch [15000/50000]  MSE: 0.000025  L1: 103.03  Loss: 0.000128\n",
            "Epoch [15500/50000]  MSE: 0.000022  L1: 102.12  Loss: 0.000124\n",
            "Epoch [16000/50000]  MSE: 0.000058  L1: 101.21  Loss: 0.000159\n",
            "Epoch [16500/50000]  MSE: 0.000048  L1: 100.31  Loss: 0.000148\n",
            "Epoch [17000/50000]  MSE: 0.000018  L1: 99.31  Loss: 0.000117\n",
            "Epoch [17500/50000]  MSE: 0.000012  L1: 97.91  Loss: 0.000110\n",
            "Epoch [18000/50000]  MSE: 0.000005  L1: 96.73  Loss: 0.000102\n",
            "Epoch [18500/50000]  MSE: 0.000006  L1: 96.11  Loss: 0.000102\n",
            "Epoch [19000/50000]  MSE: 0.000001  L1: 94.86  Loss: 0.000096\n",
            "Epoch [19500/50000]  MSE: 0.000004  L1: 94.49  Loss: 0.000099\n",
            "Epoch [20000/50000]  MSE: 0.000003  L1: 92.90  Loss: 0.000096\n",
            "Epoch [20500/50000]  MSE: 0.000005  L1: 93.09  Loss: 0.000098\n",
            "Epoch [21000/50000]  MSE: 0.000036  L1: 92.38  Loss: 0.000128\n",
            "Epoch [21500/50000]  MSE: 0.000001  L1: 91.09  Loss: 0.000093\n",
            "Epoch [22000/50000]  MSE: 0.000007  L1: 90.69  Loss: 0.000097\n",
            "Epoch [22500/50000]  MSE: 0.000029  L1: 89.69  Loss: 0.000119\n",
            "Epoch [23000/50000]  MSE: 0.000007  L1: 89.13  Loss: 0.000096\n",
            "Epoch [23500/50000]  MSE: 0.000007  L1: 88.84  Loss: 0.000096\n",
            "Epoch [24000/50000]  MSE: 0.000002  L1: 88.03  Loss: 0.000090\n",
            "Epoch [24500/50000]  MSE: 0.000126  L1: 87.89  Loss: 0.000214\n",
            "Epoch [25000/50000]  MSE: 0.000056  L1: 87.33  Loss: 0.000143\n",
            "Epoch [25500/50000]  MSE: 0.000014  L1: 86.91  Loss: 0.000101\n",
            "Epoch [26000/50000]  MSE: 0.000006  L1: 86.69  Loss: 0.000093\n",
            "Epoch [26500/50000]  MSE: 0.000069  L1: 86.47  Loss: 0.000156\n",
            "Epoch [27000/50000]  MSE: 0.000003  L1: 86.25  Loss: 0.000089\n",
            "Epoch [27500/50000]  MSE: 0.000031  L1: 86.03  Loss: 0.000117\n",
            "Epoch [28000/50000]  MSE: 0.000159  L1: 85.66  Loss: 0.000245\n",
            "Epoch [28500/50000]  MSE: 0.000001  L1: 85.90  Loss: 0.000087\n",
            "Epoch [29000/50000]  MSE: 0.000009  L1: 85.30  Loss: 0.000094\n",
            "Epoch [29500/50000]  MSE: 0.000037  L1: 85.06  Loss: 0.000123\n",
            "Epoch [30000/50000]  MSE: 0.000032  L1: 84.54  Loss: 0.000117\n",
            "Epoch [30500/50000]  MSE: 0.000002  L1: 84.75  Loss: 0.000087\n",
            "Epoch [31000/50000]  MSE: 0.000055  L1: 84.53  Loss: 0.000140\n",
            "Epoch [31500/50000]  MSE: 0.000005  L1: 84.21  Loss: 0.000089\n",
            "Epoch [32000/50000]  MSE: 0.000005  L1: 83.86  Loss: 0.000089\n",
            "Epoch [32500/50000]  MSE: 0.000002  L1: 83.44  Loss: 0.000085\n",
            "Epoch [33000/50000]  MSE: 0.000001  L1: 82.98  Loss: 0.000084\n",
            "Epoch [33500/50000]  MSE: 0.000003  L1: 82.52  Loss: 0.000086\n",
            "Epoch [34000/50000]  MSE: 0.000004  L1: 82.29  Loss: 0.000086\n",
            "Epoch [34500/50000]  MSE: 0.000010  L1: 81.59  Loss: 0.000091\n",
            "Epoch [35000/50000]  MSE: 0.000003  L1: 81.07  Loss: 0.000084\n",
            "Epoch [35500/50000]  MSE: 0.000011  L1: 80.51  Loss: 0.000091\n",
            "Epoch [36000/50000]  MSE: 0.000041  L1: 84.49  Loss: 0.000126\n",
            "Epoch [36500/50000]  MSE: 0.000011  L1: 82.70  Loss: 0.000094\n",
            "Epoch [37000/50000]  MSE: 0.000010  L1: 81.84  Loss: 0.000091\n",
            "Epoch [37500/50000]  MSE: 0.000070  L1: 81.56  Loss: 0.000152\n",
            "Epoch [38000/50000]  MSE: 0.000020  L1: 80.86  Loss: 0.000100\n",
            "Epoch [38500/50000]  MSE: 0.000017  L1: 80.47  Loss: 0.000097\n",
            "Epoch [39000/50000]  MSE: 0.000183  L1: 80.28  Loss: 0.000263\n",
            "Epoch [39500/50000]  MSE: 0.000010  L1: 80.76  Loss: 0.000090\n",
            "Epoch [40000/50000]  MSE: 0.000038  L1: 79.93  Loss: 0.000118\n",
            "Epoch [40500/50000]  MSE: 0.000005  L1: 79.57  Loss: 0.000085\n",
            "Epoch [41000/50000]  MSE: 0.000010  L1: 79.45  Loss: 0.000089\n",
            "Epoch [41500/50000]  MSE: 0.000011  L1: 79.30  Loss: 0.000090\n",
            "Epoch [42000/50000]  MSE: 0.000005  L1: 78.98  Loss: 0.000084\n",
            "Epoch [42500/50000]  MSE: 0.000050  L1: 79.93  Loss: 0.000130\n",
            "Epoch [43000/50000]  MSE: 0.000010  L1: 78.48  Loss: 0.000088\n",
            "Epoch [43500/50000]  MSE: 0.000023  L1: 78.35  Loss: 0.000102\n",
            "Epoch [44000/50000]  MSE: 0.000013  L1: 78.17  Loss: 0.000092\n",
            "Epoch [44500/50000]  MSE: 0.000006  L1: 77.98  Loss: 0.000084\n",
            "Epoch [45000/50000]  MSE: 0.000004  L1: 77.79  Loss: 0.000081\n",
            "Epoch [45500/50000]  MSE: 0.000013  L1: 77.52  Loss: 0.000091\n",
            "Epoch [46000/50000]  MSE: 0.000010  L1: 77.54  Loss: 0.000088\n",
            "Epoch [46500/50000]  MSE: 0.000010  L1: 77.38  Loss: 0.000087\n",
            "Epoch [47000/50000]  MSE: 0.000002  L1: 77.17  Loss: 0.000079\n",
            "Epoch [47500/50000]  MSE: 0.000006  L1: 77.08  Loss: 0.000083\n",
            "Epoch [48000/50000]  MSE: 0.000006  L1: 76.87  Loss: 0.000083\n",
            "Epoch [48500/50000]  MSE: 0.000014  L1: 76.42  Loss: 0.000090\n",
            "Epoch [49000/50000]  MSE: 0.000045  L1: 76.61  Loss: 0.000122\n",
            "Epoch [49500/50000]  MSE: 0.000035  L1: 76.27  Loss: 0.000111\n",
            "\n",
            "予測結果：\n",
            "[[ 0.9254422   0.11551844  0.13934174]\n",
            " [ 0.41002536  0.73690134  0.26947182]\n",
            " [ 0.21674387  0.3240215   0.64180726]\n",
            " [ 0.95999974  0.91758     0.08027498]\n",
            " [ 0.4330293   0.7988629   0.8688506 ]\n",
            " [ 0.7189416   0.31474164  0.62013704]\n",
            " [-0.00214896 -0.00257379 -0.00113299]\n",
            " [ 0.49945498  0.4951483   0.49798393]\n",
            " [ 0.99654794  0.9966243   1.0033605 ]\n",
            " [ 0.45202273  0.30624717  0.25603747]\n",
            " [ 0.7616907   0.5612574   0.4934681 ]\n",
            " [ 0.35245544  0.4707943   0.6105972 ]\n",
            " [ 0.3531191   0.42036647  0.24891114]\n",
            " [ 0.5151811   0.49983233  0.6864934 ]\n",
            " [ 0.37570214  0.74053675  0.67845595]\n",
            " [ 0.86811715  0.47556525  0.18507768]\n",
            " [ 0.26690218  0.3518874   0.65289205]\n",
            " [ 0.7742401   0.30941767  0.37588766]\n",
            " [ 0.35977733  0.22708185  0.40793633]\n",
            " [ 0.6118016   0.7356884   0.22882622]\n",
            " [ 0.8910735   0.62864846  0.15512991]\n",
            " [ 0.14976567  0.2432501   0.5622519 ]\n",
            " [ 0.2334891   0.57688946  0.27048552]\n",
            " [ 0.69943196  0.21203128  0.22328156]\n",
            " [ 0.91366726  0.7744611   0.11038768]\n",
            " [ 0.74798995  0.30880785  0.56837916]\n",
            " [ 0.00299321  0.5193199   0.6479521 ]\n",
            " [ 0.9477677   0.9498802   0.92396754]\n",
            " [ 0.7879265   0.7935695   0.7899868 ]\n",
            " [ 0.62653404  0.63279104  0.6376306 ]\n",
            " [ 0.47528565  0.47523454  0.47545874]\n",
            " [ 0.32557714  0.3293606   0.3361155 ]\n",
            " [ 0.1896667   0.18943383  0.1902421 ]]\n",
            "\n",
            "C++ 用のパラメータファイル (model_parameters.h) を作成しました。\n",
            "隠れ層次元: 40\n"
          ]
        }
      ],
      "source": [
        "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "Y_tensor = torch.tensor(Y, dtype=torch.float32)\n",
        "\n",
        "# ========== モデル設定（次元を変更する場合はここを編集） ==========\n",
        "HIDDEN_DIM = 40  # 隠れ層の次元（40, 100, 200などに変更可能）\n",
        "# ================================================================\n",
        "\n",
        "# モデル定義\n",
        "class ColorNet(nn.Module):\n",
        "    def __init__(self, hidden_dim=40):\n",
        "        super(ColorNet, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(3, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 3),\n",
        "        )\n",
        "\n",
        "    def predict(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "model = ColorNet(hidden_dim=HIDDEN_DIM)\n",
        "print(f\"モデル定義完了: 隠れ層次元 = {HIDDEN_DIM}\")\n",
        "\n",
        "# 損失関数（MSE）\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# 最適化手法\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# L1正則化の係数\n",
        "lambda_l1 = 1e-6\n",
        "\n",
        "# 学習ループ\n",
        "epochs = 50000\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = model(X_tensor)\n",
        "    mse = criterion(outputs, Y_tensor)\n",
        "\n",
        "    # --- L1 正則化-----------------------------\n",
        "    l1 = torch.tensor(0.0, requires_grad=False)\n",
        "    for name, p in model.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            l1 = l1 + p.abs().sum()\n",
        "    loss = mse + lambda_l1 * l1\n",
        "    # -----------------------------------------\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "        print(f'Epoch [{epoch}/{epochs}]  MSE: {mse.item():.6f}  L1: {l1.item():.2f}  Loss: {loss.item():.6f}')\n",
        "\n",
        "with torch.no_grad():\n",
        "    predictions = model(X_tensor)\n",
        "    print(\"\\n予測結果：\")\n",
        "    print(predictions.numpy())\n",
        "\n",
        "def convert_to_cpp_array(tensor: torch.Tensor, name: str, dtype: str = \"float\"):\n",
        "    flat = tensor.detach().numpy().flatten()\n",
        "    array_str = f\"{dtype} {name}[] = {{\"\n",
        "    array_str += \", \".join(map(str, flat))\n",
        "    array_str += \"};\"\n",
        "    return array_str\n",
        "\n",
        "cpp_code = f\"// モデルパラメータ (隠れ層次元: {HIDDEN_DIM})\\n\"\n",
        "\n",
        "layer_idx = 1\n",
        "for layer in model.model:\n",
        "    if isinstance(layer, torch.nn.Linear):\n",
        "        cpp_code += convert_to_cpp_array(layer.weight, f\"weight_{layer_idx}\") + \"\\n\"\n",
        "        cpp_code += convert_to_cpp_array(layer.bias,   f\"bias_{layer_idx}\") + \"\\n\"\n",
        "        layer_idx += 1\n",
        "\n",
        "with open(\"model_parameters.h\", \"w\") as f:\n",
        "    f.write(cpp_code)\n",
        "\n",
        "print(f\"\\nC++ 用のパラメータファイル (model_parameters.h) を作成しました。\")\n",
        "print(f\"隠れ層次元: {HIDDEN_DIM}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cell 6で学習したモデルを再利用します（隠れ層次元: 40）\n",
            "\n",
            "【1層目】元の重み行列サイズ: (40, 3) (120 要素)\n",
            "プルーニング前の非ゼロ要素: 120\n",
            "プルーニング後の非ゼロ要素: 37\n",
            "スパース性: 69.17%\n",
            "  data_1: 37 要素\n",
            "  indices_1: 37 要素\n",
            "  indptr_1: 41 要素\n",
            "  圧縮率: 1.04x\n",
            "\n",
            "【2層目】元の重み行列サイズ: (40, 40) (1600 要素)\n",
            "プルーニング前の非ゼロ要素: 1600\n",
            "プルーニング後の非ゼロ要素: 94\n",
            "スパース性: 94.12%\n",
            "  data_2: 94 要素\n",
            "  indices_2: 94 要素\n",
            "  indptr_2: 41 要素\n",
            "  圧縮率: 6.99x\n",
            "\n",
            "CSR形式パラメータを出力しました: model_parameters_csr40.h\n"
          ]
        }
      ],
      "source": [
        "import numpy as np, torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from scipy.sparse import csr_matrix\n",
        "from pathlib import Path\n",
        "\n",
        "# ========== CSR圧縮設定 ==========\n",
        "PRUNING_THRESHOLD = 0.01  # プルーニングのしきい値（調整可能）\n",
        "# ================================\n",
        "\n",
        "# 重要: Cell 6で学習したモデルを再利用します\n",
        "# Cell 6を先に実行して、model変数が定義されていることを確認してください\n",
        "if 'model' not in globals():\n",
        "    raise ValueError(\"エラー: Cell 6を先に実行して、モデルを学習してください。\")\n",
        "\n",
        "print(f\"Cell 6で学習したモデルを再利用します（隠れ層次元: {HIDDEN_DIM}）\")\n",
        "\n",
        "# 1層目と2層目を取得\n",
        "first_linear = None\n",
        "second_linear = None\n",
        "for layer in model.model:\n",
        "    if isinstance(layer, torch.nn.Linear):\n",
        "        if layer.in_features == 3 and layer.out_features == HIDDEN_DIM:\n",
        "            first_linear = layer\n",
        "        elif layer.in_features == HIDDEN_DIM and layer.out_features == HIDDEN_DIM:\n",
        "            second_linear = layer\n",
        "\n",
        "if first_linear is None:\n",
        "    raise ValueError(f\"1層目（3->{HIDDEN_DIM}）が見つかりません\")\n",
        "if second_linear is None:\n",
        "    raise ValueError(f\"2層目（{HIDDEN_DIM}->{HIDDEN_DIM}）が見つかりません\")\n",
        "\n",
        "# ========== 1層目のCSR圧縮 ==========\n",
        "W1 = first_linear.weight.detach().cpu().numpy().copy()  # (HIDDEN_DIM, 3)\n",
        "b1 = first_linear.bias.detach().cpu().numpy().copy()    # (HIDDEN_DIM,)\n",
        "\n",
        "print(f\"\\n【1層目】元の重み行列サイズ: {W1.shape} ({W1.size} 要素)\")\n",
        "\n",
        "# 1) プルーニング（固定しきい値）\n",
        "non_zero_before_1 = np.count_nonzero(W1)\n",
        "W1[np.abs(W1) < PRUNING_THRESHOLD] = 0.0\n",
        "non_zero_after_1 = np.count_nonzero(W1)\n",
        "sparsity_1 = (1 - non_zero_after_1 / W1.size) * 100\n",
        "\n",
        "print(f\"プルーニング前の非ゼロ要素: {non_zero_before_1}\")\n",
        "print(f\"プルーニング後の非ゼロ要素: {non_zero_after_1}\")\n",
        "print(f\"スパース性: {sparsity_1:.2f}%\")\n",
        "\n",
        "# 2) CSR化\n",
        "csr1 = csr_matrix(W1)  # 行=出力(HIDDEN_DIM), 列=入力(3)\n",
        "data_1 = csr1.data.astype(np.float32)\n",
        "indices_1 = csr1.indices.astype(np.uint16)\n",
        "indptr_1 = csr1.indptr.astype(np.uint16)  # 長さ HIDDEN_DIM+1\n",
        "\n",
        "print(f\"  data_1: {data_1.size} 要素\")\n",
        "print(f\"  indices_1: {indices_1.size} 要素\")\n",
        "print(f\"  indptr_1: {indptr_1.size} 要素\")\n",
        "print(f\"  圧縮率: {W1.size / (data_1.size + indices_1.size + indptr_1.size):.2f}x\")\n",
        "\n",
        "# ========== 2層目のCSR圧縮 ==========\n",
        "W2 = second_linear.weight.detach().cpu().numpy().copy()  # (HIDDEN_DIM, HIDDEN_DIM)\n",
        "b2 = second_linear.bias.detach().cpu().numpy().copy()    # (HIDDEN_DIM,)\n",
        "\n",
        "print(f\"\\n【2層目】元の重み行列サイズ: {W2.shape} ({W2.size} 要素)\")\n",
        "\n",
        "# 1) プルーニング（固定しきい値）\n",
        "non_zero_before_2 = np.count_nonzero(W2)\n",
        "W2[np.abs(W2) < PRUNING_THRESHOLD] = 0.0\n",
        "non_zero_after_2 = np.count_nonzero(W2)\n",
        "sparsity_2 = (1 - non_zero_after_2 / W2.size) * 100\n",
        "\n",
        "print(f\"プルーニング前の非ゼロ要素: {non_zero_before_2}\")\n",
        "print(f\"プルーニング後の非ゼロ要素: {non_zero_after_2}\")\n",
        "print(f\"スパース性: {sparsity_2:.2f}%\")\n",
        "\n",
        "# 2) CSR化\n",
        "csr2 = csr_matrix(W2)  # 行=出力(HIDDEN_DIM), 列=入力(HIDDEN_DIM)\n",
        "data_2 = csr2.data.astype(np.float32)\n",
        "indices_2 = csr2.indices.astype(np.uint16)\n",
        "indptr_2 = csr2.indptr.astype(np.uint16)  # 長さ HIDDEN_DIM+1\n",
        "\n",
        "print(f\"  data_2: {data_2.size} 要素\")\n",
        "print(f\"  indices_2: {indices_2.size} 要素\")\n",
        "print(f\"  indptr_2: {indptr_2.size} 要素\")\n",
        "print(f\"  圧縮率: {W2.size / (data_2.size + indices_2.size + indptr_2.size):.2f}x\")\n",
        "\n",
        "# 3) C配列としてヘッダ出力（1層目と2層目をCSRに）\n",
        "def to_c_array(name, arr, ctype):\n",
        "    elems = \", \".join(map(str, arr.tolist()))\n",
        "    return f\"{ctype} {name}[] = {{{elems}}};\\n\"\n",
        "\n",
        "out = []\n",
        "out.append(f\"// CSR形式パラメータ (隠れ層次元: {HIDDEN_DIM}, プルーニングしきい値: {PRUNING_THRESHOLD})\\n\")\n",
        "out.append(\"// 1層目 (3 -> HIDDEN_DIM)\\n\")\n",
        "out.append(to_c_array(\"data_1\", data_1, \"float\"))\n",
        "out.append(to_c_array(\"indices_1\", indices_1, \"uint16_t\"))\n",
        "out.append(to_c_array(\"indptr_1\", indptr_1, \"uint16_t\"))\n",
        "out.append(\"// 2層目 (HIDDEN_DIM -> HIDDEN_DIM)\\n\")\n",
        "out.append(to_c_array(\"data_2\", data_2, \"float\"))\n",
        "out.append(to_c_array(\"indices_2\", indices_2, \"uint16_t\"))\n",
        "out.append(to_c_array(\"indptr_2\", indptr_2, \"uint16_t\"))\n",
        "\n",
        "filename = f\"model_parameters_csr{HIDDEN_DIM}.h\"\n",
        "Path(filename).write_text(\"\".join(out), encoding=\"utf-8\")\n",
        "\n",
        "print(f\"\\nCSR形式パラメータを出力しました: {filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "【1層目】量子化結果:\n",
            "  元のデータ範囲: [-1.711221, 1.901482]\n",
            "  スケールファクタ: 66.790009\n",
            "  平均量子化誤差: 0.003247\n",
            "\n",
            "【2層目】量子化結果:\n",
            "  元のデータ範囲: [-3.596975, 1.571822]\n",
            "  スケールファクタ: 35.307442\n",
            "  平均量子化誤差: 0.007145\n",
            "\n",
            "量子化CSR形式パラメータを出力しました: model_parameters_csr_quantized40.h\n"
          ]
        }
      ],
      "source": [
        "# ========== 量子化（CSR完了後、オプション） ==========\n",
        "# 注意: 量子化はCSR形式のパラメータに対して適用します\n",
        "# 8-bit量子化を想定（必要に応じて調整）\n",
        "\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# CSRデータを量子化\n",
        "def quantize_to_int8(data, scale_factor=None):\n",
        "    \"\"\"\n",
        "    float32のデータをint8に量子化\n",
        "    scale_factorがNoneの場合は自動計算\n",
        "    \"\"\"\n",
        "    if scale_factor is None:\n",
        "        # データの最大絶対値からスケールを決定\n",
        "        max_val = np.max(np.abs(data))\n",
        "        scale_factor = 127.0 / max_val if max_val > 0 else 1.0\n",
        "    \n",
        "    quantized = np.clip(np.round(data * scale_factor), -128, 127).astype(np.int8)\n",
        "    return quantized, scale_factor\n",
        "\n",
        "def dequantize_from_int8(quantized, scale_factor):\n",
        "    \"\"\"int8からfloat32に逆量子化\"\"\"\n",
        "    return quantized.astype(np.float32) / scale_factor\n",
        "\n",
        "# CSRデータの量子化（オプション: 実行する場合はコメントアウトを外す）\n",
        "USE_QUANTIZATION = True  # Trueにすると量子化を適用\n",
        "\n",
        "if USE_QUANTIZATION:\n",
        "    # 前のセルで生成されたCSRデータを使用\n",
        "    # 注意: このセルは前のセルの後に実行してください\n",
        "    try:\n",
        "        # 1層目の量子化\n",
        "        data_1_quantized, scale_factor_1 = quantize_to_int8(data_1)\n",
        "        data_1_dequantized = dequantize_from_int8(data_1_quantized, scale_factor_1)\n",
        "        quantization_error_1 = np.mean(np.abs(data_1 - data_1_dequantized))\n",
        "        \n",
        "        print(f\"\\n【1層目】量子化結果:\")\n",
        "        print(f\"  元のデータ範囲: [{np.min(data_1):.6f}, {np.max(data_1):.6f}]\")\n",
        "        print(f\"  スケールファクタ: {scale_factor_1:.6f}\")\n",
        "        print(f\"  平均量子化誤差: {quantization_error_1:.6f}\")\n",
        "        \n",
        "        # 2層目の量子化\n",
        "        data_2_quantized, scale_factor_2 = quantize_to_int8(data_2)\n",
        "        data_2_dequantized = dequantize_from_int8(data_2_quantized, scale_factor_2)\n",
        "        quantization_error_2 = np.mean(np.abs(data_2 - data_2_dequantized))\n",
        "        \n",
        "        print(f\"\\n【2層目】量子化結果:\")\n",
        "        print(f\"  元のデータ範囲: [{np.min(data_2):.6f}, {np.max(data_2):.6f}]\")\n",
        "        print(f\"  スケールファクタ: {scale_factor_2:.6f}\")\n",
        "        print(f\"  平均量子化誤差: {quantization_error_2:.6f}\")\n",
        "        \n",
        "        # 量子化されたCSRパラメータを出力\n",
        "        def to_c_array(name, arr, ctype):\n",
        "            elems = \", \".join(map(str, arr.tolist()))\n",
        "            return f\"{ctype} {name}[] = {{{elems}}};\\n\"\n",
        "        \n",
        "        out_quantized = []\n",
        "        out_quantized.append(f\"// 量子化CSR形式パラメータ (隠れ層次元: {HIDDEN_DIM})\\n\")\n",
        "        out_quantized.append(\"// 1層目 (3 -> HIDDEN_DIM)\\n\")\n",
        "        out_quantized.append(to_c_array(\"data_1_quantized\", data_1_quantized, \"int8_t\"))\n",
        "        out_quantized.append(f\"float scale_factor_1 = {scale_factor_1};\\n\")\n",
        "        out_quantized.append(to_c_array(\"indices_1\", indices_1, \"uint16_t\"))\n",
        "        out_quantized.append(to_c_array(\"indptr_1\", indptr_1, \"uint16_t\"))\n",
        "        out_quantized.append(\"// 2層目 (HIDDEN_DIM -> HIDDEN_DIM)\\n\")\n",
        "        out_quantized.append(to_c_array(\"data_2_quantized\", data_2_quantized, \"int8_t\"))\n",
        "        out_quantized.append(f\"float scale_factor_2 = {scale_factor_2};\\n\")\n",
        "        out_quantized.append(to_c_array(\"indices_2\", indices_2, \"uint16_t\"))\n",
        "        out_quantized.append(to_c_array(\"indptr_2\", indptr_2, \"uint16_t\"))\n",
        "        \n",
        "        filename = f\"model_parameters_csr_quantized{HIDDEN_DIM}.h\"\n",
        "        Path(filename).write_text(\"\".join(out_quantized), encoding=\"utf-8\")\n",
        "        print(f\"\\n量子化CSR形式パラメータを出力しました: {filename}\")\n",
        "    except NameError:\n",
        "        print(\"エラー: 前のセルでCSRパラメータを生成してください\")\n",
        "else:\n",
        "    print(\"量子化はスキップされました（USE_QUANTIZATION = False）\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
