\documentclass[a4paper,12pt]{jsarticle}  % 日本語論文向け（uplatex推奨）

% 基本エンコーディング・フォント
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

% 日本語対応（uplatex + dvipdfmx用）
\usepackage{japanese}
\usepackage[dvipdfmx]{pxjahyper}

% ページ設定
\usepackage{geometry}
\geometry{a4paper, margin=1in}

% 数学・数式
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}

% 表・列制御
\usepackage{booktabs}
\usepackage{array}
\usepackage{longtable}
\usepackage{multirow}
\usepackage{colortbl}

% 図・キャプション
\usepackage[dvipdfmx]{graphicx}
\usepackage{caption}
\usepackage{subcaption}

% アルゴリズム
\usepackage{algorithm}
\usepackage{algorithmic}

% ハイパーリンク
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=red,
    urlcolor=green
}

% コードハイライト
\usepackage{listings}
\lstset{
  language=Python,
  basicstyle=\small\ttfamily,
  breaklines=true,
  columns=fixed,
  keepspaces=true,
  showstringspaces=false,
  frame=single,
  numbers=left,
  numberstyle=\tiny,
  captionpos=b
}

\begin{document}

\title{2025年度　アジャイルワーク 報告書}
\author{24G1089　武本 龍}
\maketitle

\section{はじめに}
近年、ディープラーニングをはじめとするAI技術は急速に発展しており、その学習や推論には大規模な計算資源や電力を必要とすることが一般的となっている。
しかし、組込み機器やIoTデバイスのような小型環境では、CPU性能やメモリ容量、電力供給といったリソースが大幅に制限されるため、
従来の手法をそのまま適用することは困難である。
そこで本研究では、既存のArduino Uno R4 WiFi環境において可能な限り高性能なニューラルネットワーク推論を実現することを目的とし、
学習データの軽量化やモデルの圧縮を含む最適化手法を検討し、特に、学習データを圧縮した上で推論に必要な情報を保持できるか、
また限られた計算能力の中で最大限の推論精度を引き出せるかを検証し、その実験手法および得られた知見について報告する。

\section{実験の概要}
図\ref{fig:実験概要}に，本実験の全体構成を示す．

\begin{figure}[h]
    \centering
    \includegraphics[width=16cm]{実験概要.jpg}
    \caption{実験の全体構成}
    \label{fig:実験概要}
\end{figure}
\clearpage
本実験では，Arduino Uno R4 WiFiを用いてカラーセンサーを構築し，授業内で配布された$3 \times 3$のカラーチャートを測定する．
測定後，ニューラルネットワークを用いた補正処理により，平均二乗誤差（MSE）の低減を目指す．
前章で述べた2つの検証項目に対応し，本実験では以下の観点から評価を行う．

第一の検証として，ニューラルネットワークのパラメータ圧縮によるメモリ効率の改善を検討する．
具体的には，隠れ層のデータ圧縮手法を導入し，推論に必要な情報を保持しながらメモリ使用量をどの程度削減できるかを評価する．

第二の検証として，限られた計算資源の中での推論性能の最大化を検討する．
測定したカラーチャートと基準カラーチャート間のMSEを評価指標とし，ニューラルネットワークによる学習を活用して推論精度の向上を図る．
また，predict関数の処理時間を計測し，実行速度についても評価する．

\subsection{平均二乗誤差（MSE）}
平均二乗誤差（MSE）は，2枚の画像の対応するピクセル位置における輝度差の2乗の平均値として定義され，以下の式で表される．
\begin{equation}
\text{MSE} = \frac{1}{m \times n} \sum_{i=1}^{m} \sum_{j=1}^{n} \left( I(i,j) - K(i,j) \right)^2
\end{equation}
ここで，$I$と$K$は比較対象となる2枚の画像，$m \times n$は画像サイズを表す．

本実験ではRGB画像を扱うため，各ピクセルについてR，G，Bチャネルごとの差の2乗を加算し，チャネル数で除した値をMSEとして算出する．
具体的な計算式を以下に示す：
\begin{equation}
\text{MSE} = \frac{(r_{\text{diff}})^2 + (g_{\text{diff}})^2 + (b_{\text{diff}})^2}{3}
\end{equation}
\clearpage


\clearpage
\section{実験理論}
本章では，ニューラルネットワークを用いた読み込み品質の改善手法について述べる．

\subsection{ニューラルネットワークによる品質改善}
サンプル画像と測定画像との誤差を最小化するため，本研究ではニューラルネットワークを用いた学習手法を導入する．
特に，低リソース環境であるArduino上での推論実行を前提とし，モデルの圧縮および疎化手法を併用しながら性能の最適化を図る．

\subsubsection{ネットワーク構造}
本実験で採用したモデルは，全結合型（Fully Connected）の4層ニューラルネットワークである．
入力層はRGBの3次元，2つの隠れ層はそれぞれ40次元（40個のニューロンが全結合），出力層は再びRGBの3次元とした．
各ニューロンにおける推論は以下の式で表される．
\begin{equation}
y = x_1 w_1 + x_2 w_2 + \cdots + x_{n-1} w_{n-1} + b
\end{equation}
ここで，$w_i$は重み，$b$はバイアスを表す．
算出された値はReLU活性化関数を通過し，次層へ伝搬される．

モデルはPyTorchにより定義・訓練し，L1正則化を導入して重みの疎化を促進した．
訓練後の重みおよびバイアスはC++配列としてエクスポートし，Arduino上で実行可能な形式に変換した．
さらに，本研究では隠れ層の次元拡張性を検証するため，40次元に加えて80次元，120次元のモデルについても実験を行った．

\subsection{隠れ層の圧縮手法}

\subsubsection{圧縮の必要性}
Arduino Uno R4 WiFiのようなマイクロコントローラでは，利用可能なメモリ（SRAM約32\,KB，Flash 256\,KB）が極めて限定的である．
隠れ層の次元を増加させると，重みおよびバイアスの格納や推論演算に必要なメモリが不足する可能性が高い．

例えば，隠れ層次元を40から70以上に拡張するとパラメータ総数は急増する．
\begin{itemize}
    \item 40次元：約1,923パラメータ
    \item 70次元：約3,000パラメータ以上
\end{itemize}
float32形式では10\,KBを超える場合，Arduino上での動作が困難となる．
したがって，隠れ層の次元を拡張しながら高い推論性能を維持するには，重みデータの圧縮が不可欠である．

本研究では，この制約を克服するため，まずCSR形式による疎行列圧縮を適用し，さらなる圧縮が必要な場合には量子化を追加適用する方針とする．
以下では，各手法の原理と特徴について述べる．

\subsubsection{プルーニング（Pruning）}
プルーニングとは，閾値以下の重みを0とみなし接続を削除することで，モデルを疎行列化する手法である．
Hanら\cite{han2015deep}は，重要接続の学習，閾値による削減，再訓練を繰り返すことで，大規模モデルを10倍以上圧縮できることを示した．

本研究では，L1正則化により重みを0に近づけた後，閾値0.01でプルーニングを実施する．
この処理により多くの重みが0となり，後述する疎行列表現による効率的な格納が可能となる．

\paragraph{メリット}
\begin{itemize}
    \item パラメータ削減：非ゼロ率を大幅に低下可能（40次元モデルで1,923から200以下も実現可能）
    \item 計算量削減：不要な演算が減少し推論が高速化
    \item 精度維持：軽微な削減であれば再訓練により精度回復が可能
\end{itemize}

\paragraph{デメリット}
\begin{itemize}
    \item 再訓練なしでは精度低下が生じやすい
    \item インデックス保存など疎行列特有のオーバーヘッドが存在
    \item プルーニング量の決定に追加の探索が必要
\end{itemize}

\subsubsection{CSR（Compressed Sparse Row）形式}
CSR形式は，非ゼロ要素を行単位でまとめて保存する疎行列表現であり，値配列（data），列インデックス（indices），行ポインタ（indptr）で構成される．
プルーニングにより疎化された重み行列を効率的に格納でき，行方向のアクセスが高速なためArduino上での推論に適している．

本研究では，CSR形式を第一の圧縮手法として採用する．
L1正則化およびプルーニング後の重み行列をCSR形式に変換することで，SRAM 32\,KBの制約下でも動作可能なモデルへ圧縮する．

\paragraph{メリット}
\begin{itemize}
    \item 行方向のアクセスが高速で推論が効率的
    \item インデックス管理が最適化されメモリ効率が高い
    \item 固定長配列でArduino実装に適する
    \item 非ゼロ率に応じて3〜10倍のメモリ削減が可能
\end{itemize}

\paragraph{デメリット}
\begin{itemize}
    \item 変換時にソートが必要
    \item 列方向アクセスは非効率
\end{itemize}

なお，疎行列表現としてはCOO（Coordinate）形式も存在し，実装が容易という利点があるが，行列ベクトル積の計算効率がCSR形式より劣るため，本研究ではCSR形式を採用した．

\subsubsection{量子化（Quantization）}
量子化とは，ニューラルネットワークの重みや活性化値を32ビット浮動小数点から8ビット整数へ変換し，メモリ削減と計算高速化を図る手法である．
Jacobら\cite{jacob2018quantization}が提案したアフィン変換
\begin{equation}
r = S(q - Z)
\end{equation}
を用いることで，推論時の整数演算が可能となる．
ここで，$S$はスケール，$Z$はゼロポイントを表す．

本研究では，CSR圧縮のみでは十分なメモリ削減が得られない場合の追加手法として量子化を位置づける．
CSR形式で格納された重みに対してfloat32からint8への変換を適用することで，さらに約4倍のメモリ削減が期待できる．

\paragraph{メリット}
\begin{itemize}
    \item メモリ削減：32ビットから8ビットへの変換により約4倍削減
    \item 計算高速化：整数演算により浮動小数点演算より低レイテンシ
    \item 精度維持：量子化感知訓練（QAT）を用いることでMSEをほぼ維持可能
\end{itemize}

\paragraph{デメリット}
\begin{itemize}
    \item モデル規模が小さい場合，チャネルごとの差により誤差が生じやすい
    \item スケール・ゼロポイントの計算やint32蓄積処理など実装がやや複雑
    \item 訓練時にfake quantizationノードの挿入が必要
\end{itemize}

\subsubsection{圧縮手法の比較と本研究での適用方針}
表\ref{tab:weight_compression_summary}に，各圧縮手法の特徴を示す．

\begin{table}[h]
    \centering
    \caption{重み圧縮手法の比較}
    \label{tab:weight_compression_summary}
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{手法} & \textbf{メモリ削減率} & \textbf{計算効率} & \textbf{実装難易度} & \textbf{Arduino適合性} \\
        \hline
        CSR形式 & 3--10倍 & 高 & 中 & 高 \\
        \hline
        量子化 & 約4倍 & 高 & 中 & 高 \\
        \hline
        CSR+量子化 & 12--40倍 & 高 & 高 & 高 \\
        \hline
    \end{tabular}
\end{table}

本研究では，CSR形式による疎行列圧縮を第一の手法として適用し，推論品質への影響を評価する．
CSR圧縮によりMSEが許容範囲内に収まる場合はそのまま採用し，さらなるメモリ削減が必要な場合や隠れ層次元の拡張を行う場合には，CSR圧縮モデルに対して量子化を追加適用する．
この段階的なアプローチにより，推論精度とメモリ効率のバランスを最適化することを目指す．

\clearpage

\section{システムの構成}
本章では，実験に用いたシステムのプログラム構成および配線について述べる．

\subsection{プログラムの構成}
本システムのプログラムを以下に示す．
\begin{lstlisting}[language=Python, caption=メインプログラム]
% TODO: コードを記載
\end{lstlisting}

\begin{lstlisting}[language=Python, caption=補助関数]
% TODO: コードを記載
\end{lstlisting}

\subsection{ハードウェア構成}
本節では，実験で使用した配線および回路構成について述べる．
表\ref{tab:pin_assignment}にArduinoのピン割り当て，表\ref{tab:機材表}に使用機材一覧，図\ref{fig:回路図}に回路図を示す．

\begin{table}[h]
    \centering
    \caption{Arduinoのピン割り当て}
    \label{tab:pin_assignment}
    \begin{tabular}{|c|c|l|}
        \hline
        \textbf{ピン} & \textbf{機能}              & \textbf{説明}                     \\ \hline \hline
        D2           & タクトスイッチ（赤）       & 最大値・最小値の切り替え          \\ \hline
        D3           & タクトスイッチ（青）       & RGBデータの読み取りトリガー       \\ \hline
        A0           & 照度センサー               & フォトトランジスタからのアナログ入力 \\ \hline
    \end{tabular}
\end{table}

\begin{table}[h]
    \centering
    \caption{使用機材一覧}
    \label{tab:機材表}
    \begin{tabular}{|c|c|c|}
        \hline
        機材名 & 型番 & 個数  \\ \hline
        \hline
        炭素皮膜抵抗$330\Omega$ & - & 3  \\ \hline
        炭素皮膜抵抗$3.3k\Omega$ & - & 1  \\ \hline
        炭素皮膜抵抗$10k\Omega$ & - & 2  \\ \hline
        RGBフルカラーLED & OSTA5131A & 1  \\ \hline
        照度センサー（フォトトランジスタ） & NJL7302L-F3 & 1  \\ \hline
        タクトスイッチ(赤・青) & 1273HIM-160G-G & 2  \\ \hline
        ジャンパーワイヤ & BBJ-65 & 13 \\ \hline
        マイコンボード & Arduino UNO R4 WiFi & 1\\ \hline
        ブレッドボード & - & 1 \\ \hline 
    \end{tabular}
\end{table}

\begin{figure}[h]
    \centering
    \includegraphics[width=16cm]{回路図.pdf}
    \caption{回路図}
    \label{fig:回路図}
\end{figure}

\clearpage


\section{実験方法}
以下に，実験方法を示す．

シリアルモニタ経由で画像サイズを入力（配布したカラーチャートだと「３」

ボタンを押すごとに、RGBデータを読み取る

紙をスライドさせて、すべての画素を読み取る（配布したカラーチャートだと、計9回）

シリアルモニタにPPM形式で画像データをテキスト出力






読み込み品質の評価は，以下の手順で実施する．
\begin{enumerate}
    \item \textbf{2つのボタンプログラムによるカラーチャートの読み取り}\\
    事前に黒と白のサンプルを測定し，最小値・最大値を基準として読み込み精度をキャリブレーションする．これにより，センサの感度を調整し，安定したRGB値を取得する．
    \item \textbf{PPM画像出力}\\
    前回授業で配布された3$\times$3のカラーチャートをセンサで読み取り，取得したRGBデータをPPM形式の画像ファイルとして出力する．この画像は，後続の品質評価に用いる．
    \item \textbf{平均二乗誤差（MSE）の計算}\\
    出力したPPM画像と基準画像の品質を，専用のMSE測定ソフトウェアで評価する．
\end{enumerate}

\clearpage

\section{実験方法}
本節では，重み圧縮手法としてCSR（Compressed Sparse Row）形式を第一優先とし，次にCSR圧縮モデルに対する量子化を適用してさらなる圧縮を検討する．
実験は，隠れ層次元40から開始し，「非圧縮」「CSR圧縮」「CSR+量子化」のMSEを比較して品質影響を評価する．
全体フローは，PyTorchによる訓練・圧縮生成，Arduino Uno R4 WiFiへのデプロイ，センサーデータによる推論・MSE計算である．
目標は，MSE相対誤差を5%以内に抑えつつ，次元を100-200へ拡張可能とする．これにより，L1正則化による疎化を活かし，メモリ制約下での画像復元品質向上と読み取り時間短縮を実現する．\subsection{全体実験フロー}データ準備: 授業配布の3$\times$3カラーチャートRGB値を訓練データ（9サンプル，ノイズ付加）とし，基準画像を評価用とする．センサー（例: AS7341）で実測データを収集．
モデル訓練: PyTorchでColorNet（入力3$\to$隠れ$d_1\to d_2\to$出力3，$d_1=d_2=40$初期）を訓練（epochs=50,000, Adam lr=0.01, $\lambda_{L1}=10^{-6}$）．L1正則化で非ゼロ率50％以下を目指す．
圧縮生成: プルーニング（閾値0.01）後，CSR変換（SciPy）し，model_parameters.hエクスポート．
Arduinoデプロイ: スケッチで整数-only forward実装（PROGMEM保存）．RGB入力$\to$推論$\to$PPM出力．
評価基準: MSE/PSNR（PCソフト）とレイテンシ（millis()）を測定．相対誤差<5％，PSNR>25dBで次元拡張（40$\to$60$\to$100$\to$200）．

結果は表\ref{tab:results}にまとめ，圧縮率・誤差・時間のトレードオフを分析する．

\subsection{CSR形式圧縮の実験方法}
CSRを優先する理由は，L1正則化による疎化を活かした高圧縮率（3-10倍）と推論高速化（行指向matvec）である．以下の手順で実施．\begin{enumerate}
    \item \textbf{モデル訓練（Python）:}
    PyTorchでColorNetを訓練．L1正則化で重みを疎化（非ゼロ率<50％）．ReLU活性化使用．
    \item \textbf{プルーニングとCSR生成:}  
    閾値0.01で重みを0化（`torch.abs(w) < 0.01`）．SciPyの`sparse.csr_matrix`でCSR変換（data, indices, indptrをNumPy出力）．C配列として`model_parameters.h`生成（例: `const float csr_w1_data[NNZ] = {...};`）．
    \item \textbf{Arduino実装:}  
    CSR matvec関数を実装（`for j=indptr[i]; j<indptr[i+1]; y[i] += data[j] * x[indices[j]];`）．センサーRGB入力$\to$CSR forward（ReLU統合）$\to$出力RGB$\to$PPM出力．PROGMEMでFlash保存．
    \item \textbf{評価:}  
    PPMと基準画像のMSE/PSNR計算．非圧縮 vs CSRの相対誤差を算出（目標: <3\%）．40次元で確認後，次元増加・再訓練．\end{enumerate}
\clearpage
\subsection{CSR+量子化による追加圧縮の実験方法}
CSR後，8-bit量子化（uint8重み/活性化，int32バイアス）を適用し，メモリをさらに4倍削減．論文\cite{jacob2018quantization}のスキーム（$r = S(q - Z)$）を基に，CSRの疎性を保ち200次元対応を目指す．量子化感知訓練（QAT）で精度を維持．
\begin{enumerate}
    \item \textbf{量子化感知訓練（Python）:}
    訓練グラフにfake quantization挿入（$\hat{r} = \round(\clamp(r; a, b) / S) \cdot S + Z$，$S=(b-a)/255$，範囲$[a,b]$をEMA学習）．初期50kステップで量子化無効化，ReLU6で範囲安定化（epochs=50,000）．
    \item \textbf{量子化実行（Python）:}  
    CSRデータ（float32）をuint8へ変換（$q = \round((r - Z)/S)$，scale=$max(|r|)/127$）．バイアスは$S_w S_a$スケールでint32．multiplier $M = S_w S_a / S_o$をfixed-pointオフライン計算．indptr/indicesをint16圧縮，`model_parameters.h`更新．
    \item \textbf{Arduino実装:}  
    matvec内でuint8乗算+int32蓄積+スケーリング（gemmlowp風）．ReLUをint8 clamp(0,127)．EloquentTinyMLライブラリでint8対応．
    \item \textbf{評価:}  
CSR vs CSR+量子化のMSE比較（目標: 追加誤差<2\%）．レイテンシ短縮率測定．100次元でPSNR>25dB確認後，200次元挑戦．
\end{enumerate}
これらの実験により，CSR基盤上で量子化を積層し，MSE低減・時間短縮を両立．プルーニングとの相乗効果で，非ゼロ率低減と整数演算効率を検証する．


\section{実験方法}
本節では，重み圧縮手法としてCSR（Compressed Sparse Row）形式を第一優先とし，次にCSR圧縮モデルに対する量子化を適用してさらなる圧縮を検討する．
実験は，隠れ層次元40から開始し，「非圧縮」「CSR圧縮」「CSR+量子化」のMSEを比較して品質影響を評価する．
全体フローは，PyTorchによる訓練・圧縮生成，Arduino Uno R4 WiFiへのデプロイ，センサーデータによる推論・MSE計算である．



目標は，MSE相対誤差を5％以内に抑えつつ，次元を100-200へ拡張可能とする．これにより，L1正則化による疎化を活かし，メモリ制約下での画像復元品質向上と読み取り時間短縮を実現する．
\subsection{全体実験フロー}データ準備: 授業配布の3$\times$3カラーチャートRGB値を訓練データ（9サンプル，ノイズ付加）とし，基準画像を評価用とする．センサー（例: AS7341）で実測データを収集．
モデル訓練: PyTorchでColorNet（入力3$\to$隠れ$d_1\to d_2\to$出力3，$d_1=d_2=40$初期）を訓練（epochs=50,000, Adam lr=0.01, $\lambda_{L1}=10^{-6}$）．L1正則化で非ゼロ率50％以下を目指す．
圧縮生成: プルーニング（閾値0.01）後，CSR変換（SciPy）し，model_parameters.hエクスポート．
Arduinoデプロイ: スケッチで整数-only forward実装（PROGMEM保存）．RGB入力$\to$推論$\to$PPM出力．
評価基準: MSE/PSNR（PCソフト）とレイテンシ（millis()）を測定．相対誤差<5％，PSNR>25dBで次元拡張（40$\to$60$\to$100$\to$200）．

結果は表\ref{tab:results}にまとめ，圧縮率・誤差・時間のトレードオフを分析する．


本節では、









\clearpage
\begin{thebibliography}{9}
\bibitem{jacob2018quantization} B. Jacob et al., ``Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference,'' CVPR, 2018.
\bibitem{han2015deep} Song Han et al., ``Learning both Weights and Connections for Efficient Neural Networks,'' NeurIPS, 2015.
\end{thebibliography}


\end{document}