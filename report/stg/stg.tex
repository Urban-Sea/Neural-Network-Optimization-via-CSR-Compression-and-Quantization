\documentclass[a4paper,12pt]{jsarticle}  % 日本語論文向け（uplatex推奨）

% 基本エンコーディング・フォント
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

% ページ設定
\usepackage{geometry}
\geometry{a4paper, margin=1in}

% 数学・数式
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}

% 表・列制御
\usepackage{booktabs}
\usepackage{array}
\usepackage{longtable}
\usepackage{multirow}
\usepackage{colortbl}

% 図・キャプション
\usepackage[dvipdfmx]{graphicx}
\usepackage{caption}
\usepackage{subcaption}

% アルゴリズム
\usepackage{algorithm}
\usepackage{algorithmic}

% ハイパーリンク（pxjahyperより前に読み込む必要がある）
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=red,
    urlcolor=green
}

% 日本語対応（uplatex + dvipdfmx用、hyperrefの後に読み込む）
\usepackage[dvipdfmx]{pxjahyper}

% コードハイライト
\usepackage{listings}
\lstset{
  language=Python,
  basicstyle=\small\ttfamily,
  breaklines=true,
  columns=fixed,
  keepspaces=true,
  showstringspaces=false,
  frame=single,
  numbers=left,
  numberstyle=\tiny,
  captionpos=b
}

\begin{document}

\title{2025年度　アジャイルワーク 報告書}
\author{24G1089　武本 龍}
\maketitle

\section{はじめに}
近年、ディープラーニングをはじめとするAI技術は急速に発展しており、その学習や推論には大規模な計算資源や電力を必要とすることが一般的となっている。
しかし、組込み機器やIoTデバイスのような小型環境では、CPU性能やメモリ容量、電力供給といったリソースが大幅に制限されるため、
従来の手法をそのまま適用することは困難である。
そこで本研究では、既存のArduino Uno R4 WiFi環境において可能な限り高性能なニューラルネットワーク推論を実現することを目的とし、
学習データの軽量化やモデルの圧縮を含む最適化手法を検討し、特に、学習データを圧縮した上で推論に必要な情報を保持できるか、
また限られた計算能力の中で最大限の推論精度を引き出せるかを検証し、その実験手法および得られた知見について報告する。

\section{実験の概要}
図\ref{fig:実験概要}に，本実験の全体構成を示す．

\begin{figure}[h]
    \centering
    \includegraphics[width=16cm]{実験概要.jpg}
    \caption{実験の全体構成}
    \label{fig:実験概要}
\end{figure}
\clearpage
本実験では，Arduino Uno R4 WiFiを用いてカラーセンサーを構築し，授業内で配布された$3 \times 3$のカラーチャートを測定する．
測定後，ニューラルネットワークを用いた補正処理により，平均二乗誤差（MSE）の低減を目指す．
前章で述べた2つの検証項目に対応し，本実験では以下の観点から評価を行う．

第一の検証として，ニューラルネットワークのパラメータ圧縮によるメモリ効率の改善を検討する．
具体的には，隠れ層のデータ圧縮手法を導入し，推論に必要な情報を保持しながらメモリ使用量をどの程度削減できるかを評価する．

第二の検証として，限られた計算資源の中での推論性能の最大化を検討する．
測定したカラーチャートと基準カラーチャート間のMSEを評価指標とし，ニューラルネットワークによる学習を活用して推論精度の向上を図る．
また，predict関数の処理時間を計測し，実行速度についても評価する．

\subsection{平均二乗誤差（MSE）}
平均二乗誤差（MSE）は，2枚の画像の対応するピクセル位置における輝度差の2乗の平均値として定義され，以下の式で表される．
\begin{equation}
\text{MSE} = \frac{1}{m \times n} \sum_{i=1}^{m} \sum_{j=1}^{n} \left( I(i,j) - K(i,j) \right)^2
\end{equation}
ここで，$I$と$K$は比較対象となる2枚の画像，$m \times n$は画像サイズを表す．

本実験ではRGB画像を扱うため，各ピクセルについてR，G，Bチャネルごとの差の2乗を加算し，チャネル数で除した値をMSEとして算出する．
具体的な計算式を以下に示す：
\begin{equation}
\text{MSE} = \frac{(r_{\text{diff}})^2 + (g_{\text{diff}})^2 + (b_{\text{diff}})^2}{3}
\end{equation}
\clearpage


\clearpage
\section{実験理論}
本章では，ニューラルネットワークを用いた読み込み品質の改善手法について述べる．

\subsection{ニューラルネットワークによる品質改善}
サンプル画像と測定画像との誤差を最小化するため，本研究ではニューラルネットワークを用いた学習手法を導入する．
特に，低リソース環境であるArduino上での推論実行を前提とし，モデルの圧縮および疎化手法を併用しながら性能の最適化を図る．

\subsubsection{ネットワーク構造}
本実験で採用したモデルは，全結合型（Fully Connected）の4層ニューラルネットワークである．
入力層はRGBの3次元，2つの隠れ層はそれぞれ40次元（40個のニューロンが全結合），出力層は再びRGBの3次元とした．
各ニューロンにおける推論は以下の式で表される．
\begin{equation}
y = x_1 w_1 + x_2 w_2 + \cdots + x_{n-1} w_{n-1} + b
\end{equation}
ここで，$w_i$は重み，$b$はバイアスを表す．
算出された値はReLU活性化関数を通過し，次層へ伝搬される．

モデルはPyTorchにより定義・訓練し，L1正則化を導入して重みの疎化を促進した．
訓練後の重みおよびバイアスはC++配列としてエクスポートし，Arduino上で実行可能な形式に変換した．
さらに，本研究では隠れ層の次元拡張性を検証するため，40次元に加えて80次元，120次元のモデルについても実験を行った．

\subsection{隠れ層の圧縮手法}

\subsubsection{圧縮の必要性}
Arduino Uno R4 WiFiのようなマイクロコントローラでは，利用可能なメモリ（SRAM約32\,KB，Flash 256\,KB）が極めて限定的である．
隠れ層の次元を増加させると，重みおよびバイアスの格納や推論演算に必要なメモリが不足する可能性が高い．

例えば，隠れ層次元を40から70以上に拡張するとパラメータ総数は急増する．
\begin{itemize}
    \item 40次元：約1,923パラメータ
    \item 70次元：約3,000パラメータ以上
\end{itemize}
float32形式では10\,KBを超える場合，Arduino上での動作が困難となる．
したがって，隠れ層の次元を拡張しながら高い推論性能を維持するには，重みデータの圧縮が不可欠である．

\subsubsection{圧縮手法の概観}
ニューラルネットワークの圧縮手法は多岐にわたるが，本研究のようなマイクロコントローラ環境では，実装の複雑さと圧縮効果のバランスが重要となる．
代表的な手法として，プルーニング（枝刈り），疎行列表現（CSR形式など），量子化が挙げられる．

これらの手法は独立に適用することも，組み合わせて適用することも可能である．
以下では，各手法の原理と特徴を述べた上で，本研究における適用方針を示す．

\clearpage
\subsubsection{プルーニング（Pruning）}
プルーニングとは，閾値以下の重みを0とみなし接続を削除することで，モデルを疎行列化する手法である．
Hanら\cite{han2015deep}は，重要接続の学習，閾値による削減，再訓練を繰り返すことで，大規模モデルを10倍以上圧縮できることを示した．

本研究では，L1正則化により重みを0に近づけた後，閾値0.01でプルーニングを実施する．
この処理により多くの重みが0となり，後述する疎行列表現による効率的な格納が可能となる．

\paragraph{メリット}
\begin{itemize}
    \item パラメータ削減：非ゼロ率を大幅に低下可能（40次元モデルで1,923から200以下も実現可能）
    \item 計算量削減：不要な演算が減少し推論が高速化
    \item 精度維持：軽微な削減であれば再訓練により精度回復が可能
\end{itemize}

\paragraph{デメリット}
\begin{itemize}
    \item 再訓練なしでは精度低下が生じやすい
    \item インデックス保存など疎行列特有のオーバーヘッドが存在
    \item プルーニング量の決定に追加の探索が必要
\end{itemize}

\subsubsection{CSR（Compressed Sparse Row）形式}
プルーニングにより疎化された重み行列は，そのまま密行列として保持すると0要素にもメモリを消費するため非効率である．
CSR形式は，非ゼロ要素のみを行単位でまとめて保存する疎行列表現であり，値配列（data），列インデックス（indices），行ポインタ（indptr）で構成される．
行方向のアクセスが高速であり，行列ベクトル積を多用するニューラルネットワークの推論に適している．

\paragraph{メリット}
\begin{itemize}
    \item 行方向のアクセスが高速で推論が効率的
    \item インデックス管理が最適化されメモリ効率が高い
    \item 固定長配列でArduino実装に適する
    \item 非ゼロ率に応じて3〜10倍のメモリ削減が可能
\end{itemize}

\paragraph{デメリット}
\begin{itemize}
    \item 変換時にソートが必要
    \item 列方向アクセスは非効率
\end{itemize}

なお，疎行列表現としてはCOO（Coordinate）形式も存在し，実装が容易という利点があるが，行列ベクトル積の計算効率がCSR形式より劣るため，本研究ではCSR形式を採用した．

\subsubsection{量子化（Quantization）}
量子化とは，ニューラルネットワークの重みや活性化値を32ビット浮動小数点から8ビット整数へ変換し，メモリ削減と計算高速化を図る手法である．
Jacobら\cite{jacob2018quantization}が提案したアフィン変換
\begin{equation}
r = S(q - Z)
\end{equation}
を用いることで，推論時の整数演算が可能となる．
ここで，$S$はスケール，$Z$はゼロポイントを表す．

量子化は，プルーニングやCSR形式とは独立に適用可能であり，CSR形式で格納された重みに対しても追加適用できる．
float32からint8への変換により，さらに約4倍のメモリ削減が期待できる．

\paragraph{メリット}
\begin{itemize}
    \item メモリ削減：32ビットから8ビットへの変換により約4倍削減
    \item 計算高速化：整数演算により浮動小数点演算より低レイテンシ
    \item 精度維持：量子化感知訓練（QAT）を用いることでMSEをほぼ維持可能
\end{itemize}

\paragraph{デメリット}
\begin{itemize}
    \item モデル規模が小さい場合，チャネルごとの差により誤差が生じやすい
    \item スケール・ゼロポイントの計算やint32蓄積処理など実装がやや複雑
    \item 訓練時にfake quantizationノードの挿入が必要
\end{itemize}

\subsubsection{本研究における適用方針}
表\ref{tab:weight_compression_summary}に，各圧縮手法の特徴を示す．

\begin{table}[h]
    \centering
    \caption{重み圧縮手法の比較}
    \label{tab:weight_compression_summary}
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{手法} & \textbf{メモリ削減率} & \textbf{計算効率} & \textbf{実装難易度} & \textbf{Arduino適合性} \\
        \hline
        CSR形式 & 3--10倍 & 高 & 中 & 高 \\
        \hline
        量子化 & 約4倍 & 高 & 中 & 高 \\
        \hline
        CSR+量子化 & 12--40倍 & 高 & 高 & 高 \\
        \hline
    \end{tabular}
\end{table}

本研究では，段階的な圧縮アプローチを採用する．
その理由は以下のとおりである．

第一に，圧縮処理は推論精度に影響を与える可能性があるため，必要最小限の圧縮にとどめることが望ましい．
過度な圧縮は精度劣化を招くリスクがあり，圧縮手法を一度に複数適用するよりも，段階的に適用して各段階で精度を確認する方が安全である．

第二に，プルーニングとCSR形式は本質的に連続した処理である．
L1正則化によって重みを疎化し，その結果生じた0要素を効率的に格納するのがCSR形式の役割である．
したがって，この二つを組み合わせた「CSR圧縮」を第一段階として適用するのが自然な流れとなる．

第三に，量子化はCSR形式とは独立に適用可能であり，追加的な圧縮手段として位置づけられる．
CSR圧縮のみでメモリ制約を満たせる場合は量子化を省略でき，さらなる圧縮が必要な場合にのみ追加適用すればよい．

以上の考察に基づき，本研究では次の方針を採る．
まず，L1正則化およびプルーニング後の重み行列をCSR形式に変換し，推論品質への影響を評価する．
CSR圧縮によりMSEが許容範囲内に収まり，かつメモリ制約を満たす場合はそのまま採用する．
一方，さらなるメモリ削減が必要な場合や隠れ層次元の拡張を行う場合には，CSR圧縮モデルに対して量子化を追加適用する．
この段階的なアプローチにより，推論精度とメモリ効率のバランスを最適化することを目指す．

\clearpage
\section{システムの構成}

本章では，実験に用いたシステムのハードウェア構成およびソフトウェア構成について述べる．

\subsection{ハードウェア構成}

本節では，実験で使用した配線および回路構成について述べる．
表\ref{tab:pin_assignment}にArduinoのピン割り当て，表\ref{tab:機材表}に使用機材一覧，図\ref{fig:回路図}に回路図を示す．

\begin{table}[h]
    \centering
    \caption{Arduinoのピン割り当て}
    \label{tab:pin_assignment}
    \begin{tabular}{|c|c|l|}
        \hline
        \textbf{ピン} & \textbf{機能}              & \textbf{説明}                     \\ \hline \hline
        D2           & タクトスイッチ(赤)       & 最大値・最小値の切り替え          \\ \hline
        D3           & タクトスイッチ(青)       & RGBデータの読み取りトリガー       \\ \hline
        A0           & 照度センサー               & フォトトランジスタからのアナログ入力 \\ \hline
    \end{tabular}
\end{table}

\begin{table}[h]
    \centering
    \caption{使用機材一覧}
    \label{tab:機材表}
    \begin{tabular}{|c|c|c|}
        \hline
        機材名 & 型番 & 個数  \\ \hline
        \hline
        炭素皮膜抵抗$330\Omega$ & - & 3  \\ \hline
        炭素皮膜抵抗$3.3k\Omega$ & - & 1  \\ \hline
        炭素皮膜抵抗$10k\Omega$ & - & 2  \\ \hline
        RGBフルカラーLED & OSTA5131A & 1  \\ \hline
        照度センサー(フォトトランジスタ) & NJL7302L-F3 & 1  \\ \hline
        タクトスイッチ(赤・青) & 1273HIM-160G-G & 2  \\ \hline
        ジャンパーワイヤ & BBJ-65 & 13 \\ \hline
        マイコンボード & Arduino UNO R4 WiFi & 1\\ \hline
        ブレッドボード & - & 1 \\ \hline 
    \end{tabular}
\end{table}

\begin{figure}[h]
    \centering
    \includegraphics[width=16cm]{回路図.pdf}
    \caption{回路図}
    \label{fig:回路図}
\end{figure}

\clearpage

\subsection{ソフトウェア構成}

本システムのソフトウェアは，学習フェーズとデプロイフェーズの2段階で構成される．

\subsubsection{学習フェーズ}
学習フェーズでは，PC上でPythonおよびPyTorchを用いてニューラルネットワークの学習を行う．
学習にはJupyter Notebook（\texttt{train\_L1\_normalization.ipynb}）を使用し，以下の処理を実行する．
\begin{enumerate}
    \item データの読み込みと前処理
    \item L1正則化を適用したニューラルネットワークの学習
    \item プルーニングおよびCSR形式への変換
    \item Arduinoで読み込み可能なヘッダファイル（\texttt{.h}）の生成
\end{enumerate}

\subsubsection{デプロイフェーズ}
デプロイフェーズでは，生成したパラメータファイルをArduinoに組み込み，実機上で推論を実行する．
Arduinoコードは用途に応じて以下の3種類を用意した．
\begin{itemize}
    \item \texttt{AI\_Model}：密行列形式（非圧縮）のニューラルネットワーク
    \item \texttt{AI\_CSR}：CSR形式で圧縮したニューラルネットワーク
    \item \texttt{AI\_CSR\_Quantized}：CSR形式に量子化を追加適用したニューラルネットワーク
\end{itemize}

\begin{lstlisting}[language=C, caption=Arduinoメインプログラム（抜粋）]
% TODO: コードを記載
\end{lstlisting}

\begin{lstlisting}[language=C, caption=CSR形式での行列ベクトル積演算]
% TODO: コードを記載
\end{lstlisting}

\clearpage

\section{実験方法}

本章では，前章で述べた段階的圧縮アプローチの有効性を検証するために実施した実験について述べる．

\subsection{実験の目的と方針}

本実験の目的は，Arduino Uno R4 WiFiのメモリ制約下において，ニューラルネットワークの隠れ層次元を拡張しつつ，推論精度を維持することである．
具体的には，隠れ層次元を現行の40から100〜200へ拡張可能とし，画像復元品質の向上と読み取り時間の短縮を実現することを目指す．

この目的を達成するため，重み圧縮手法としてCSR（Compressed Sparse Row）形式を第一優先とし，CSR圧縮のみでは不十分な場合にはCSR圧縮モデルに対して量子化を追加適用する方針とした．
L1正則化による重みの疎化を活かすことで，メモリ効率と推論精度のバランスを最適化する．

実験では，隠れ層次元40から開始し，「非圧縮（密行列形式）」「CSR圧縮」「CSR＋量子化」の3種類のモデルについてMSEを比較し，各圧縮手法が推論品質に与える影響を評価する．

\subsection{実験の全体フロー}

本実験は，以下の3つのフェーズから構成される．

\begin{enumerate}
    \item \textbf{訓練・圧縮フェーズ}：PC上でPyTorchを用いてニューラルネットワークを訓練し，CSR形式への変換および量子化を適用してパラメータファイルを生成する
    \item \textbf{デプロイフェーズ}：生成したパラメータファイルをArduino Uno R4 WiFiに組み込み，実機へ書き込む
    \item \textbf{評価フェーズ}：センサーデータを用いて推論を実行し，出力画像と参照画像のMSEを計算して品質を評価する
\end{enumerate}

% 必要に応じて図を追加
% \begin{figure}[h]
%     \centering
%     \includegraphics[width=14cm]{experiment_flow.pdf}
%     \caption{実験の全体フロー}
%     \label{fig:experiment_flow}
% \end{figure}

\subsection{実験条件}

本実験では，隠れ層次元を変化させながら，各圧縮手法の効果を評価した．
表\ref{tab:experiment_conditions}に実験条件を示す．

\begin{table}[h]
    \centering
    \caption{実験条件}
    \label{tab:experiment_conditions}
    \begin{tabular}{|l|l|}
        \hline
        \textbf{項目} & \textbf{設定値} \\
        \hline
        隠れ層次元 & 40, 80, 120 \\
        \hline
        プルーニング閾値 & 0.01（固定） \\
        \hline
        正則化 & L1正則化 \\
        \hline
        疎行列形式 & CSR形式 \\
        \hline
        量子化 & int8（必要に応じて適用） \\
        \hline
    \end{tabular}
\end{table}

プルーニング閾値を0.01に固定した理由は，予備実験において精度と圧縮率のバランスが良好であったためである．

\subsection{実験手順}

\subsubsection{モデルの学習とパラメータ生成}

モデルの学習およびパラメータ生成は，Jupyter Notebook（\texttt{train\_L1\_normalization.ipynb}）を用いて実施した．
以下に各ステップの詳細を示す．

\paragraph{ステップ1：データ準備}\mbox{}\newline
まず，学習に必要なライブラリ（PyTorch，NumPy，SciPy等）をインポートした．
次に，参照画像としてPPM形式のカラーチャート画像を読み込み，推論用データを準備した．

\paragraph{ステップ2：ニューラルネットワークの学習}\mbox{}\newline
L1正則化を適用したニューラルネットワークを学習した．
学習時には，隠れ層次元を指定するパラメータ\texttt{HIDDEN\_DIM}を設定した．
本実験では，\texttt{HIDDEN\_DIM}を40, 80, 120と変化させて複数のモデルを学習した．
学習完了後，密行列形式のパラメータファイル（\texttt{model\_parameters.h}）が自動生成される．
このファイルは，圧縮なしのベースラインモデルとして使用する．

\paragraph{ステップ3：CSR形式への変換}\mbox{}\newline
学習済みモデルに対し，プルーニング閾値0.01でプルーニングを実施した後，重み行列をCSR形式に変換した．
変換処理では，閾値以下の重みを0として扱い，非ゼロ要素のみを値配列（data），列インデックス（indices），行ポインタ（indptr）として抽出した．
変換後のパラメータは\texttt{model\_parameters\_csr.h}として出力される．

各隠れ層次元に対してこの処理を行い，生成されたファイルは以下のようにリネームして管理した．
\begin{itemize}
    \item 40次元：\texttt{model\_parameters\_csr40.h}
    \item 80次元：\texttt{model\_parameters\_csr80.h}
    \item 120次元：\texttt{model\_parameters\_csr120.h}
\end{itemize}

\paragraph{ステップ4：量子化の適用（オプション）}\mbox{}\newline
CSR圧縮のみではメモリ制約を満たせない場合，またはさらなる圧縮が必要な場合には，CSR形式のパラメータに対してint8量子化を追加適用した．
量子化処理では，float32形式の重みをint8形式に変換し，スケールおよびゼロポイントを算出した．
量子化後のパラメータは\texttt{model\_parameters\_csr\_quantized.h}として出力される．
\clearpage
\subsubsection{Arduinoへのデプロイ}

生成したパラメータファイルをArduinoプロジェクトに組み込み，実機へ書き込みを行った．
以下に詳細な手順を示す．

\paragraph{ステップ1：パラメータファイルの配置}\mbox{}\newline
生成されたパラメータファイルを，対応するArduinoプロジェクトフォルダにコピーした．
表\ref{tab:parameter_files}にファイルの配置先を示す．

\begin{table}[h]
    \centering
    \caption{パラメータファイルの配置}
    \label{tab:parameter_files}
    \begin{tabular}{|l|l|l|}
        \hline
        \textbf{生成ファイル} & \textbf{コピー先} & \textbf{用途} \\
        \hline
        \texttt{model\_parameters.h} & \texttt{Arduino/AI\_Model/} & 密行列形式モデル \\
        \hline
        \texttt{model\_parameters\_csr*.h} & \texttt{Arduino/AI\_CSR/} & CSR形式モデル \\
        \hline
        \texttt{model\_parameters\_csr\_quantized.h} & \texttt{Arduino/AI\_CSR\_Quantized/} & CSR+量子化モデル \\
        \hline
    \end{tabular}
\end{table}

\paragraph{ステップ2：Arduinoコードの設定}\mbox{}\newline
各Arduinoプロジェクト内の\texttt{.ino}ファイルを開き，以下の設定を行った．

まず，\texttt{HIDDEN\_DIM}マクロを学習時と同一の値に設定した．
\begin{lstlisting}[language=C, caption=隠れ層次元の設定]
#define HIDDEN_DIM 80  // 学習時と同じ値に設定
\end{lstlisting}

次に，使用するパラメータファイルをインクルードした．
\begin{lstlisting}[language=C, caption=パラメータファイルのインクルード]
#include "model_parameters_csr80.h"  // 対応するファイルを指定
\end{lstlisting}

なお，\texttt{HIDDEN\_DIM}の値と読み込むパラメータファイルの次元が一致していない場合，正常に動作しないため注意が必要である．

\paragraph{ステップ3：コンパイルとアップロード}\mbox{}\newline
Arduino IDEを用いて，以下の手順でコンパイルおよびアップロードを行った．
\begin{enumerate}
    \item Arduino IDEで対象の\texttt{.ino}ファイルを開く
    \item ボード設定を「Arduino UNO R4 WiFi」に設定する
    \item 接続されているシリアルポートを選択する
    \item 「検証」ボタンでコンパイルエラーがないことを確認する
    \item 「アップロード」ボタンでArduinoに書き込む
\end{enumerate}

コンパイル時には，メモリ使用量が表示される．
SRAM使用量が32\,KBを超える場合はアップロードに失敗するため，その場合はより高い圧縮率の手法を適用する必要がある．

\clearpage
\subsubsection{スキャン実行とデータ取得}

Arduinoに接続したRGBカラーセンサを用いて参照画像をスキャンし，推論結果をPPM形式の画像ファイルとして出力した．
スキャンは以下の手順で実施した．

\paragraph{ステップ1：キャリブレーション}\mbox{}\newline
センサの感度は環境光や個体差により変動するため，測定前にキャリブレーションを行った．
具体的には，2つのタクトスイッチを用いたプログラムにより，黒と白のサンプルを事前に測定し，センサ出力の最小値および最大値を取得した．

キャリブレーション手順は以下のとおりである．
\begin{enumerate}
    \item 赤色タクトスイッチ（D2ピン）を押し，キャリブレーションモードに入る
    \item 黒色サンプルをセンサにかざし，青色タクトスイッチ（D3ピン）を押して最小値を記録する
    \item 白色サンプルをセンサにかざし，青色タクトスイッチを押して最大値を記録する
    \item 赤色タクトスイッチを押し，キャリブレーションモードを終了する
\end{enumerate}

これらの値を基準として読み取り範囲を正規化することで，安定したRGB値の取得を可能とした．

\paragraph{ステップ2：カラーチャートの読み取り}\mbox{}\newline
キャリブレーション完了後，3$\times$3のカラーチャートをセンサで読み取った．
読み取り手順は以下のとおりである．
\begin{enumerate}
    \item カラーチャートの各セルにセンサを順番にかざす
    \item 青色タクトスイッチ（D3ピン）を押してRGB値を取得する
    \item 取得したRGB値はニューラルネットワークによる推論を経て補正される
    \item 全9セルの読み取りが完了するまで繰り返す
\end{enumerate}

\paragraph{ステップ3：PPM画像の出力}\mbox{}\newline
取得したRGBデータは，シリアル通信を介してPC上のスキャナプログラム（\texttt{scanner.c}）に送信され，PPM（Portable Pixel Map）形式の画像ファイルとして出力された．
PPM形式は非圧縮のラスタ画像フォーマットであり，画素値を直接比較できるため，後続のMSE評価に適している．

出力されたPPMファイルは，実験条件ごとに以下のフォルダに整理して保存した．
\begin{itemize}
    \item 密行列形式（40次元）：\texttt{ppm/AI\_Model.data/}
    \item CSR形式（40次元）：\texttt{ppm/csr\_40\_0.01/}
    \item CSR形式（80次元）：\texttt{ppm/csr\_80\_0.01/}
    \item CSR形式（120次元）：\texttt{ppm/csr\_120\_0.01/}
\end{itemize}

各実験条件につき複数回（10回程度）のスキャンを実施し，結果のばらつきを考慮した．

\subsection{評価方法}

推論精度の評価指標として，平均二乗誤差（MSE: Mean Squared Error）を用いた．
MSEは以下の式で定義される．
\begin{equation}
    \text{MSE} = \frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y}_i)^2
\end{equation}
ここで，$N$は画素数，$y_i$は参照画像の画素値，$\hat{y}_i$はスキャン結果の画素値である．

評価には自作のMSE計算ツール（\texttt{mse\_calculator.html}）を使用した．
このツールはブラウザ上で動作し，2つのPPM画像をドラッグ＆ドロップするだけでMSEを算出できる．

評価手順は以下のとおりである．
\begin{enumerate}
    \item ブラウザで\texttt{mse\_calculator.html}を開く
    \item 参照画像（\texttt{ppm/reference\_image1.ppm}）をドラッグ＆ドロップする
    \item スキャン結果のPPMファイルをドラッグ＆ドロップする
    \item 算出されたMSE値を記録する
    \item 各実験条件のすべてのスキャン結果についてMSEを算出し，平均値・最小値・最大値を求める
\end{enumerate}

\subsection{比較対象}

本実験では，以下の3種類のモデルを比較対象とした．

\begin{enumerate}
    \item \textbf{密行列形式（非圧縮）}：L1正則化のみを適用し，圧縮処理を行わないベースラインモデル
    \item \textbf{CSR圧縮}：プルーニング後にCSR形式へ変換したモデル
    \item \textbf{CSR＋量子化}：CSR圧縮に加えてint8量子化を適用したモデル
\end{enumerate}

これらのモデルについて，各隠れ層次元におけるMSEとメモリ使用量を比較し，段階的圧縮アプローチの有効性を検証した．
最終的な目標は，MSEを許容範囲内に抑えつつ，隠れ層次元を100〜200へ拡張可能とすることである．
\clearpage
\section{実験結果}

本章では，前章で述べた実験方法に基づいて実施した実験の結果を示す．

\subsection{MSE測定結果}

各圧縮手法および隠れ層次元におけるMSE測定結果を表\ref{tab:results_mse_comparison}に示す．

\begin{table}[h]
    \centering
    \caption{圧縮手法別MSE比較}
    \label{tab:results_mse_comparison}
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{圧縮手法} & \textbf{隠れ層次元} & \textbf{MSE最小値} & \textbf{MSE最大値} & \textbf{MSE平均値} \\
        \hline
        \hline
        \multicolumn{5}{|c|}{\textbf{非圧縮（密行列形式）}} \\
        \hline
        密行列形式 & 40 & 484.04 & 1559.96 & 730.13 \\
        \hline
        密行列形式 & 50 & 231.11 & 535.59 & 406.93 \\
        \hline
        密行列形式 & 60 & 138.00 & 423.22 & 305.48 \\
        \hline
        密行列形式 & 70 & コンパイルエラー & コンパイルエラー & コンパイルエラー \\
        \hline
        \multicolumn{5}{|c|}{\textbf{CSR圧縮}} \\
        \hline
        CSR圧縮 & 40 & 324.00 & 692.37 & 518.58 \\
        \hline
        CSR圧縮 & 80 & 225.19 & 729.26 & 464.86 \\
        \hline
        CSR圧縮 & 120 & -- & -- & -- \\
        \hline
        CSR圧縮 & 160 & -- & -- & -- \\
        \hline
        CSR圧縮 & 200 & -- & -- & -- \\
        \hline
        CSR圧縮 & 400 & -- & -- & -- \\
        \hline
        CSR圧縮 & 500 & -- & -- & -- \\
        \hline
        CSR圧縮 & 600 & -- & -- & -- \\
        \hline
        CSR圧縮 & 800 & オーバーフロー & オーバーフロー & オーバーフロー \\
        \hline
        \multicolumn{5}{|c|}{\textbf{CSR＋量子化}} \\
        \hline
        CSR＋量子化 & 40 & -- & -- & -- \\
        \hline
        CSR＋量子化 & 80 & -- & -- & -- \\
        \hline
        CSR＋量子化 & 120 & -- & -- & -- \\
        \hline
        CSR＋量子化 & 160 & -- & -- & -- \\
        \hline
        CSR＋量子化 & 200 & -- & -- & -- \\
        \hline
        CSR＋量子化 & 400 & -- & -- & -- \\
        \hline
        CSR＋量子化 & 600 & -- & -- & -- \\
        \hline
        CSR＋量子化 & 800 & コンパイルエラー & コンパイルエラー & コンパイルエラー \\
        \hline
    \end{tabular}
\end{table}

また，同一次元における圧縮手法間の比較を容易にするため，表\ref{tab:results_by_dimension}に隠れ層次元別の結果を示す．

\begin{table}[h]
    \centering
    \caption{隠れ層次元別MSE比較（平均値）}
    \label{tab:results_by_dimension}
    \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{隠れ層次元} & \textbf{非圧縮} & \textbf{CSR圧縮} & \textbf{CSR＋量子化} \\
        \hline
        40 & 730.13 & 518.58 & -- \\
        \hline
        50 & 406.93 & -- & -- \\
        \hline
        60 & 305.48 & -- & -- \\
        \hline
        70 & コンパイルエラー & -- & -- \\
        \hline
        80 & コンパイルエラー & 464.86 & -- \\
        \hline
        120 & コンパイルエラー & -- & -- \\
        \hline
        160 & コンパイルエラー & -- & -- \\
        \hline
        200 & コンパイルエラー & -- & -- \\
        \hline
        400 & コンパイルエラー & -- & -- \\
        \hline
        500 & コンパイルエラー & -- & -- \\
        \hline
        600 & コンパイルエラー & -- & -- \\
        \hline
        800 & コンパイルエラー & オーバーフロー & コンパイルエラー \\
        \hline
    \end{tabular}
\end{table}

\subsection{コンパイル時間とメモリ使用量}

各条件におけるArduinoのコンパイル時間とメモリ使用量を表\ref{tab:results_compile_memory}に示す．

\begin{table}[h]
    \centering
    \caption{コンパイル時間とメモリ使用量}
    \label{tab:results_compile_memory}
    \begin{tabular}{|l|c|c|c|}
        \hline
        \textbf{圧縮手法} & \textbf{隠れ層次元} & \textbf{コンパイル時間} & \textbf{メモリ使用量} \\
        \hline
        \hline
        \multicolumn{4}{|c|}{\textbf{非圧縮（密行列形式）}} \\
        \hline
        密行列形式 & 40 & 4.303s & 14524バイト（44\%） \\
        \hline
        密行列形式 & 50 & 4.589s & 18444バイト（56\%） \\
        \hline
        密行列形式 & 60 & 4.831s & 23164バイト（70\%） \\
        \hline
        密行列形式 & 70 & コンパイルエラー & コンパイルエラー \\
        \hline
        \multicolumn{4}{|c|}{\textbf{CSR圧縮}} \\
        \hline
        CSR圧縮 & 40 & 3.783s & 8488バイト（25\%） \\
        \hline
        CSR圧縮 & 80 & 4.037s & 9508バイト（29\%） \\
        \hline
        CSR圧縮 & 120 & 4.062s & 10520バイト（32\%） \\
        \hline
        CSR圧縮 & 160 & 4.042s & 11332バイト（34\%） \\
        \hline
        CSR圧縮 & 200 & 4.027s & 12332バイト（37\%） \\
        \hline
        CSR圧縮 & 400 & 4.316s & 17204バイト（52\%） \\
        \hline
        CSR圧縮 & 500 & 4.548s & 19556バイト（59\%） \\
        \hline
        CSR圧縮 & 600 & 4.802s & 21976バイト（67\%） \\
        \hline
        CSR圧縮 & 800 & オーバーフロー & オーバーフロー \\
        \hline
        \multicolumn{4}{|c|}{\textbf{CSR＋量子化}} \\
        \hline
        CSR＋量子化 & 40 & 3.772s & 8160バイト（24\%） \\
        \hline
        CSR＋量子化 & 80 & 3.809s & 9148バイト（27\%） \\
        \hline
        CSR＋量子化 & 120 & 4.028s & 10132バイト（30\%） \\
        \hline
        CSR＋量子化 & 160 & 4.033s & 12000バイト（36\%） \\
        \hline
        CSR＋量子化 & 200 & 4.033s & 12000バイト（36\%） \\
        \hline
        CSR＋量子化 & 400 & 4.307s & 16836バイト（51\%） \\
        \hline
        CSR＋量子化 & 600 & 4.801s & 21684バイト（66\%） \\
        \hline
        CSR＋量子化 & 800 & コンパイルエラー & コンパイルエラー \\
        \hline
    \end{tabular}
\end{table}



\subsection{詳細データ}

以下に，各実験条件における個別のスキャン結果を示す．

\subsubsection{非圧縮（密行列形式）}

表\ref{tab:results_dense_detail_40}に，密行列形式（40次元）の詳細な測定結果を示す．

\begin{table}[h]
    \centering
    \caption{密行列形式（40次元）の詳細測定結果}
    \label{tab:results_dense_detail_40}
    \begin{tabular}{|c|c||c|c|}
        \hline
        \textbf{ファイル} & \textbf{MSE} & \textbf{ファイル} & \textbf{MSE} \\
        \hline
        nn1.ppm & 484.04 & nn6.ppm & 715.63 \\
        \hline
        nn2.ppm & 713.74 & nn7.ppm & 523.63 \\
        \hline
        nn3.ppm & 733.93 & nn8.ppm & 792.85 \\
        \hline
        nn4.ppm & 1559.96 & nn9.ppm & 905.85 \\
        \hline
        nn5.ppm & 782.33 & nn10.ppm & 882.15 \\
        \hline
    \end{tabular}
\end{table}

表\ref{tab:results_dense_detail_50}に，密行列形式（50次元）の詳細な測定結果を示す．

\begin{table}[h]
    \centering
    \caption{密行列形式（50次元）の詳細測定結果}
    \label{tab:results_dense_detail_50}
    \begin{tabular}{|c|c||c|c|}
        \hline
        \textbf{ファイル} & \textbf{MSE} & \textbf{ファイル} & \textbf{MSE} \\
        \hline
        nn50\_1.ppm & 369.30 & nn50\_6.ppm & 231.11 \\
        \hline
        nn50\_2.ppm & 486.26 & nn50\_7.ppm & 463.85 \\
        \hline
        nn50\_3.ppm & 444.11 & nn50\_8.ppm & 307.26 \\
        \hline
        nn50\_4.ppm & 472.78 & nn50\_9.ppm & 342.67 \\
        \hline
        nn50\_5.ppm & 416.04 & nn50\_10.ppm & 535.59 \\
        \hline
    \end{tabular}
\end{table}

表\ref{tab:results_dense_detail_60}に，密行列形式（60次元）の詳細な測定結果を示す．

\begin{table}[h]
    \centering
    \caption{密行列形式（60次元）の詳細測定結果}
    \label{tab:results_dense_detail_60}
    \begin{tabular}{|c|c||c|c|}
        \hline
        \textbf{ファイル} & \textbf{MSE} & \textbf{ファイル} & \textbf{MSE} \\
        \hline
        nn60\_1.ppm & 193.07 & nn60\_6.ppm & 332.41 \\
        \hline
        nn60\_2.ppm & 138.00 & nn60\_7.ppm & 297.22 \\
        \hline
        nn60\_3.ppm & 376.22 & nn60\_8.ppm & 417.44 \\
        \hline
        nn60\_4.ppm & 227.26 & nn60\_9.ppm & 240.33 \\
        \hline
        nn60\_5.ppm & 423.22 & nn60.ppm & 409.30 \\
        \hline
    \end{tabular}
\end{table}

\subsubsection{CSR圧縮}

表\ref{tab:results_csr_detail}に，CSR圧縮モデルの詳細な測定結果を示す．

\begin{table}[h]
    \centering
    \caption{CSR圧縮の詳細測定結果}
    \label{tab:results_csr_detail}
    \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{次元} & \textbf{ファイル} & \textbf{MSE} & \textbf{備考} \\
        \hline
        \hline
        \multirow{10}{*}{40} & csr1.ppm & 600.00 & \multirow{10}{*}{測定完了} \\
        \cline{2-3}
        & csr2.ppm & 517.48 & \\
        \cline{2-3}
        & csr3.ppm & 569.78 & \\
        \cline{2-3}
        & csr4.ppm & 659.04 & \\
        \cline{2-3}
        & csr5.ppm & 324.00 & \\
        \cline{2-3}
        & csr6.ppm & 365.07 & \\
        \cline{2-3}
        & csr7.ppm & 522.59 & \\
        \cline{2-3}
        & csr8.ppm & 495.04 & \\
        \cline{2-3}
        & csr9.ppm & 692.37 & \\
        \cline{2-3}
        & csr10.ppm & 440.41 & \\
        \hline
        \hline
        \multirow{10}{*}{80} & 1.ppm & 644.59 & \multirow{10}{*}{測定完了} \\
        \cline{2-3}
        & 2.ppm & 459.37 & \\
        \cline{2-3}
        & 3.ppm & 361.33 & \\
        \cline{2-3}
        & 4.ppm & 225.19 & \\
        \cline{2-3}
        & 5.ppm & 729.26 & \\
        \cline{2-3}
        & 6.ppm & 408.15 & \\
        \cline{2-3}
        & 7.ppm & 380.59 & \\
        \cline{2-3}
        & 8.ppm & 499.85 & \\
        \cline{2-3}
        & 9.ppm & 437.44 & \\
        \cline{2-3}
        & 10.ppm & 472.85 & \\
        \hline
        \hline
        120 & -- & -- & 測定未実施 \\
        \hline
        160 & -- & -- & 測定未実施 \\
        \hline
        200 & -- & -- & 測定未実施 \\
        \hline
        400 & -- & -- & 測定未実施 \\
        \hline
        500 & -- & -- & 測定未実施 \\
        \hline
        600 & -- & -- & 測定未実施 \\
        \hline
        800 & -- & -- & オーバーフロー \\
        \hline
    \end{tabular}
\end{table}

\subsubsection{CSR＋量子化}

CSR＋量子化モデルについては，現時点でMSE測定は未実施である．
各次元におけるメモリ使用量とコンパイル時間は表\ref{tab:results_compile_memory}に示したとおりである．

\subsection{結果のまとめ}

現時点で得られた実験結果をまとめると，以下のとおりである．

\begin{enumerate}
    \item 非圧縮（密行列形式）では，40次元でMSE平均値730.13，50次元で406.93，60次元で305.48と，次元を増やすほど精度が向上したが，70次元ではメモリ不足によりコンパイルエラーが発生した．
    \item CSR圧縮（40次元）のMSE平均値は518.58であり，非圧縮（40次元）の730.13と比較して約29\%改善した．
    \item CSR圧縮（80次元）のMSE平均値は464.86であり，非圧縮（40次元）と比較して約36\%改善した．
    \item CSR圧縮により，隠れ層次元を600次元まで拡張してもArduino Uno R4 WiFiのメモリ制約内で動作可能であった（メモリ使用量67\%）．
    \item CSR＋量子化により，さらにメモリ効率が向上し，600次元でもメモリ使用量66\%で動作可能であった．
    \item CSR圧縮（120次元以上）およびCSR＋量子化モデルについては，MSE測定を実施予定である．
\end{enumerate}

これらの結果から，CSR形式による圧縮は推論精度を維持しつつ隠れ層次元の拡張を可能にする有効な手法であることが示唆される．
詳細な考察は次章で述べる．

\clearpage
\begin{thebibliography}{9}
\bibitem{jacob2018quantization} B. Jacob et al., ``Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference,'' CVPR, 2018.
\bibitem{han2015deep} Song Han et al., ``Learning both Weights and Connections for Efficient Neural Networks,'' NeurIPS, 2015.
\end{thebibliography}


\end{document}