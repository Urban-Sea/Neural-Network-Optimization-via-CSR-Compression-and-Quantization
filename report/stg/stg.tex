\documentclass[a4paper,12pt]{jsarticle}  % 日本語論文向け（uplatex推奨）

% 基本エンコーディング・フォント
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

% ページ設定
\usepackage{geometry}
\geometry{a4paper, margin=1in}

% 数学・数式
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}

% 表・列制御
\usepackage{booktabs}
\usepackage{array}
\usepackage{longtable}
\usepackage{multirow}
\usepackage{colortbl}

% 図・キャプション
\usepackage[dvipdfmx]{graphicx}
\usepackage{caption}
\usepackage{subcaption}

% アルゴリズム
\usepackage{algorithm}
\usepackage{algorithmic}

% ハイパーリンク（pxjahyperより前に読み込む必要がある）
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=red,
    urlcolor=green
}

% 日本語対応（uplatex + dvipdfmx用、hyperrefの後に読み込む）
\usepackage[dvipdfmx]{pxjahyper}

% コードハイライト
\usepackage{listings}
\lstset{
  language=Python,
  basicstyle=\small\ttfamily,
  breaklines=true,
  columns=fixed,
  keepspaces=true,
  showstringspaces=false,
  frame=single,
  numbers=left,
  numberstyle=\tiny,
  captionpos=b
}

\begin{document}

\title{2025年度　アジャイルワーク 報告書}
\author{24G1089　武本 龍}
\maketitle

\section{はじめに}
近年、ディープラーニングをはじめとするAI技術は急速に発展しており、その学習や推論には大規模な計算資源や電力を必要とすることが一般的となっている。
しかし、組込み機器やIoTデバイスのような小型環境では、CPU性能やメモリ容量、電力供給といったリソースが大幅に制限されるため、
従来の手法をそのまま適用することは困難である。
そこで本研究では、既存のArduino Uno R4 WiFi環境において可能な限り高性能なニューラルネットワーク推論を実現することを目的とし、
学習データの軽量化やモデルの圧縮を含む最適化手法を検討し、特に、学習データを圧縮した上で推論に必要な情報を保持できるか、
また限られた計算能力の中で最大限の推論精度を引き出せるかを検証し、その実験手法および得られた知見について報告する。

\section{実験の概要}
図\ref{fig:実験概要}に，本実験の全体構成を示す．

\begin{figure}[h]
    \centering
    \includegraphics[width=16cm]{実験概要.jpg}
    \caption{実験の全体構成}
    \label{fig:実験概要}
\end{figure}
\clearpage
本実験では，Arduino Uno R4 WiFiを用いてカラーセンサーを構築し，授業内で配布された$3 \times 3$のカラーチャートを測定する．
測定後，ニューラルネットワークを用いた補正処理により，平均二乗誤差（MSE）の低減を目指す．
前章で述べた2つの検証項目に対応し，本実験では以下の観点から評価を行う．

第一の検証として，ニューラルネットワークのパラメータ圧縮によるメモリ効率の改善を検討する．
具体的には，隠れ層のデータ圧縮手法を導入し，推論に必要な情報を保持しながらメモリ使用量をどの程度削減できるかを評価する．

第二の検証として，限られた計算資源の中での推論性能の最大化を検討する．
測定したカラーチャートと基準カラーチャート間のMSEを評価指標とし，ニューラルネットワークによる学習を活用して推論精度の向上を図る．
また，predict関数の処理時間を計測し，実行速度についても評価する．

\subsection{平均二乗誤差（MSE）}
平均二乗誤差（MSE: Mean Squared Error）は，2枚の画像の対応するピクセル位置における輝度差の2乗の平均値として定義され，以下の式で表される．
\begin{equation}
\text{MSE} = \frac{1}{m \times n} \sum_{i=1}^{m} \sum_{j=1}^{n} \left( I(i,j) - K(i,j) \right)^2
\label{eq:mse_definition}
\end{equation}
ここで，$I$と$K$は比較対象となる2枚の画像，$m \times n$は画像サイズを表す．

本実験ではRGB画像を扱うため，各ピクセルについてR，G，Bチャネルごとの差の2乗を加算し，チャネル数で除した値をMSEとして算出する．
具体的な計算式を以下に示す．
\begin{equation}
\text{MSE} = \frac{(r_{\text{diff}})^2 + (g_{\text{diff}})^2 + (b_{\text{diff}})^2}{3}
\label{eq:mse_rgb}
\end{equation}

MSEの値が小さいほど，2枚の画像間の差異が少なく，色再現性が高いことを示す．
本研究では，このMSEを推論精度の評価指標として用いる．


\clearpage
\section{実験理論}
本章では，ニューラルネットワークを用いた読み込み品質の改善手法について述べる．

\subsection{ニューラルネットワークによる品質改善}
サンプル画像と測定画像との誤差を最小化するため，本研究ではニューラルネットワークを用いた学習手法を導入する．
特に，低リソース環境であるArduino上での推論実行を前提とし，モデルの圧縮および疎化手法を併用しながら性能の最適化を図る．

\subsubsection{ネットワーク構造}
本実験で採用したモデルは，全結合型（Fully Connected）の4層ニューラルネットワークである．
入力層はRGBの3次元，2つの隠れ層はそれぞれ可変次元（実験では40〜600次元），出力層は再びRGBの3次元とした．
各層の構成を表\ref{tab:nn_structure}に示す．

\begin{table}[h]
    \centering
    \caption{ニューラルネットワークの構造}
    \label{tab:nn_structure}
    \begin{tabular}{|l|c|l|}
        \hline
        \textbf{層} & \textbf{次元数} & \textbf{活性化関数} \\
        \hline
        入力層 & 3 & -- \\
        \hline
        隠れ層1 & 40〜600（可変） & ReLU \\
        \hline
        隠れ層2 & 40〜600（可変） & ReLU \\
        \hline
        出力層 & 3 & Sigmoid \\
        \hline
    \end{tabular}
\end{table}

各ニューロンにおける推論は以下の式で表される．
\begin{equation}
y = x_1 w_1 + x_2 w_2 + \cdots + x_{n-1} w_{n-1} + b
\end{equation}
ここで，$w_i$は重み，$b$はバイアスを表す．
算出された値は活性化関数を通過し，次層へ伝搬される．

モデルはPyTorchにより定義・訓練し，L1正則化を導入して重みの疎化を促進した．
訓練後の重みおよびバイアスはC++配列としてエクスポートし，Arduino上で実行可能な形式に変換した．

本研究で適用する圧縮手法（CSR形式，量子化）は，主にパラメータ数の多い隠れ層1および隠れ層2の重み行列に対して適用する．
隠れ層の次元数を拡張するとパラメータ数が増加し，メモリ使用量が増大するため，圧縮手法の適用が不可欠となる．

\subsection{隠れ層の圧縮手法}
\label{sec:compression_methods}
本研究では，ニューラルネットワークの隠れ層パラメータに対して以下の圧縮手法を適用する．

\subsubsection{圧縮の必要性}
Arduino Uno R4 WiFiのようなマイクロコントローラでは，利用可能なメモリ（SRAM約32\,KB，Flash 256\,KB）が極めて限定的である．
隠れ層の次元を増加させると，重みおよびバイアスの格納や推論演算に必要なメモリが不足する可能性が高い．

例えば，隠れ層次元を40から70以上に拡張するとパラメータ総数は急増する．
\begin{itemize}
    \item 40次元：約1,923パラメータ
    \item 70次元：約3,000パラメータ以上
\end{itemize}
float32形式では10\,KBを超える場合，Arduino上での動作が困難となる．
したがって，隠れ層の次元を拡張しながら高い推論性能を維持するには，重みデータの圧縮が不可欠である．

\clearpage
\subsubsection{プルーニング（Pruning）}
プルーニングとは，閾値以下の重みを0とみなし接続を削除することで，モデルを疎行列化する手法である．
Hanら\cite{han2015deep}は，重要接続の学習，閾値による削減，再訓練を繰り返すことで，大規模モデルを10倍以上圧縮できることを示した．

本研究では，L1正則化により重みを0に近づけた後，閾値0.01でプルーニングを実施する．
この処理により多くの重みが0となり，後述する疎行列表現による効率的な格納が可能となる．

\paragraph{メリット}
\begin{itemize}
    \item パラメータ削減：非ゼロ率を大幅に低下可能（40次元モデルで1,923から200以下も実現可能）
    \item 計算量削減：不要な演算が減少し推論が高速化
    \item 精度維持：軽微な削減であれば再訓練により精度回復が可能
\end{itemize}

\paragraph{デメリット}
\begin{itemize}
    \item 再訓練なしでは精度低下が生じやすい
    \item インデックス保存など疎行列特有のオーバーヘッドが存在
    \item プルーニング量の決定に追加の探索が必要
\end{itemize}

\subsubsection{CSR（Compressed Sparse Row）形式}
プルーニングにより疎化された重み行列は，そのまま密行列として保持すると0要素にもメモリを消費するため非効率である．
CSR形式は，非ゼロ要素のみを行単位でまとめて保存する疎行列表現であり，値配列（data），列インデックス（indices），行ポインタ（indptr）で構成される．
行方向のアクセスが高速であり，行列ベクトル積を多用するニューラルネットワークの推論に適している．

\paragraph{メリット}
\begin{itemize}
    \item 行方向のアクセスが高速で推論が効率的
    \item インデックス管理が最適化されメモリ効率が高い
    \item 固定長配列でArduino実装に適する
    \item 非ゼロ率に応じて3〜10倍のメモリ削減が可能
\end{itemize}

\paragraph{デメリット}
\begin{itemize}
    \item 変換時にソートが必要
    \item 列方向アクセスは非効率
\end{itemize}

なお，疎行列表現としてはCOO（Coordinate）形式も存在し，実装が容易という利点があるが，行列ベクトル積の計算効率がCSR形式より劣るため，本研究ではCSR形式を採用した．

\subsubsection{量子化（Quantization）}
量子化とは，ニューラルネットワークの重みや活性化値を32ビット浮動小数点から8ビット整数へ変換し，メモリ削減と計算高速化を図る手法である．
Jacobら\cite{jacob2018quantization}が提案したアフィン変換
\begin{equation}
r = S(q - Z)
\end{equation}
を用いることで，推論時の整数演算が可能となる．
ここで，$S$はスケール，$Z$はゼロポイントを表す．

量子化は，プルーニングやCSR形式とは独立に適用可能であり，CSR形式で格納された重みに対しても追加適用できる．
float32からint8への変換により，さらに約4倍のメモリ削減が期待できる．

\paragraph{メリット}
\begin{itemize}
    \item メモリ削減：32ビットから8ビットへの変換により約4倍削減
    \item 計算高速化：整数演算により浮動小数点演算より低レイテンシ
    \item 精度維持：量子化感知訓練（QAT）を用いることでMSEをほぼ維持可能
\end{itemize}

\paragraph{デメリット}
\begin{itemize}
    \item モデル規模が小さい場合，チャネルごとの差により誤差が生じやすい
    \item スケール・ゼロポイントの計算やint32蓄積処理など実装がやや複雑
    \item 訓練時にfake quantizationノードの挿入が必要
\end{itemize}

\subsubsection{本研究における適用方針}
表\ref{tab:weight_compression_summary}に，各圧縮手法の特徴を示す．

\begin{table}[h]
    \centering
    \caption{重み圧縮手法の比較}
    \label{tab:weight_compression_summary}
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{手法} & \textbf{メモリ削減率} & \textbf{計算効率} & \textbf{実装難易度} & \textbf{Arduino適合性} \\
        \hline
        CSR形式 & 3--10倍 & 高 & 中 & 高 \\
        \hline
        量子化 & 約4倍 & 高 & 中 & 高 \\
        \hline
        CSR+量子化 & 12--40倍 & 高 & 高 & 高 \\
        \hline
    \end{tabular}
\end{table}

\subsubsection{段階的圧縮アプローチ}
\label{sec:staged_compression}

本研究では，段階的な圧縮アプローチを採用する．
その理由は以下のとおりである．

第一に，圧縮処理は推論精度に影響を与える可能性があるため，必要最小限の圧縮にとどめることが望ましい．
過度な圧縮は精度劣化を招くリスクがあり，圧縮手法を一度に複数適用するよりも，段階的に適用して各段階で精度を確認する方が安全である．

第二に，プルーニングとCSR形式は本質的に連続した処理である．
L1正則化によって重みを疎化し，その結果生じた0要素を効率的に格納するのがCSR形式の役割である．
したがって，この二つを組み合わせた「CSR圧縮」を第一段階として適用するのが自然な流れとなる．

第三に，量子化はCSR形式とは独立に適用可能であり，追加的な圧縮手段として位置づけられる．
CSR圧縮のみでメモリ制約を満たせる場合は量子化を省略でき，さらなる圧縮が必要な場合にのみ追加適用すればよい．

以上の考察に基づき，本研究では次の方針を採る．
まず，L1正則化およびプルーニング後の重み行列をCSR形式に変換し，推論品質への影響を評価する．
CSR圧縮によりMSEが許容範囲内に収まり，かつメモリ制約を満たす場合はそのまま採用する．
一方，さらなるメモリ削減が必要な場合や隠れ層次元の拡張を行う場合には，CSR圧縮モデルに対して量子化を追加適用する．
この段階的なアプローチにより，推論精度とメモリ効率のバランスを最適化することを目指す．

\clearpage
\section{システムの構成}

本章では，実験に用いたシステムのハードウェア構成およびソフトウェア構成について述べる．

\subsection{ハードウェア構成}

本節では，実験で使用した配線および回路構成について述べる．
表\ref{tab:pin_assignment}にArduinoのピン割り当て，表\ref{tab:機材表}に使用機材一覧，図\ref{fig:回路図}に回路図を示す．

\begin{table}[h]
    \centering
    \caption{Arduinoのピン割り当て}
    \label{tab:pin_assignment}
    \begin{tabular}{|c|c|l|}
        \hline
        \textbf{ピン} & \textbf{機能}              & \textbf{説明}                     \\ \hline \hline
        D2           & タクトスイッチ(赤)       & 最大値・最小値の切り替え          \\ \hline
        D3           & タクトスイッチ(青)       & RGBデータの読み取りトリガー       \\ \hline
        A0           & 照度センサー               & フォトトランジスタからのアナログ入力 \\ \hline
    \end{tabular}
\end{table}

\begin{table}[h]
    \centering
    \caption{使用機材一覧}
    \label{tab:機材表}
    \begin{tabular}{|c|c|c|}
        \hline
        機材名 & 型番 & 個数  \\ \hline
        \hline
        炭素皮膜抵抗$330\Omega$ & - & 3  \\ \hline
        炭素皮膜抵抗$3.3k\Omega$ & - & 1  \\ \hline
        炭素皮膜抵抗$10k\Omega$ & - & 2  \\ \hline
        RGBフルカラーLED & OSTA5131A & 1  \\ \hline
        照度センサー(フォトトランジスタ) & NJL7302L-F3 & 1  \\ \hline
        タクトスイッチ(赤・青) & 1273HIM-160G-G & 2  \\ \hline
        ジャンパーワイヤ & BBJ-65 & 13 \\ \hline
        マイコンボード & Arduino UNO R4 WiFi & 1\\ \hline
        ブレッドボード & - & 1 \\ \hline 
    \end{tabular}
\end{table}

\begin{figure}[h]
    \centering
    \includegraphics[width=16cm]{回路図.pdf}
    \caption{回路図}
    \label{fig:回路図}
\end{figure}

\clearpage

\subsection{ソフトウェア構成}

本システムのソフトウェアは，PC上で実行する学習フェーズと，Arduino上で実行するデプロイフェーズの2段階で構成される．
本節では，まずニューラルネットワークの構造を述べた後，各フェーズの処理内容について説明する．

\subsubsection{ニューラルネットワークの構造}
本システムで使用するニューラルネットワークは，RGB色補正を目的とした4層の全結合ネットワークである．
ネットワーク構造の詳細（各層の次元数，活性化関数，推論の数式）については，第3章の表\ref{tab:nn_structure}を参照されたい．

学習フェーズでは，隠れ層1および隠れ層2の次元数を40〜600の範囲で変化させて複数のモデルを訓練した．
デプロイフェーズでは，訓練済みモデルのパラメータをArduinoに組み込み，実機上で推論を実行する．

\subsubsection{学習フェーズ}

学習フェーズでは，PC上でPythonおよびPyTorchを用いてニューラルネットワークの学習を行う．
学習にはJupyter Notebook（\texttt{train\_L1\_normalization.ipynb}）を使用し，以下の処理を実行する．
\begin{enumerate}
    \item データの読み込みと前処理
    \item L1正則化を適用したニューラルネットワークの学習
    \item プルーニングおよびCSR形式への変換（隠れ層1，隠れ層2の重み行列に適用）
    \item Arduinoで読み込み可能なヘッダファイル（\texttt{.h}）の生成
\end{enumerate}

L1正則化により隠れ層1および隠れ層2の重みが疎化され，プルーニング後にCSR形式へ変換することで，メモリ使用量を大幅に削減できる．

\subsubsection{圧縮手法の実装}
\label{sec:compression_implementation}

第\ref{sec:compression_methods}節で述べた圧縮手法に基づき，本システムでは3種類の実装を用意した．

\begin{enumerate}
    \item \textbf{密行列形式（AI\_Model）}：圧縮なし．2次元配列で重み行列を格納し，標準的な行列ベクトル積で順伝播を行う．
    \item \textbf{CSR形式（AI\_CSR）}：プルーニング後にCSR形式へ変換．\texttt{data}，\texttt{indices}，\texttt{indptr}配列を用いて非ゼロ要素のみを計算する．
    \item \textbf{量子化CSR形式（AI\_CSR\_Quantized）}：CSR形式に加えてint8量子化を適用．推論時にスケールファクタで逆量子化を行う．
\end{enumerate}

各実装はArduinoスケッチとして独立したディレクトリ（\texttt{AI\_Model/}，\texttt{AI\_CSR/}，\texttt{AI\_CSR\_Quantized/}）に配置される．

\subsubsection{デプロイフェーズ}

デプロイフェーズでは，学習フェーズで生成したパラメータファイルをArduinoに組み込み，実機上で推論を実行する．
Arduinoコードは，重み行列の格納形式に応じて以下の3種類を用意した．

\begin{itemize}
    \item \texttt{AI\_Model}：密行列形式（非圧縮）のニューラルネットワーク．隠れ層1および隠れ層2の重み行列を通常の2次元配列として格納する．
    \item \texttt{AI\_CSR}：CSR形式で圧縮したニューラルネットワーク．隠れ層1および隠れ層2の重み行列をCSR形式で格納し，メモリ使用量を削減する．
    \item \texttt{AI\_CSR\_Quantized}：CSR形式に量子化を追加適用したニューラルネットワーク．隠れ層1および隠れ層2の重みをint8形式に量子化し，さらなるメモリ削減を実現する．
\end{itemize}

次節では，これらのニューラルネットワークを組み込んだRGB画像読み取りシステムの処理フローについて述べる．


\clearpage

\subsection{RGB画像読み取りシステムの処理フロー}

本節では，Arduinoで動作するRGB画像読み取りシステムの処理フローについて述べる．
本システムでは，RGBセンサーから画素値を逐次読み取り，前節で述べたニューラルネットワークによってRGB値を補正した上で，PPM形式の画像として出力する．

処理は大きく，センサー入出力や画像バッファ管理を行う「共通部分」と，RGB補正を行う「NN部分」の2つに分けられる．
共通部分はニューラルネットワークの格納形式（密行列形式，CSR形式，量子化CSR形式）に依存しない処理であり，NN部分は格納形式に応じた推論処理を実装する．

\subsubsection{共通部分（センサー読み取りと画像バッファ管理）}

共通部分では，RGBセンサーの読み取り，画素値の正規化，NN出力の保存，PPM形式での画像出力などを実装する．
主に以下の5つの関数から構成される．

\paragraph{\texttt{allocateArray}関数}
画像の高さ $N$ と幅方向の要素数 $M$ を引数として受け取り，2次元配列（$N \times M$ の画素バッファ）をヒープ領域に動的確保する（図\ref{fig:scanner_allocateArray}）．
行ポインタの確保に失敗した場合や，途中の行の確保に失敗した場合には，確保済みメモリを解放して\texttt{NULL}を返すことで，メモリ不足に対処する．

\paragraph{\texttt{setup}関数}
シリアル通信の初期化，RGB LEDピンの出力設定および初期消灯，ボタン入力ピンの\texttt{INPUT\_PULLUP}設定，割り込みハンドラの登録を行う（図\ref{fig:scanner_setup}）．
続いてシリアルモニタから画像の高さ（Height）$N$ を読み取り，幅方向の要素数 $M=3N$ を計算し，\texttt{allocateArray}関数により画像バッファを動的確保する．
確保に成功した場合は，全要素を0で初期化する．

\paragraph{\texttt{read}関数}
ループ変数\texttt{count}に応じてR，G，Bの順にLEDを点灯しながらアナログ入力を行う（図\ref{fig:scanner_read}）．
すなわち，\texttt{count==0}のときはRのみ点灯して\texttt{rgb[0]}を読み取り，\texttt{count==1}ではGのみ点灯して\texttt{rgb[1]}を読み取り，それ以外（\texttt{count==2}）ではBのみ点灯して\texttt{rgb[2]}を読み取る．
3色の読み取り後にはすべてのLEDを消灯する．

\paragraph{\texttt{readAndProcess}関数}
まず\texttt{read}関数を呼び出し\texttt{rgb[]}に格納された生のセンサー値を取得し，事前にキャリブレーションされた最小値（\texttt{r\_min}，\texttt{g\_min}，\texttt{b\_min}）と最大値（\texttt{r\_max}，\texttt{g\_max}，\texttt{b\_max}）を用いて0〜1に正規化した入力ベクトル\texttt{RGBInput[3]}を生成する（図\ref{fig:scanner_readAndProcess}）．
続いて\texttt{forward\_rgb}関数を呼び出してニューラルネットワーク推論を行い，補正後のRGB値である\texttt{RGBOutput[3]}を得る．
ここで呼び出される\texttt{forward\_rgb}関数が，入力層から隠れ層1，隠れ層2を経て出力層に至る順伝播計算を実行する．
最後に，出力値を0〜255にクリッピングし，B，R，Gの順でシリアル出力する．

\paragraph{\texttt{loop}関数}
処理を2つに分割して実行する．
1つ目は画素読み取りと保存を行う処理（図\ref{fig:scanner_loop_pixel}），2つ目はMin/Maxキャリブレーションを行う処理（図\ref{fig:scanner_loop_minmax}）である．

画素保存処理では，\texttt{buttonInputPressed}が真のとき，最新の\texttt{RGBOutput}を\texttt{array[n][m..m+2]}に書き込み，列インデックス\texttt{m}を3進める．
行が埋まれば\texttt{n}をインクリメントし，全行の読み取りが完了した場合にはPPM形式で全画素を出力し，\texttt{NVIC\_SystemReset()}によりリセットする．

キャリブレーション処理では，\texttt{buttonMinMaxPressed}が真のとき，変数\texttt{pushed}の偶奇に応じて最小値または最大値を更新する．
最小値は\texttt{rgb[]}そのものを保存し，最大値は\texttt{rgb[]}から最小値を引いた差分として設定する．

\begin{figure}[h]
  \centering
  \includegraphics[width=11cm]{フローチャート/Scanner共通/scanner_allocateArray.png}
  \caption{RGB画像バッファを動的確保する\texttt{allocateArray}関数のフローチャート}
  \label{fig:scanner_allocateArray}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=13cm]{フローチャート/Scanner共通/scanner_setup.png}
    \caption{RGB画像読み取りシステムの\texttt{setup}関数のフローチャート}
    \label{fig:scanner_setup}
  \end{figure}
  
  \begin{figure}[h]
    \centering
    \includegraphics[width=10cm]{フローチャート/Scanner共通/scanner_read.png}
    \caption{\texttt{read}関数（R/G/B順にLED点灯と読み取りを行う）のフローチャート}
    \label{fig:scanner_read}
  \end{figure}
  
  \begin{figure}[h]
    \centering
    \includegraphics[width=11cm]{フローチャート/Scanner共通/scanner_readAndProcess.png}
    \caption{\texttt{readAndProcess}関数（正規化およびNN推論処理）のフローチャート}
    \label{fig:scanner_readAndProcess}
  \end{figure}
  
  \begin{figure}[h]
    \centering
    \includegraphics[width=13cm]{フローチャート/Scanner共通/scanner_loop_pixel.png}
    \caption{\texttt{loop}関数における画素読み取り・保存処理のフローチャート}
    \label{fig:scanner_loop_pixel}
\end{figure}
  
\begin{figure}[h]
    \centering
    \includegraphics[width=11cm]{フローチャート/Scanner共通/scanner_loop_minmax.png}
    \caption{\texttt{loop}関数におけるMin/Maxキャリブレーション処理のフローチャート}
    \label{fig:scanner_loop_minmax}
\end{figure}


\clearpage

\subsubsection{NN部分（ニューラルネットワーク推論）}

NN部分では，共通部分の\texttt{readAndProcess}関数から呼び出される\texttt{forward\_rgb}関数を実装する．
この関数は，正規化されたRGB入力（3次元）を入力層で受け取り，隠れ層1，隠れ層2を経て，出力層から補正されたRGB出力（3次元）を返す．

\texttt{forward\_rgb}関数における順伝播計算の流れは以下のとおりである．
\begin{enumerate}
    \item 入力層（3次元）から隠れ層1への変換：重み行列$W_1$との積とバイアス$b_1$の加算，ReLU活性化
    \item 隠れ層1から隠れ層2への変換：重み行列$W_2$との積とバイアス$b_2$の加算，ReLU活性化
    \item 隠れ層2から出力層（3次元）への変換：重み行列$W_3$との積とバイアス$b_3$の加算，Sigmoid活性化
\end{enumerate}

\texttt{forward\_rgb}関数の実装は，重み行列の格納形式に応じて以下の3種類が存在する．

\paragraph{密行列形式（\texttt{AI\_Model}）}
隠れ層1および隠れ層2の重み行列（$W_1$，$W_2$，$W_3$）を通常の2次元配列として格納し，標準的な行列ベクトル積により順伝播計算を行う（図\ref{fig:nn_dense_forward}）．
実装が単純であるが，メモリ使用量が大きいため，隠れ層の次元拡張に制約がある．

\paragraph{CSR形式（\texttt{AI\_CSR}）}
プルーニングにより疎化された隠れ層1および隠れ層2の重み行列をCSR形式で格納し，非ゼロ要素のみを用いて行列ベクトル積を計算する（図\ref{fig:nn_csr_forward}）．
CSR形式では，値配列（data），列インデックス（indices），行ポインタ（indptr）を用いて疎行列を表現する．
メモリ使用量を削減できるため，より大きな隠れ層次元を扱うことが可能である．

\paragraph{量子化CSR形式（\texttt{AI\_CSR\_Quantized}）}
CSR形式に加えて，隠れ層1および隠れ層2の重みをint8形式に量子化することで，さらなるメモリ削減を実現する（図\ref{fig:nn_quantized_forward}）．
推論時には，各層ごとに保存されたスケール$S$とゼロポイント$Z$を用いて逆量子化を行い，浮動小数点演算に変換して計算する．
量子化による精度劣化を最小限に抑えるため，量子化感知訓練（QAT）を適用することも可能である．


\clearpage

\section{実験方法}

本章では，前章で述べた段階的圧縮アプローチの有効性を検証するために実施した実験について述べる．

\subsection{実験の目的と方針}

本実験の目的は，Arduino Uno R4 WiFiのメモリ制約下において，ニューラルネットワークの隠れ層次元を拡張しつつ，推論精度を維持することである．
具体的には，隠れ層次元を現行の40から600以上へ拡張可能とし，画像復元品質の向上を実現することを目指す．

この目的を達成するため，重み圧縮手法としてCSR（Compressed Sparse Row）形式を第一優先とし，CSR圧縮のみでは不十分な場合にはCSR圧縮モデルに対して量子化を追加適用する方針とした．
L1正則化による重みの疎化を活かすことで，メモリ効率と推論精度のバランスを最適化する．

実験では，隠れ層次元40から開始し，「非圧縮（密行列形式）」「CSR圧縮」「CSR＋量子化」の3種類のモデルについてMSEを比較し，各圧縮手法が推論品質に与える影響を評価する．

\subsection{実験の全体フロー}

本実験は，以下の3つのフェーズから構成される．

\begin{enumerate}
    \item \textbf{訓練・圧縮フェーズ}：PC上でPyTorchを用いてニューラルネットワークを訓練し，CSR形式への変換および量子化を適用してパラメータファイルを生成する
    \item \textbf{デプロイフェーズ}：生成したパラメータファイルをArduino Uno R4 WiFiに組み込み，実機へ書き込む
    \item \textbf{評価フェーズ}：センサーデータを用いて推論を実行し，出力画像と参照画像のMSEを計算して品質を評価する
\end{enumerate}

% 必要に応じて図を追加
% \begin{figure}[h]
%     \centering
%     \includegraphics[width=14cm]{experiment_flow.pdf}
%     \caption{実験の全体フロー}
%     \label{fig:experiment_flow}
% \end{figure}

\subsection{実験条件}

本実験では，隠れ層次元を変化させながら，各圧縮手法の効果を評価した．
表\ref{tab:experiment_conditions}に実験条件を示す．

\begin{table}[h]
    \centering
    \caption{実験条件}
    \label{tab:experiment_conditions}
    \begin{tabular}{|l|l|}
        \hline
        \textbf{項目} & \textbf{設定値} \\
        \hline
        隠れ層次元 & 40, 50, 60, 70, 80, 120, 160, 200, 400, 600 \\
        \hline
        プルーニング閾値 & 0.01（固定） \\
        \hline
        正則化 & L1正則化（係数: $1 \times 10^{-6}$） \\
        \hline
        学習エポック数 & 50000 \\
        \hline
        最適化手法 & Adam（学習率: 0.01） \\
        \hline
        疎行列形式 & CSR形式 \\
        \hline
        量子化 & int8（必要に応じて適用） \\
        \hline
    \end{tabular}
\end{table}

プルーニング閾値を0.01に固定した理由は，予備実験において精度と圧縮率のバランスが良好であったためである．
また，L1正則化係数を$1 \times 10^{-6}$としたのは，重みの疎化を促進しつつ学習の収束性を維持するためである．


\subsection{実験手順}

\subsubsection{モデルの学習とパラメータ生成}

モデルの学習およびパラメータ生成は，Jupyter Notebook（\texttt{train\_L1\_normalization.ipynb}）を用いて実施した．
以下に各ステップの詳細を示す．


\paragraph{ステップ1：環境セットアップとデータ準備}
まず，PyTorch，NumPy，Matplotlib等の必要なライブラリをインストールし，\texttt{cv2}，\texttt{torch}，\texttt{numpy}等をインポートした．

次に，PPM形式のカラーチャート画像を読み込み，参照画像（3$\times$3および6$\times$6のカラーチャート）を準備した．
推論用データ（$X$）と正解データ（$Y$）は0〜1の範囲に正規化し，\texttt{formatted\_arrays.txt}として保存した．

\paragraph{ステップ2：ニューラルネットワークの学習}
第3章で述べた4層全結合ニューラルネットワークを，L1正則化を適用して学習した．

学習パラメータは表\ref{tab:training_params}のとおりである．

\begin{table}[h]
    \centering
    \caption{学習パラメータ}
    \label{tab:training_params}
    \begin{tabular}{|l|l|}
        \hline
        \textbf{項目} & \textbf{設定値} \\
        \hline
        損失関数 & MSE + L1正則化 \\
        \hline
        L1正則化係数 & $1 \times 10^{-6}$ \\
        \hline
        最適化手法 & Adam \\
        \hline
        学習率 & 0.01 \\
        \hline
        エポック数 & 50000 \\
        \hline
        進捗表示間隔 & 500エポックごと \\
        \hline
    \end{tabular}
\end{table}

本実験では，隠れ層次元（\texttt{HIDDEN\_DIM}）を40, 50, 60, 70, 80, 120, 160, 200, 400, 600と変化させて複数のモデルを学習した．
学習完了後，密行列形式のパラメータファイル（\texttt{model\_parameters.h}）が自動生成される．
このファイルには全層の重みとバイアスがC++配列として出力され，圧縮なしのベースラインモデルとして使用する．


\paragraph{ステップ3：CSR形式への変換}
学習済みモデルに対し，プルーニング閾値0.01でプルーニングを実施した後，重み行列をCSR形式に変換した．
CSR形式への変換は，隠れ層1の重み行列（入力層$\rightarrow$隠れ層1）および隠れ層2の重み行列（隠れ層1$\rightarrow$隠れ層2）に対して適用した．

変換処理は以下の手順で実施した．
\begin{enumerate}
    \item 重み行列を取得し，絶対値が0.01未満の要素を0に設定（プルーニング）
    \item 非ゼロ要素を抽出し，CSR形式の3つの配列に変換：
    \begin{itemize}
        \item \texttt{data}：非ゼロ要素の値配列（float32）
        \item \texttt{indices}：列インデックス配列（uint16\_t）
        \item \texttt{indptr}：行ポインタ配列（uint16\_t）
    \end{itemize}
    \item スパース性（非ゼロ率）と圧縮率を算出
\end{enumerate}

変換後のパラメータは，各隠れ層次元に応じて\texttt{model\_parameters\_csr40.h}，\texttt{model\_parameters\_csr80.h}等のファイル名で出力した．

\paragraph{ステップ4：量子化の適用（オプション）}
CSR圧縮のみではメモリ制約を満たせない場合，CSR形式のパラメータに対してint8量子化を追加適用した．

量子化処理は以下の手順で実施した．
\begin{enumerate}
    \item CSR形式の値配列（\texttt{data}）に対してスケールファクタを計算：
    \begin{equation}
        \text{scale} = \frac{127.0}{\max(|\texttt{data}|)}
    \end{equation}
    \item 各要素を量子化し，$-128$〜$127$の範囲にクリッピング：
    \begin{equation}
        \texttt{quantized} = \text{clip}(\text{round}(\texttt{data} \times \text{scale}), -128, 127)
    \end{equation}
    \item 逆量子化誤差を算出して精度劣化を確認
\end{enumerate}

量子化は隠れ層1および隠れ層2の重み行列に対して，各層ごとに独立したスケールファクタを用いて適用した．
量子化後のパラメータは，\texttt{model\_parameters\_csr\_quantized40.h}等のファイル名で出力した．

\paragraph{次元変更時の手順}
異なる次元で実験する場合は，以下の手順を実行した．
\begin{enumerate}
    \item Jupyter Notebookで\texttt{HIDDEN\_DIM}を変更
    \item 学習を実行し，密行列形式パラメータを生成
    \item CSR変換を実行し，CSR形式パラメータを生成
    \item 必要に応じて量子化を適用
    \item 生成ファイルをArduinoプロジェクトにコピー
    \item Arduinoコードの\texttt{HIDDEN\_DIM}を同じ値に設定
\end{enumerate}

\clearpage

\subsubsection{Arduinoへのデプロイ}

生成したパラメータファイルをArduinoプロジェクトに組み込み，実機へ書き込みを行った．

\paragraph{ステップ1：パラメータファイルの配置}
生成されたパラメータファイルを，表\ref{tab:parameter_files}に示す対応するArduinoプロジェクトフォルダにコピーした．

\begin{table}[h]
    \centering
    \caption{パラメータファイルの配置}
    \label{tab:parameter_files}
    \begin{tabular}{|l|l|l|}
        \hline
        \textbf{生成ファイル} & \textbf{コピー先} & \textbf{用途} \\
        \hline
        \texttt{model\_parameters*.h} & \texttt{Arduino/AI\_Model/} & 密行列形式 \\
        \hline
        \texttt{model\_parameters\_csr*.h} & \texttt{Arduino/AI\_CSR/} & CSR形式 \\
        \hline
        \texttt{model\_parameters\_csr\_quantized*.h} & \texttt{Arduino/AI\_CSR\_Quantized/} & CSR+量子化 \\
        \hline
    \end{tabular}
\end{table}

\paragraph{ステップ2：Arduinoコードの設定}
各Arduinoプロジェクト内の\texttt{.ino}ファイルにおいて，\texttt{HIDDEN\_DIM}マクロを学習時と同一の値に設定し，対応するパラメータファイルをインクルードした．

\begin{lstlisting}[language=C, caption=Arduinoコードの設定例（80次元の場合）]
#define HIDDEN_DIM 80  // 学習時と同じ値に設定
#include "model_parameters_csr80.h"  // 対応するファイルをインクルード
\end{lstlisting}

\texttt{HIDDEN\_DIM}の値とパラメータファイルの次元が一致していない場合，正常に動作しないため注意が必要である．

\paragraph{ステップ3：コンパイルとアップロード}
Arduino IDEを用いて，ボード設定を「Arduino UNO R4 WiFi」に設定し，コンパイル・アップロードを行った．
コンパイル時に表示されるSRAM使用量が32\,KBを超える場合はアップロードに失敗するため，その場合はより高い圧縮率の手法を適用する必要がある．

\clearpage
\subsubsection{スキャン実行とデータ取得}

Arduinoに接続したRGBカラーセンサを用いて参照画像をスキャンし，推論結果をPPM形式の画像ファイルとして出力した．

\paragraph{ステップ1：キャリブレーション}
センサの感度は環境光や個体差により変動するため，測定前にキャリブレーションを行った．
2つのタクトスイッチを用いて，黒色サンプルで最小値を，白色サンプルで最大値を記録し，これらを基準として読み取り範囲を正規化した．

\paragraph{ステップ2：カラーチャートの読み取り}
キャリブレーション完了後，3$\times$3のカラーチャートを1セルずつセンサで読み取った．
取得したRGB値はニューラルネットワークによる推論を経て補正され，全9セルの読み取りが完了するまで繰り返した．

\paragraph{ステップ3：PPM画像の出力}
取得したRGBデータは，シリアル通信を介してPC上のスキャナプログラム（\texttt{scanner.c}）に送信され，PPM形式の画像ファイルとして出力された．
出力ファイルは実験条件ごとにフォルダを分けて保存し，各条件につき10回程度のスキャンを実施した．


\subsection{評価方法}

推論精度の評価指標として，第2章で定義した平均二乗誤差（MSE）を用いた（式\ref{eq:mse_definition}，式\ref{eq:mse_rgb}参照）．
MSEの値が小さいほど，参照画像との差異が少なく，色補正の精度が高いことを示す．

評価には自作のMSE計算ツール（\texttt{mse\_calculator.html}）を使用した．
このツールはブラウザ上で動作し，参照画像とスキャン結果のPPMファイルをドラッグ＆ドロップすることでMSEを算出できる．
各実験条件のすべてのスキャン結果についてMSEを算出し，平均値・最小値・最大値を求めた．

\subsection{比較対象}

本実験では，以下の3種類のモデルを比較対象とした．

\begin{enumerate}
    \item \textbf{密行列形式（非圧縮）}：L1正則化のみを適用し，圧縮処理を行わないベースラインモデル
    \item \textbf{CSR圧縮}：プルーニング後にCSR形式へ変換したモデル（隠れ層1および隠れ層2に適用）
    \item \textbf{CSR＋量子化}：CSR圧縮に加えてint8量子化を適用したモデル（隠れ層1および隠れ層2に適用）
\end{enumerate}

これらのモデルについて，各隠れ層次元におけるMSEとメモリ使用量を比較し，段階的圧縮アプローチの有効性を検証した．
最終的な目標は，MSEを許容範囲内に抑えつつ，隠れ層次元を600以上へ拡張可能とすることである．

\clearpage

\section{実験結果}

本章では，前章で述べた実験方法に基づいて実施した実験の結果を示す．

\subsection{MSE測定結果}

各圧縮手法および隠れ層次元におけるMSE測定結果を表\ref{tab:results_mse_comparison}に示す．

\begin{table}[h]
    \centering
    \caption{圧縮手法別MSE比較}
    \label{tab:results_mse_comparison}
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{圧縮手法} & \textbf{隠れ層次元} & \textbf{MSE最小値} & \textbf{MSE最大値} & \textbf{MSE平均値} \\
        \hline
        \hline
        \multicolumn{5}{|c|}{\textbf{非圧縮（密行列形式）}} \\
        \hline
        密行列形式 & 40 & 277.67 & 792.85 & 595.95 \\
        \hline
        密行列形式 & 50 & 231.11 & 535.59 & 406.93 \\
        \hline
        密行列形式 & 60 & 138.00 & 423.22 & 305.48 \\
        \hline
        密行列形式 & 70 & コンパイルエラー & コンパイルエラー & コンパイルエラー \\
        \hline
        \multicolumn{5}{|c|}{\textbf{CSR圧縮}} \\
        \hline
        CSR圧縮 & 40 & 324.00 & 692.37 & 518.58 \\
        \hline
        CSR圧縮 & 80 & 225.19 & 729.26 & 464.86 \\
        \hline
        CSR圧縮 & 120 & 295.37 & 814.33 & 620.49 \\
        \hline
        CSR圧縮 & 160 & 295.52 & 1179.59 & 589.08 \\
        \hline
        CSR圧縮 & 200 & 291.41 & 979.85 & 493.35 \\
        \hline
        CSR圧縮 & 400 & 390.89 & 1978.81 & 864.40 \\
        \hline
        CSR圧縮 & 600 & 253.44 & 2143.81 & 670.69 \\
        \hline
        CSR圧縮 & 800 & コンパイルエラー & コンパイルエラー & コンパイルエラー \\
        \hline
        \multicolumn{5}{|c|}{\textbf{CSR＋量子化}} \\
        \hline
        CSR＋量子化 & 40 & 278.78 & 588.15 & 408.97 \\
        \hline
        CSR＋量子化 & 80 & 200.22 & 323.96 & 270.68 \\
        \hline
        CSR＋量子化 & 120 & 169.37 & 310.63 & 244.83 \\
        \hline
        CSR＋量子化 & 160 & -- & -- & -- \\
        \hline
        CSR＋量子化 & 200 & -- & -- & -- \\
        \hline
        CSR＋量子化 & 400 & -- & -- & -- \\
        \hline
        CSR＋量子化 & 600 & -- & -- & -- \\
        \hline
        CSR＋量子化 & 800 & コンパイルエラー & コンパイルエラー & コンパイルエラー \\
        \hline
    \end{tabular}
\end{table}

また，同一次元における圧縮手法間の比較を容易にするため，表\ref{tab:results_by_dimension}に隠れ層次元別の結果を示す．

\begin{table}[h]
    \centering
    \caption{隠れ層次元別MSE比較（平均値）}
    \label{tab:results_by_dimension}
    \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{隠れ層次元} & \textbf{非圧縮} & \textbf{CSR圧縮} & \textbf{CSR＋量子化} \\
        \hline
        40 & 595.95 & 518.58 & 408.97 \\
        \hline
        50 & 406.93 & -- & -- \\
        \hline
        60 & 305.48 & -- & -- \\
        \hline
        70 & コンパイルエラー & -- & -- \\
        \hline
        80 & コンパイルエラー & 464.86 & 270.68 \\
        \hline
        120 & コンパイルエラー & 620.49 & 244.83 \\
        \hline
        160 & コンパイルエラー & 589.08 & -- \\
        \hline
        200 & コンパイルエラー & 493.35 & -- \\
        \hline
        400 & コンパイルエラー & 864.40 & -- \\
        \hline
        600 & コンパイルエラー & 670.69 & -- \\
        \hline
        800 & コンパイルエラー & コンパイルエラー & コンパイルエラー \\
        \hline
    \end{tabular}
\end{table}

\subsection{コンパイル時間とメモリ使用量}

各条件におけるArduinoのコンパイル時間とメモリ使用量を表\ref{tab:results_compile_memory}に示す．

\begin{table}[h]
    \centering
    \caption{コンパイル時間とメモリ使用量}
    \label{tab:results_compile_memory}
    \begin{tabular}{|l|c|c|c|}
        \hline
        \textbf{圧縮手法} & \textbf{隠れ層次元} & \textbf{コンパイル時間} & \textbf{メモリ使用量} \\
        \hline
        \hline
        \multicolumn{4}{|c|}{\textbf{非圧縮（密行列形式）}} \\
        \hline
        密行列形式 & 40 & 4.303s & 14524バイト（44\%） \\
        \hline
        密行列形式 & 50 & 4.589s & 18444バイト（56\%） \\
        \hline
        密行列形式 & 60 & 4.831s & 23164バイト（70\%） \\
        \hline
        密行列形式 & 70 & コンパイルエラー & コンパイルエラー \\
        \hline
        \multicolumn{4}{|c|}{\textbf{CSR圧縮}} \\
        \hline
        CSR圧縮 & 40 & 3.783s & 8488バイト（25\%） \\
        \hline
        CSR圧縮 & 80 & 4.037s & 9508バイト（29\%） \\
        \hline
        CSR圧縮 & 120 & 4.062s & 10520バイト（32\%） \\
        \hline
        CSR圧縮 & 160 & 4.042s & 11332バイト（34\%） \\
        \hline
        CSR圧縮 & 200 & 4.027s & 12332バイト（37\%） \\
        \hline
        CSR圧縮 & 400 & 4.316s & 17204バイト（52\%） \\
        \hline
        CSR圧縮 & 600 & 4.802s & 21976バイト（67\%） \\
        \hline
        CSR圧縮 & 800 & コンパイルエラー & コンパイルエラー \\
        \hline
        \multicolumn{4}{|c|}{\textbf{CSR＋量子化}} \\
        \hline
        CSR＋量子化 & 40 & 3.772s & 8160バイト（24\%） \\
        \hline
        CSR＋量子化 & 80 & 3.809s & 9148バイト（27\%） \\
        \hline
        CSR＋量子化 & 120 & 4.028s & 10132バイト（30\%） \\
        \hline
        CSR＋量子化 & 160 & 4.033s & 12000バイト（36\%） \\
        \hline
        CSR＋量子化 & 200 & 4.033s & 12000バイト（36\%） \\
        \hline
        CSR＋量子化 & 400 & 4.307s & 16836バイト（51\%） \\
        \hline
        CSR＋量子化 & 600 & 4.801s & 21684バイト（66\%） \\
        \hline
        CSR＋量子化 & 800 & コンパイルエラー & コンパイルエラー \\
        \hline
    \end{tabular}
\end{table}



\subsection{詳細データ}

以下に，各実験条件における個別のスキャン結果を示す．

\subsubsection{非圧縮（密行列形式）}

表\ref{tab:results_dense_detail_40}に，密行列形式（40次元）の詳細な測定結果を示す．

\begin{table}[h]
    \centering
    \caption{密行列形式（40次元）の詳細測定結果}
    \label{tab:results_dense_detail_40}
    \begin{tabular}{|c|c||c|c|}
        \hline
        \textbf{ファイル} & \textbf{MSE} & \textbf{ファイル} & \textbf{MSE} \\
        \hline
        nn1.ppm & 484.04 & nn6.ppm & 715.63 \\
        \hline
        nn2.ppm & 713.74 & nn7.ppm & 523.63 \\
        \hline
        nn3.ppm & 733.93 & nn8.ppm & 792.85 \\
        \hline
        nn4.ppm & 277.67 & nn9.ppm & 284.15 \\
        \hline
        nn5.ppm & 782.33 & nn10.ppm & 651.52 \\
        \hline
    \end{tabular}
\end{table}

表\ref{tab:results_dense_detail_50}に，密行列形式（50次元）の詳細な測定結果を示す．

\begin{table}[h]
    \centering
    \caption{密行列形式（50次元）の詳細測定結果}
    \label{tab:results_dense_detail_50}
    \begin{tabular}{|c|c||c|c|}
        \hline
        \textbf{ファイル} & \textbf{MSE} & \textbf{ファイル} & \textbf{MSE} \\
        \hline
        nn50\_1.ppm & 369.30 & nn50\_6.ppm & 231.11 \\
        \hline
        nn50\_2.ppm & 486.26 & nn50\_7.ppm & 463.85 \\
        \hline
        nn50\_3.ppm & 444.11 & nn50\_8.ppm & 307.26 \\
        \hline
        nn50\_4.ppm & 472.78 & nn50\_9.ppm & 342.67 \\
        \hline
        nn50\_5.ppm & 416.04 & nn50\_10.ppm & 535.59 \\
        \hline
    \end{tabular}
\end{table}

表\ref{tab:results_dense_detail_60}に，密行列形式（60次元）の詳細な測定結果を示す．

\begin{table}[h]
    \centering
    \caption{密行列形式（60次元）の詳細測定結果}
    \label{tab:results_dense_detail_60}
    \begin{tabular}{|c|c||c|c|}
        \hline
        \textbf{ファイル} & \textbf{MSE} & \textbf{ファイル} & \textbf{MSE} \\
        \hline
        nn60\_1.ppm & 193.07 & nn60\_6.ppm & 332.41 \\
        \hline
        nn60\_2.ppm & 138.00 & nn60\_7.ppm & 297.22 \\
        \hline
        nn60\_3.ppm & 376.22 & nn60\_8.ppm & 417.44 \\
        \hline
        nn60\_4.ppm & 227.26 & nn60\_9.ppm & 240.33 \\
        \hline
        nn60\_5.ppm & 423.22 & nn60.ppm & 409.30 \\
        \hline
    \end{tabular}
\end{table}

\subsubsection{CSR圧縮}

表\ref{tab:results_csr_detail}に，CSR圧縮モデルの詳細な測定結果を示す．

\begin{table}[h]
    \centering
    \caption{CSR圧縮の詳細測定結果}
    \label{tab:results_csr_detail}
    \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{次元} & \textbf{ファイル} & \textbf{MSE} & \textbf{備考} \\
        \hline
        \hline
        \multirow{10}{*}{40} & csr1.ppm & 600.00 & \multirow{10}{*}{測定完了} \\
        \cline{2-3}
        & csr2.ppm & 517.48 & \\
        \cline{2-3}
        & csr3.ppm & 569.78 & \\
        \cline{2-3}
        & csr4.ppm & 659.04 & \\
        \cline{2-3}
        & csr5.ppm & 324.00 & \\
        \cline{2-3}
        & csr6.ppm & 365.07 & \\
        \cline{2-3}
        & csr7.ppm & 522.59 & \\
        \cline{2-3}
        & csr8.ppm & 495.04 & \\
        \cline{2-3}
        & csr9.ppm & 692.37 & \\
        \cline{2-3}
        & csr10.ppm & 440.41 & \\
        \hline
        \hline
        \multirow{10}{*}{80} & 1.ppm & 644.59 & \multirow{10}{*}{測定完了} \\
        \cline{2-3}
        & 2.ppm & 459.37 & \\
        \cline{2-3}
        & 3.ppm & 361.33 & \\
        \cline{2-3}
        & 4.ppm & 225.19 & \\
        \cline{2-3}
        & 5.ppm & 729.26 & \\
        \cline{2-3}
        & 6.ppm & 408.15 & \\
        \cline{2-3}
        & 7.ppm & 380.59 & \\
        \cline{2-3}
        & 8.ppm & 499.85 & \\
        \cline{2-3}
        & 9.ppm & 437.44 & \\
        \cline{2-3}
        & 10.ppm & 472.85 & \\
        \hline
        \hline
        \multirow{10}{*}{120} & 1.ppm & 724.67 & \multirow{10}{*}{測定完了} \\
        \cline{2-3}
        & 2.ppm & 295.37 & \\
        \cline{2-3}
        & 3.ppm & 663.78 & \\
        \cline{2-3}
        & 4.ppm & 514.59 & \\
        \cline{2-3}
        & 5.ppm & 694.22 & \\
        \cline{2-3}
        & 6.ppm & 710.96 & \\
        \cline{2-3}
        & 7.ppm & 656.44 & \\
        \cline{2-3}
        & 8.ppm & 584.59 & \\
        \cline{2-3}
        & 9.ppm & 814.33 & \\
        \cline{2-3}
        & 10.ppm & 545.93 & \\
        \hline
        \hline
        \multirow{10}{*}{160} & 1.ppm & 394.30 & \multirow{10}{*}{測定完了} \\
        \cline{2-3}
        & 2.ppm & 516.96 & \\
        \cline{2-3}
        & 3.ppm & 663.78 & \\
        \cline{2-3}
        & 4.ppm & 668.63 & \\
        \cline{2-3}
        & 5.ppm & 1179.59 & \\
        \cline{2-3}
        & 6.ppm & 353.07 & \\
        \cline{2-3}
        & 7.ppm & 686.56 & \\
        \cline{2-3}
        & 8.ppm & 295.52 & \\
        \cline{2-3}
        & 9.ppm & 434.04 & \\
        \cline{2-3}
        & 10.ppm & 698.33 & \\
        \hline
        \hline
        \multirow{10}{*}{200} & 1.ppm & 563.52 & \multirow{10}{*}{測定完了} \\
        \cline{2-3}
        & 2.ppm & 291.41 & \\
        \cline{2-3}
        & 3.ppm & 235.52 & \\
        \cline{2-3}
        & 4.ppm & 675.11 & \\
        \cline{2-3}
        & 5.ppm & 662.07 & \\
        \cline{2-3}
        & 6.ppm & 714.96 & \\
        \cline{2-3}
        & 7.ppm & 678.93 & \\
        \cline{2-3}
        & 8.ppm & 462.56 & \\
        \cline{2-3}
        & 9.ppm & 979.85 & \\
        \cline{2-3}
        & 10.ppm & 331.59 & \\
        \hline
        \hline
        \multirow{10}{*}{400} & 1.ppm & 390.89 & \multirow{10}{*}{測定完了} \\
        \cline{2-3}
        & 2.ppm & 736.11 & \\
        \cline{2-3}
        & 3.ppm & 701.15 & \\
        \cline{2-3}
        & 4.ppm & 324.52 & \\
        \cline{2-3}
        & 5.ppm & 616.00 & \\
        \cline{2-3}
        & 6.ppm & 1127.33 & \\
        \cline{2-3}
        & 7.ppm & 421.78 & \\
        \cline{2-3}
        & 8.ppm & 1913.30 & \\
        \cline{2-3}
        & 9.ppm & 1978.81 & \\
        \cline{2-3}
        & 10.ppm & 434.30 & \\
        \hline
        \hline
        \multirow{10}{*}{600} & 1.ppm & 740.33 & \multirow{10}{*}{測定完了} \\
        \cline{2-3}
        & 2.ppm & 1427.52 & \\
        \cline{2-3}
        & 3.ppm & 2143.81 & \\
        \cline{2-3}
        & 4.ppm & 285.26 & \\
        \cline{2-3}
        & 5.ppm & 253.44 & \\
        \cline{2-3}
        & 6.ppm & 258.63 & \\
        \cline{2-3}
        & 7.ppm & 292.15 & \\
        \cline{2-3}
        & 8.ppm & 384.85 & \\
        \cline{2-3}
        & 9.ppm & 326.15 & \\
        \cline{2-3}
        & 10.ppm & 594.78 & \\
        \hline
        \hline
        800 & -- & -- & コンパイルエラー \\
        \hline
    \end{tabular}
\end{table}

\subsubsection{CSR＋量子化}

表\ref{tab:results_quantized_detail}に，CSR＋量子化モデルの詳細な測定結果を示す．

\begin{table}[h]
    \centering
    \caption{CSR＋量子化の詳細測定結果}
    \label{tab:results_quantized_detail}
    \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{次元} & \textbf{ファイル} & \textbf{MSE} & \textbf{備考} \\
        \hline
        \hline
        \multirow{10}{*}{40} & q1.ppm & 289.30 & \multirow{10}{*}{測定完了} \\
        \cline{2-3}
        & q2.ppm & 304.44 & \\
        \cline{2-3}
        & q3.ppm & 381.19 & \\
        \cline{2-3}
        & q4.ppm & 588.15 & \\
        \cline{2-3}
        & q5.ppm & 278.78 & \\
        \cline{2-3}
        & q6.ppm & 471.30 & \\
        \cline{2-3}
        & q7.ppm & 582.63 & \\
        \cline{2-3}
        & q8.ppm & 324.44 & \\
        \cline{2-3}
        & q9.ppm & 321.37 & \\
        \cline{2-3}
        & q10.ppm & 548.11 & \\
        \hline
        \hline
        \multirow{10}{*}{80} & q1.ppm & 235.74 & \multirow{10}{*}{測定完了} \\
        \cline{2-3}
        & q2.ppm & 237.63 & \\
        \cline{2-3}
        & q3.ppm & 200.22 & \\
        \cline{2-3}
        & q4.ppm & 292.22 & \\
        \cline{2-3}
        & q5.ppm & 282.70 & \\
        \cline{2-3}
        & q6.ppm & 268.26 & \\
        \cline{2-3}
        & q7.ppm & 323.96 & \\
        \cline{2-3}
        & q8.ppm & 270.19 & \\
        \cline{2-3}
        & q9.ppm & 313.37 & \\
        \cline{2-3}
        & q10.ppm & 282.48 & \\
        \hline
        \hline
        \multirow{10}{*}{120} & q1.ppm & 297.70 & \multirow{10}{*}{測定完了} \\
        \cline{2-3}
        & q2.ppm & 180.11 & \\
        \cline{2-3}
        & q3.ppm & 239.15 & \\
        \cline{2-3}
        & q4.ppm & 310.63 & \\
        \cline{2-3}
        & q5.ppm & 309.41 & \\
        \cline{2-3}
        & q6.ppm & 169.37 & \\
        \cline{2-3}
        & q7.ppm & 228.59 & \\
        \cline{2-3}
        & q8.ppm & 257.85 & \\
        \cline{2-3}
        & q9.ppm & 196.19 & \\
        \cline{2-3}
        & q10.ppm & 259.30 & \\
        \hline
        160 & -- & -- & 測定未実施 \\
        \hline
        200 & -- & -- & 測定未実施 \\
        \hline
        400 & -- & -- & 測定未実施 \\
        \hline
        600 & -- & -- & 測定未実施 \\
        \hline
        800 & -- & -- & コンパイルエラー \\
        \hline
    \end{tabular}
\end{table}

\subsection{結果のまとめ}

現時点で得られた実験結果をまとめると，以下のとおりである．

\begin{enumerate}
    \item 非圧縮（密行列形式）では，40次元でMSE平均値730.13，50次元で406.93，60次元で305.48と，次元を増やすほど精度が向上したが，70次元ではメモリ不足によりコンパイルエラーが発生した．
    \item CSR圧縮（40次元）のMSE平均値は518.58であり，非圧縮（40次元）の730.13と比較して約29\%改善した．
    \item CSR圧縮（80次元）のMSE平均値は464.86であり，非圧縮（40次元）と比較して約36\%改善した．
    \item CSR圧縮により，隠れ層次元を600次元まで拡張してもArduino Uno R4 WiFiのメモリ制約内で動作可能であった（メモリ使用量67\%）．
    \item CSR＋量子化により，さらにメモリ効率が向上し，600次元でもメモリ使用量66\%で動作可能であった．
    \item CSR圧縮（120次元以上）およびCSR＋量子化モデルについては，MSE測定を実施予定である．
\end{enumerate}

これらの結果から，CSR形式による圧縮は推論精度を維持しつつ隠れ層次元の拡張を可能にする有効な手法であることが示唆される．
詳細な考察は次章で述べる．

\clearpage
\begin{thebibliography}{9}
\bibitem{jacob2018quantization} B. Jacob et al., ``Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference,'' CVPR, 2018.
\bibitem{han2015deep} Song Han et al., ``Learning both Weights and Connections for Efficient Neural Networks,'' NeurIPS, 2015.
\end{thebibliography}


\end{document}