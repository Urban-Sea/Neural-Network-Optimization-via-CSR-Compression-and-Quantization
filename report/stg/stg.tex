\documentclass[a4paper,12pt]{jsarticle}  % 日本語論文向け（uplatex推奨）

% 基本エンコーディング・フォント
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

% 日本語対応（uplatex + dvipdfmx用）
\usepackage{japanese}
\usepackage[dvipdfmx]{pxjahyper}

% ページ設定
\usepackage{geometry}
\geometry{a4paper, margin=1in}

% 数学・数式
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}

% 表・列制御
\usepackage{booktabs}
\usepackage{array}
\usepackage{longtable}
\usepackage{multirow}
\usepackage{colortbl}

% 図・キャプション
\usepackage[dvipdfmx]{graphicx}
\usepackage{caption}
\usepackage{subcaption}

% アルゴリズム
\usepackage{algorithm}
\usepackage{algorithmic}

% ハイパーリンク
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=red,
    urlcolor=green
}

% コードハイライト
\usepackage{listings}
\lstset{
  language=Python,
  basicstyle=\small\ttfamily,
  breaklines=true,
  columns=fixed,
  keepspaces=true,
  showstringspaces=false,
  frame=single,
  numbers=left,
  numberstyle=\tiny,
  captionpos=b
}

\begin{document}

\title{2025年度　アジャイルワーク 報告書}
\author{24G1089　武本 龍}
\maketitle

\section{はじめに}
近年、ディープラーニングをはじめとするAI技術は急速に発展しており、その学習や推論には大規模な計算資源や電力を必要とすることが一般的となっている。
しかし、組込み機器やIoTデバイスのような小型環境では、CPU性能やメモリ容量、電力供給といったリソースが大幅に制限されるため、
従来の手法をそのまま適用することは困難である。
そこで本研究では、既存のArduino Uno R4 WiFi環境において可能な限り高性能なニューラルネットワーク推論を実現することを目的とし、
学習データの軽量化やモデルの圧縮を含む最適化手法を検討し、特に、学習データを圧縮した上で推論に必要な情報を保持できるか、
また限られた計算能力の中で最大限の推論精度を引き出せるかを検証し、その実験手法および得られた知見について報告する。

\section{実験の概要}
図\ref{fig:実験概要}に，本実験の全体構成を示す．

\begin{figure}[h]
    \centering
    \includegraphics[width=16cm]{実験概要.jpg}
    \caption{実験の全体構成}
    \label{fig:実験概要}
\end{figure}
\clearpage
本実験では，Arduino Uno R4 WiFiを用いてカラーセンサーを構築し，授業内で配布された$3 \times 3$のカラーチャートを測定する．
測定後，ニューラルネットワークを用いた補正処理により，平均二乗誤差（MSE）の低減を目指す．
前章で述べた2つの検証項目に対応し，本実験では以下の観点から評価を行う．

第一の検証として，ニューラルネットワークのパラメータ圧縮によるメモリ効率の改善を検討する．
具体的には，隠れ層のデータ圧縮手法を導入し，推論に必要な情報を保持しながらメモリ使用量をどの程度削減できるかを評価する．

第二の検証として，限られた計算資源の中での推論性能の最大化を検討する．
測定したカラーチャートと基準カラーチャート間のMSEを評価指標とし，ニューラルネットワークによる学習を活用して推論精度の向上を図る．
また，predict関数の処理時間を計測し，実行速度についても評価する．

\subsection{平均二乗誤差（MSE）}
平均二乗誤差（MSE）は，2枚の画像の対応するピクセル位置における輝度差の2乗の平均値として定義され，以下の式で表される．
\begin{equation}
\text{MSE} = \frac{1}{m \times n} \sum_{i=1}^{m} \sum_{j=1}^{n} \left( I(i,j) - K(i,j) \right)^2
\end{equation}
ここで，$I$と$K$は比較対象となる2枚の画像，$m \times n$は画像サイズを表す．

本実験ではRGB画像を扱うため，各ピクセルについてR，G，Bチャネルごとの差の2乗を加算し，チャネル数で除した値をMSEとして算出する．
具体的な計算式を以下に示す：
\begin{equation}
\text{MSE} = \frac{(r_{\text{diff}})^2 + (g_{\text{diff}})^2 + (b_{\text{diff}})^2}{3}
\end{equation}
\clearpage


\clearpage
\section{実験理論}
本章では，ニューラルネットワークを用いた読み込み品質の改善手法について述べる．

\subsection{ニューラルネットワークによる品質改善}
サンプル画像と測定画像との誤差を最小化するため，本研究ではニューラルネットワークを用いた学習手法を導入する．
特に，低リソース環境であるArduino上での推論実行を前提とし，モデルの圧縮および疎化手法を併用しながら性能の最適化を図る．

\subsubsection{ネットワーク構造}
本実験で採用したモデルは，全結合型（Fully Connected）の4層ニューラルネットワークである．
入力層はRGBの3次元，2つの隠れ層はそれぞれ40次元（40個のニューロンが全結合），出力層は再びRGBの3次元とした．
各ニューロンにおける推論は以下の式で表される．
\begin{equation}
y = x_1 w_1 + x_2 w_2 + \cdots + x_{n-1} w_{n-1} + b
\end{equation}
ここで，$w_i$は重み，$b$はバイアスを表す．
算出された値はReLU活性化関数を通過し，次層へ伝搬される．

モデルはPyTorchにより定義・訓練し，L1正則化を導入して重みの疎化を促進した．
訓練後の重みおよびバイアスはC++配列としてエクスポートし，Arduino上で実行可能な形式に変換した．
さらに，本研究では隠れ層の次元拡張性を検証するため，40次元に加えて80次元，120次元のモデルについても実験を行った．

\subsection{隠れ層の圧縮手法}

\subsubsection{圧縮の必要性}
Arduino Uno R4 WiFiのようなマイクロコントローラでは，利用可能なメモリ（SRAM約32\,KB，Flash 256\,KB）が極めて限定的である．
隠れ層の次元を増加させると，重みおよびバイアスの格納や推論演算に必要なメモリが不足する可能性が高い．

例えば，隠れ層次元を40から70以上に拡張するとパラメータ総数は急増する．
\begin{itemize}
    \item 40次元：約1,923パラメータ
    \item 70次元：約3,000パラメータ以上
\end{itemize}
float32形式では10\,KBを超える場合，Arduino上での動作が困難となる．
したがって，隠れ層の次元を拡張しながら高い推論性能を維持するには，重みデータの圧縮が不可欠である．

\subsubsection{圧縮手法の概観}
ニューラルネットワークの圧縮手法は多岐にわたるが，本研究のようなマイクロコントローラ環境では，実装の複雑さと圧縮効果のバランスが重要となる．
代表的な手法として，プルーニング（枝刈り），疎行列表現（CSR形式など），量子化が挙げられる．

これらの手法は独立に適用することも，組み合わせて適用することも可能である．
以下では，各手法の原理と特徴を述べた上で，本研究における適用方針を示す．

\subsubsection{プルーニング（Pruning）}
プルーニングとは，閾値以下の重みを0とみなし接続を削除することで，モデルを疎行列化する手法である．
Hanら\cite{han2015deep}は，重要接続の学習，閾値による削減，再訓練を繰り返すことで，大規模モデルを10倍以上圧縮できることを示した．

本研究では，L1正則化により重みを0に近づけた後，閾値0.01でプルーニングを実施する．
この処理により多くの重みが0となり，後述する疎行列表現による効率的な格納が可能となる．

\paragraph{メリット}
\begin{itemize}
    \item パラメータ削減：非ゼロ率を大幅に低下可能（40次元モデルで1,923から200以下も実現可能）
    \item 計算量削減：不要な演算が減少し推論が高速化
    \item 精度維持：軽微な削減であれば再訓練により精度回復が可能
\end{itemize}

\paragraph{デメリット}
\begin{itemize}
    \item 再訓練なしでは精度低下が生じやすい
    \item インデックス保存など疎行列特有のオーバーヘッドが存在
    \item プルーニング量の決定に追加の探索が必要
\end{itemize}

\subsubsection{CSR（Compressed Sparse Row）形式}
プルーニングにより疎化された重み行列は，そのまま密行列として保持すると0要素にもメモリを消費するため非効率である．
CSR形式は，非ゼロ要素のみを行単位でまとめて保存する疎行列表現であり，値配列（data），列インデックス（indices），行ポインタ（indptr）で構成される．
行方向のアクセスが高速であり，行列ベクトル積を多用するニューラルネットワークの推論に適している．

\paragraph{メリット}
\begin{itemize}
    \item 行方向のアクセスが高速で推論が効率的
    \item インデックス管理が最適化されメモリ効率が高い
    \item 固定長配列でArduino実装に適する
    \item 非ゼロ率に応じて3〜10倍のメモリ削減が可能
\end{itemize}

\paragraph{デメリット}
\begin{itemize}
    \item 変換時にソートが必要
    \item 列方向アクセスは非効率
\end{itemize}

なお，疎行列表現としてはCOO（Coordinate）形式も存在し，実装が容易という利点があるが，行列ベクトル積の計算効率がCSR形式より劣るため，本研究ではCSR形式を採用した．

\subsubsection{量子化（Quantization）}
量子化とは，ニューラルネットワークの重みや活性化値を32ビット浮動小数点から8ビット整数へ変換し，メモリ削減と計算高速化を図る手法である．
Jacobら\cite{jacob2018quantization}が提案したアフィン変換
\begin{equation}
r = S(q - Z)
\end{equation}
を用いることで，推論時の整数演算が可能となる．
ここで，$S$はスケール，$Z$はゼロポイントを表す．

量子化は，プルーニングやCSR形式とは独立に適用可能であり，CSR形式で格納された重みに対しても追加適用できる．
float32からint8への変換により，さらに約4倍のメモリ削減が期待できる．

\paragraph{メリット}
\begin{itemize}
    \item メモリ削減：32ビットから8ビットへの変換により約4倍削減
    \item 計算高速化：整数演算により浮動小数点演算より低レイテンシ
    \item 精度維持：量子化感知訓練（QAT）を用いることでMSEをほぼ維持可能
\end{itemize}

\paragraph{デメリット}
\begin{itemize}
    \item モデル規模が小さい場合，チャネルごとの差により誤差が生じやすい
    \item スケール・ゼロポイントの計算やint32蓄積処理など実装がやや複雑
    \item 訓練時にfake quantizationノードの挿入が必要
\end{itemize}

\subsubsection{本研究における適用方針}
表\ref{tab:weight_compression_summary}に，各圧縮手法の特徴を示す．

\begin{table}[h]
    \centering
    \caption{重み圧縮手法の比較}
    \label{tab:weight_compression_summary}
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{手法} & \textbf{メモリ削減率} & \textbf{計算効率} & \textbf{実装難易度} & \textbf{Arduino適合性} \\
        \hline
        CSR形式 & 3--10倍 & 高 & 中 & 高 \\
        \hline
        量子化 & 約4倍 & 高 & 中 & 高 \\
        \hline
        CSR+量子化 & 12--40倍 & 高 & 高 & 高 \\
        \hline
    \end{tabular}
\end{table}

本研究では，段階的な圧縮アプローチを採用する．
その理由は以下のとおりである．

第一に，圧縮処理は推論精度に影響を与える可能性があるため，必要最小限の圧縮にとどめることが望ましい．
過度な圧縮は精度劣化を招くリスクがあり，圧縮手法を一度に複数適用するよりも，段階的に適用して各段階で精度を確認する方が安全である．

第二に，プルーニングとCSR形式は本質的に連続した処理である．
L1正則化によって重みを疎化し，その結果生じた0要素を効率的に格納するのがCSR形式の役割である．
したがって，この二つを組み合わせた「CSR圧縮」を第一段階として適用するのが自然な流れとなる．

第三に，量子化はCSR形式とは独立に適用可能であり，追加的な圧縮手段として位置づけられる．
CSR圧縮のみでメモリ制約を満たせる場合は量子化を省略でき，さらなる圧縮が必要な場合にのみ追加適用すればよい．

以上の考察に基づき，本研究では次の方針を採る．
まず，L1正則化およびプルーニング後の重み行列をCSR形式に変換し，推論品質への影響を評価する．
CSR圧縮によりMSEが許容範囲内に収まり，かつメモリ制約を満たす場合はそのまま採用する．
一方，さらなるメモリ削減が必要な場合や隠れ層次元の拡張を行う場合には，CSR圧縮モデルに対して量子化を追加適用する．
この段階的なアプローチにより，推論精度とメモリ効率のバランスを最適化することを目指す．

\clearpage
\section{システムの構成}

本章では，実験に用いたシステムのハードウェア構成およびソフトウェア構成について述べる．

\subsection{ハードウェア構成}

本節では，実験で使用した配線および回路構成について述べる．
表\ref{tab:pin_assignment}にArduinoのピン割り当て，表\ref{tab:機材表}に使用機材一覧，図\ref{fig:回路図}に回路図を示す．

\begin{table}[h]
    \centering
    \caption{Arduinoのピン割り当て}
    \label{tab:pin_assignment}
    \begin{tabular}{|c|c|l|}
        \hline
        \textbf{ピン} & \textbf{機能}              & \textbf{説明}                     \\ \hline \hline
        D2           & タクトスイッチ(赤)       & 最大値・最小値の切り替え          \\ \hline
        D3           & タクトスイッチ(青)       & RGBデータの読み取りトリガー       \\ \hline
        A0           & 照度センサー               & フォトトランジスタからのアナログ入力 \\ \hline
    \end{tabular}
\end{table}

\begin{table}[h]
    \centering
    \caption{使用機材一覧}
    \label{tab:機材表}
    \begin{tabular}{|c|c|c|}
        \hline
        機材名 & 型番 & 個数  \\ \hline
        \hline
        炭素皮膜抵抗$330\Omega$ & - & 3  \\ \hline
        炭素皮膜抵抗$3.3k\Omega$ & - & 1  \\ \hline
        炭素皮膜抵抗$10k\Omega$ & - & 2  \\ \hline
        RGBフルカラーLED & OSTA5131A & 1  \\ \hline
        照度センサー(フォトトランジスタ) & NJL7302L-F3 & 1  \\ \hline
        タクトスイッチ(赤・青) & 1273HIM-160G-G & 2  \\ \hline
        ジャンパーワイヤ & BBJ-65 & 13 \\ \hline
        マイコンボード & Arduino UNO R4 WiFi & 1\\ \hline
        ブレッドボード & - & 1 \\ \hline 
    \end{tabular}
\end{table}

\begin{figure}[h]
    \centering
    \includegraphics[width=16cm]{回路図.pdf}
    \caption{回路図}
    \label{fig:回路図}
\end{figure}

\clearpage

\subsection{ソフトウェア構成}

本システムのソフトウェアは，学習フェーズとデプロイフェーズの2段階で構成される．

\subsubsection{学習フェーズ}
学習フェーズでは，PC上でPythonおよびPyTorchを用いてニューラルネットワークの学習を行う．
学習にはJupyter Notebook（\texttt{train\_L1\_normalization.ipynb}）を使用し，以下の処理を実行する．
\begin{enumerate}
    \item データの読み込みと前処理
    \item L1正則化を適用したニューラルネットワークの学習
    \item プルーニングおよびCSR形式への変換
    \item Arduinoで読み込み可能なヘッダファイル（\texttt{.h}）の生成
\end{enumerate}

\subsubsection{デプロイフェーズ}
デプロイフェーズでは，生成したパラメータファイルをArduinoに組み込み，実機上で推論を実行する．
Arduinoコードは用途に応じて以下の3種類を用意した．
\begin{itemize}
    \item \texttt{AI\_Model}：密行列形式（非圧縮）のニューラルネットワーク
    \item \texttt{AI\_CSR}：CSR形式で圧縮したニューラルネットワーク
    \item \texttt{AI\_CSR\_Quantized}：CSR形式に量子化を追加適用したニューラルネットワーク
\end{itemize}

\begin{lstlisting}[language=C, caption=Arduinoメインプログラム（抜粋）]
% TODO: コードを記載
\end{lstlisting}

\begin{lstlisting}[language=C, caption=CSR形式での行列ベクトル積演算]
% TODO: コードを記載
\end{lstlisting}

\clearpage

\section{実験方法}

本章では，前章で述べた段階的圧縮アプローチの有効性を検証するために実施した実験の条件，手順，および評価方法について述べる．

\subsection{実験の目的と方針}

本実験の目的は，Arduino Uno R4 WiFiのメモリ制約下において，ニューラルネットワークの隠れ層次元を拡張しつつ，推論精度を維持することである．
具体的には，隠れ層次元を現行の40から100〜200へ拡張可能とし，画像復元品質の向上と読み取り時間の短縮を実現することを目指す．

この目的を達成するため，重み圧縮手法としてCSR（Compressed Sparse Row）形式を第一優先とし，CSR圧縮のみでは不十分な場合にはCSR圧縮モデルに対して量子化を追加適用する方針とした．
L1正則化による重みの疎化を活かすことで，メモリ効率と推論精度のバランスを最適化する．

実験では，隠れ層次元40から開始し，「非圧縮（密行列形式）」「CSR圧縮」「CSR＋量子化」の3種類のモデルについてMSEを比較し，各圧縮手法が推論品質に与える影響を評価する．

\subsection{実験の全体フロー}

実験の全体フローを図\ref{fig:experiment_flow}に示す．
本実験は，以下の3つのフェーズから構成される．

\begin{enumerate}
    \item \textbf{訓練・圧縮フェーズ}：PC上でPyTorchを用いてニューラルネットワークを訓練し，CSR形式への変換および量子化を適用してパラメータファイルを生成する
    \item \textbf{デプロイフェーズ}：生成したパラメータファイルをArduino Uno R4 WiFiに組み込み，実機へ書き込む
    \item \textbf{評価フェーズ}：センサーデータを用いて推論を実行し，出力画像と参照画像のMSEを計算して品質を評価する
\end{enumerate}

% 必要に応じて図を追加
% \begin{figure}[h]
%     \centering
%     \includegraphics[width=14cm]{experiment_flow.pdf}
%     \caption{実験の全体フロー}
%     \label{fig:experiment_flow}
% \end{figure}

\subsection{実験条件}

本実験では，隠れ層次元を変化させながら，各圧縮手法の効果を評価した．
表\ref{tab:experiment_conditions}に実験条件を示す．

\begin{table}[h]
    \centering
    \caption{実験条件}
    \label{tab:experiment_conditions}
    \begin{tabular}{|l|l|}
        \hline
        \textbf{項目} & \textbf{設定値} \\
        \hline
        隠れ層次元 & 40, 80, 120 \\
        \hline
        プルーニング閾値 & 0.01（固定） \\
        \hline
        正則化 & L1正則化 \\
        \hline
        疎行列形式 & CSR形式 \\
        \hline
        量子化 & int8（必要に応じて適用） \\
        \hline
    \end{tabular}
\end{table}

プルーニング閾値を0.01に固定した理由は，予備実験において精度と圧縮率のバランスが良好であったためである．

\subsection{実験手順}

\subsubsection{モデルの学習とパラメータ生成}
まず，L1正則化を適用したニューラルネットワークを学習し，重みの疎化を促進した．
学習完了後，密行列形式のパラメータファイル（\texttt{model\_parameters.h}）を生成した．
このファイルは，圧縮なしのベースラインモデルとして使用する．

次に，学習済みモデルに対し，閾値0.01でプルーニングを実施した後，重み行列をCSR形式に変換した．
変換後のパラメータは\texttt{model\_parameters\_csr.h}として出力した．
各隠れ層次元（40, 80, 120）に対してこの処理を行い，それぞれ\texttt{model\_parameters\_csr40.h}，\texttt{model\_parameters\_csr80.h}，\texttt{model\_parameters\_csr120.h}として管理した．

CSR圧縮のみではメモリ制約を満たせない場合，またはさらなる圧縮が必要な場合には，CSR形式のパラメータに対してint8量子化を追加適用し，\texttt{model\_parameters\_csr\_quantized.h}として出力した．

\subsubsection{Arduinoへのデプロイ}
生成したパラメータファイルをArduinoプロジェクトに組み込み，Arduino IDEを用いてコンパイル・アップロードを行った．
この際，Arduinoコード内の\texttt{HIDDEN\_DIM}マクロを学習時と同一の値に設定し，対応するパラメータファイルをインクルードした．

\subsubsection{スキャン実行とデータ取得}
Arduinoに接続したRGBカラーセンサを用いて参照画像をスキャンし，推論結果をPPM形式の画像ファイルとして出力した．
スキャンは以下の手順で実施した．

\paragraph{キャリブレーション}
センサの感度は環境光や個体差により変動するため，測定前にキャリブレーションを行った．
具体的には，2つのタクトスイッチを用いたプログラムにより，黒と白のサンプルを事前に測定し，センサ出力の最小値および最大値を取得した．
これらの値を基準として読み取り範囲を正規化することで，安定したRGB値の取得を可能とした．

\paragraph{カラーチャートの読み取り}
キャリブレーション完了後，3$\times$3のカラーチャートをセンサで読み取った．
各セルについてRGB値を取得し，ニューラルネットワークによる推論を経て補正されたRGB値を得た．

\paragraph{PPM画像の出力}
取得したRGBデータは，PPM（Portable Pixel Map）形式の画像ファイルとして出力した．
PPM形式は非圧縮のラスタ画像フォーマットであり，画素値を直接比較できるため，後続のMSE評価に適している．
各実験条件につき複数回のスキャンを実施し，結果のばらつきを考慮した．


\subsection{評価方法}

推論精度の評価指標として，平均二乗誤差（MSE: Mean Squared Error）を用いた．
MSEは以下の式で定義される．
\begin{equation}
    \text{MSE} = \frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y}_i)^2
\end{equation}
ここで，$N$は画素数，$y_i$は参照画像の画素値，$\hat{y}_i$はスキャン結果の画素値である．

評価手順は以下のとおりである．
\begin{enumerate}
    \item 自作のMSE計算ツール（\texttt{mse\_calculator.html}）をブラウザで開く
    \item 参照画像（\texttt{reference\_image1.ppm}）を読み込む
    \item スキャン結果のPPMファイルを読み込む
    \item 算出されたMSE値を記録する
\end{enumerate}

\subsection{比較対象}
本実験では，以下の3種類のモデルを比較対象とした．

\begin{enumerate}
    \item \textbf{密行列形式（非圧縮）}：L1正則化のみを適用し，圧縮処理を行わないベースラインモデル
    \item \textbf{CSR圧縮}：プルーニング後にCSR形式へ変換したモデル
    \item \textbf{CSR＋量子化}：CSR圧縮に加えてint8量子化を適用したモデル
\end{enumerate}

これらのモデルについて，各隠れ層次元におけるMSEとメモリ使用量を比較し，段階的圧縮アプローチの有効性を検証した．
最終的な目標は，MSEを許容範囲内に抑えつつ，隠れ層次元を100〜200へ拡張可能とすることである。

\clearpage
\begin{thebibliography}{9}
\bibitem{jacob2018quantization} B. Jacob et al., ``Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference,'' CVPR, 2018.
\bibitem{han2015deep} Song Han et al., ``Learning both Weights and Connections for Efficient Neural Networks,'' NeurIPS, 2015.
\end{thebibliography}


\end{document}