\documentclass[a4paper,12pt]{jsarticle}  % 日本語論文向け（uplatex推奨）

% 基本エンコーディング・フォント
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

% ページ設定
\usepackage{geometry}
\geometry{a4paper, margin=1in}

% 数学・数式
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}

% 表・列制御
\usepackage{booktabs}
\usepackage{array}
\usepackage{longtable}
\usepackage{multirow}
\usepackage{colortbl}

% 図・キャプション
\usepackage[dvipdfmx]{graphicx}
\usepackage{caption}
\usepackage{subcaption}

% アルゴリズム
\usepackage{algorithm}
\usepackage{algorithmic}

% ハイパーリンク（pxjahyperより前に読み込む必要がある）
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=red,
    urlcolor=green
}

% 日本語対応（uplatex + dvipdfmx用，hyperrefの後に読み込む）
\usepackage[dvipdfmx]{pxjahyper}

% コードハイライト
\usepackage{listings}
\lstset{
  language=Python,
  basicstyle=\small\ttfamily,
  breaklines=true,
  columns=fixed,
  keepspaces=true,
  showstringspaces=false,
  frame=single,
  numbers=left,
  numberstyle=\tiny,
  captionpos=b
}

\begin{document}

\title{2025年度　アジャイルワーク 報告書}
\author{24G1089　武本 龍}
\maketitle

\section{はじめに}
近年，ディープラーニングをはじめとするAI技術は急速に発展しており，その学習や推論には大規模な計算資源や電力を必要とすることが一般的となっている．
しかし，組込み機器やIoTデバイスのような小型環境では，CPU性能やメモリ容量，電力供給といったリソースが大幅に制限されるため，
従来の手法をそのまま適用することは困難である．
そこで，既存のArduino Uno R4 WiFi環境において可能な限り高性能なニューラルネットワーク推論を実現することを目的とし，
学習データの軽量化やモデルの圧縮を含む最適化手法を検討し，特に，学習データを圧縮した上で推論に必要な情報を保持できるか，
また限られた計算能力の中で最大限の推論精度を引き出せるかを検証し，その実験手法および得られた知見について報告する．

\section{実験の概要}
図\ref{fig:実験概要}に，本実験の全体構成を示す．

\begin{figure}[h]
    \centering
    \includegraphics[width=16cm]{実験概要.jpg}
    \caption{実験の全体構成}
    \label{fig:実験概要}
\end{figure}
\clearpage
Arduino Uno R4 WiFiを用いてカラーセンサーを構築し，授業内で配布された$3 \times 3$のカラーチャートを測定する．
測定後，ニューラルネットワークを用いた補正処理により，平均二乗誤差（MSE）の低減を目指す．
前章で述べた2つの検証項目に対応し，次の観点から評価を行う．

第一の検証として，ニューラルネットワークのパラメータ圧縮によるメモリ効率の改善を検討する．
具体的には，隠れ層のデータ圧縮手法を導入し，推論に必要な情報を保持しながらメモリ使用量をどの程度削減できるかを評価する．

第二の検証として，限られた計算資源の中での推論性能の最大化を検討する．
測定したカラーチャートと基準カラーチャート間のMSEを評価指標とし，ニューラルネットワークによる学習を活用して推論精度の向上を図る．
また，predict関数の処理時間を計測し，実行速度についても評価する．

\subsection{平均二乗誤差（MSE）}
平均二乗誤差（MSE: Mean Squared Error）は，2枚の画像の対応するピクセル位置における輝度差の2乗の平均値として定義され，以下の式で表される．
\begin{equation}
\text{MSE} = \frac{1}{m \times n} \sum_{i=1}^{m} \sum_{j=1}^{n} \left( I(i,j) - K(i,j) \right)^2
\label{eq:mse_definition}
\end{equation}
ここで，$I$と$K$は比較対象となる2枚の画像，$m \times n$は画像サイズを表す．

本実験ではRGB画像を扱うため，各ピクセルについてR，G，Bチャネルごとの差の2乗を加算し，チャネル数で除した値をMSEとして算出する．
具体的な計算式を以下に示す．
\begin{equation}
\text{MSE} = \frac{(r_{\text{diff}})^2 + (g_{\text{diff}})^2 + (b_{\text{diff}})^2}{3}
\label{eq:mse_rgb}
\end{equation}

MSEの値が小さいほど，2枚の画像間の差異が少なく，色再現性が高いことを示す．
このMSEを推論精度の評価指標として用いる．


\clearpage
\section{実験理論}
本章では，ニューラルネットワークを用いた読み込み品質の改善手法について述べる．

\subsection{ニューラルネットワークによる品質改善}
サンプル画像と測定画像との誤差を最小化するため，ニューラルネットワークを用いた学習手法を導入する．
特に，低リソース環境であるArduino上での推論実行を前提とし，モデルの圧縮および疎化手法を併用しながら性能の最適化を図る．

\subsubsection{ネットワーク構造}
本実験で採用したモデルは，全結合型（Fully Connected）の4層ニューラルネットワークである．
入力層はRGBの3次元，2つの隠れ層はそれぞれ可変次元（実験では40〜600次元），出力層は再びRGBの3次元とした．
各層の構成を表\ref{tab:nn_structure}に示す．

\begin{table}[h]
    \centering
    \caption{ニューラルネットワークの構造}
    \label{tab:nn_structure}
    \begin{tabular}{|l|c|l|}
        \hline
        \textbf{層} & \textbf{次元数} & \textbf{活性化関数} \\
        \hline
        入力層 & 3 & -- \\
        \hline
        隠れ層1 & 40〜600（可変） & ReLU \\
        \hline
        隠れ層2 & 40〜600（可変） & ReLU \\
        \hline
        出力層 & 3 & -- \\
        \hline
    \end{tabular}
\end{table}

各ニューロンにおける推論は以下の式で表される．
\begin{equation}
y = x_1 w_1 + x_2 w_2 + \cdots + x_{n-1} w_{n-1} + b
\end{equation}
ここで，$w_i$は重み，$b$はバイアスを表す．
算出された値は活性化関数を通過し，次層へ伝搬される．

モデルはPyTorchにより定義・訓練し，L1正則化を導入して重みの疎化を促進した．
訓練後の重みおよびバイアスはC++配列としてエクスポートし，Arduino上で実行可能な形式に変換した．

適用する圧縮手法（CSR形式，量子化）は，主にパラメータ数の多い隠れ層1および隠れ層2の重み行列に対して適用する．
これら2つの隠れ層は同一の次元数・活性化関数を持つため，以下では特に区別が必要な場合を除き，単に「隠れ層」と総称する．
隠れ層の次元数を拡張するとパラメータ数が増加し，メモリ使用量が増大するため，圧縮手法の適用が不可欠となる．
\clearpage
\subsection{隠れ層の圧縮手法}
\label{sec:compression_methods}
本研究では，ニューラルネットワークの隠れ層パラメータに対して以下の圧縮手法を適用する．
\subsubsection{圧縮の必要性}
\label{sec:memory_constraint}
Arduino Uno R4 WiFiのようなマイクロコントローラでは，利用可能なメモリ（SRAM約32\,KB，Flash 256\,KB）が極めて限定的である．
隠れ層の次元を増加させると，重みおよびバイアスの格納や推論演算に必要なメモリが不足する可能性が高い．

例えば，隠れ層次元を40から70以上に拡張するとパラメータ総数は急増する．
\begin{itemize}
    \item 40次元：約1,923パラメータ
    \item 70次元：約3,000パラメータ以上
\end{itemize}
float32形式では10\,KBを超える場合，Arduino上での動作が困難となる．
したがって，隠れ層の次元を拡張しながら高い推論性能を維持するには，重みデータの圧縮が不可欠である．

\clearpage
\subsubsection{プルーニング（Pruning）}
プルーニングとは，閾値以下の重みを0とみなし接続を削除することで，モデルを疎行列化する手法である．
Hanら\cite{han2015deep}は，重要接続の学習，閾値による削減，再訓練を繰り返すことで，大規模モデルを10倍以上圧縮できることを示した．

L1正則化により重みを0に近づけた後，閾値0.01でプルーニングを実施する．
この処理により多くの重みが0となり，後述する疎行列表現による効率的な格納が可能となる．

プルーニングの主なメリットは以下のとおりである．
\begin{itemize}
    \item パラメータ削減：非ゼロ率を大幅に低下可能（40次元モデルで1,923から200以下も実現可能）
    \item 計算量削減：不要な演算が減少し推論が高速化
    \item 精度維持：軽微な削減であれば再訓練により精度回復が可能
\end{itemize}

一方，デメリットとして以下が挙げられる．
\begin{itemize}
    \item 再訓練なしでは精度低下が生じやすい
    \item インデックス保存など疎行列特有のオーバーヘッドが存在
    \item プルーニング量の決定に追加の探索が必要
\end{itemize}

\subsubsection{CSR（Compressed Sparse Row）形式}
プルーニングにより疎化された重み行列は，そのまま密行列として保持すると0要素にもメモリを消費するため非効率である．
CSR形式は，非ゼロ要素のみを行単位でまとめて保存する疎行列表現であり，値配列（data），列インデックス（indices），行ポインタ（indptr）で構成される．
行方向のアクセスが高速であり，行列ベクトル積を多用するニューラルネットワークの推論に適している．

CSR形式の主なメリットは以下のとおりである．
\begin{itemize}
    \item 行方向のアクセスが高速で推論が効率的
    \item インデックス管理が最適化されメモリ効率が高い
    \item 固定長配列でArduino実装に適する
    \item 非ゼロ率に応じて3〜10倍のメモリ削減が可能
\end{itemize}

一方，デメリットとして以下が挙げられる．
\begin{itemize}
    \item 変換時にソートが必要
    \item 列方向アクセスは非効率
\end{itemize}

なお，疎行列表現としてはCOO（Coordinate）形式も存在し，実装が容易という利点があるが，行列ベクトル積の計算効率がCSR形式より劣るため，CSR形式を採用した．

\subsubsection{量子化（Quantization）}
量子化とは，ニューラルネットワークの重みや活性化値を32ビット浮動小数点から8ビット整数へ変換し，メモリ削減と計算高速化を図る手法である．
Jacobら\cite{jacob2018quantization}が提案したアフィン変換
\begin{equation}
r = S(q - Z)
\end{equation}
を用いることで，推論時の整数演算が可能となる．
ここで，$S$はスケール，$Z$はゼロポイントを表す．

量子化は，プルーニングやCSR形式とは独立に適用可能であり，CSR形式で格納された重みに対しても追加適用できる．
float32からint8への変換により，さらに約4倍のメモリ削減が期待できる．

量子化の主なメリットは以下のとおりである．
\begin{itemize}
    \item メモリ削減：32ビットから8ビットへの変換により約4倍削減
    \item 計算高速化：整数演算により浮動小数点演算より低レイテンシ
    \item 精度維持：量子化感知訓練（QAT）を用いることでMSEをほぼ維持可能
\end{itemize}

一方，デメリットとして以下が挙げられる．
\begin{itemize}
    \item モデル規模が小さい場合，チャネルごとの差により誤差が生じやすい
    \item スケール・ゼロポイントの計算やint32蓄積処理など実装がやや複雑
    \item 訓練時にfake quantizationノードの挿入が必要
\end{itemize}

\subsubsection{本研究における適用方針}
表\ref{tab:weight_compression_summary}に，各圧縮手法の特徴を示す．

\begin{table}[h]
    \centering
    \caption{重み圧縮手法の比較}
    \label{tab:weight_compression_summary}
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{手法} & \textbf{メモリ削減率} & \textbf{計算効率} & \textbf{実装難易度} & \textbf{Arduino適合性} \\
        \hline
        CSR形式 & 3--10倍 & 高 & 中 & 高 \\
        \hline
        量子化 & 約4倍 & 高 & 中 & 高 \\
        \hline
        CSR+量子化 & 12--40倍 & 高 & 高 & 高 \\
        \hline
    \end{tabular}
\end{table}

\subsubsection{段階的圧縮アプローチ}
\label{sec:staged_compression}


段階的な圧縮アプローチを採用する．
その理由は以下のとおりである．

第一に，圧縮処理は推論精度に影響を与える可能性があるため，必要最小限の圧縮にとどめることが望ましい．
過度な圧縮は精度劣化を招くリスクがあり，圧縮手法を一度に複数適用するよりも，段階的に適用して各段階で精度を確認する方が安全である．

第二に，プルーニングとCSR形式は本質的に連続した処理である．
L1正則化によって重みを疎化し，その結果生じた0要素を効率的に格納するのがCSR形式の役割である．
したがって，この二つを組み合わせた「CSR圧縮」を第一段階として適用する．

第三に，量子化はCSR形式とは独立に適用可能であり，追加的な圧縮手段として位置づけられる．
CSR圧縮のみでメモリ制約を満たせる場合は量子化を省略でき，さらなる圧縮が必要な場合にのみ追加適用すればよい．

以上の考察に基づき，次の方針を採る．
まず，L1正則化およびプルーニング後の重み行列をCSR形式に変換し，推論品質への影響を評価する．
CSR圧縮によりMSEが許容範囲内に収まり，かつメモリ制約を満たす場合はそのまま採用する．
一方，さらなるメモリ削減が必要な場合や隠れ層次元の拡張を行う場合には，CSR圧縮モデルに対して量子化を追加適用する．
この段階的なアプローチにより，推論精度とメモリ効率のバランスを最適化することを目指す．

\clearpage
\section{システムの構成}

本章では，実験に用いたシステムのハードウェア構成およびソフトウェア構成について述べる．

\subsection{ハードウェア構成}

実験で使用した配線および回路構成について述べる．
表\ref{tab:pin_assignment}にArduinoのピン割り当て，表\ref{tab:機材表}に使用機材一覧，図\ref{fig:回路図}に回路図を示す．

\begin{table}[h]
    \centering
    \caption{Arduinoのピン割り当て}
    \label{tab:pin_assignment}
    \begin{tabular}{|c|c|l|}
        \hline
        \textbf{ピン} & \textbf{機能}              & \textbf{説明}                     \\ \hline \hline
        D2           & タクトスイッチ(赤)       & 最大値・最小値の切り替え          \\ \hline
        D3           & タクトスイッチ(青)       & RGBデータの読み取りトリガー       \\ \hline
        A0           & 照度センサー               & フォトトランジスタからのアナログ入力 \\ \hline
    \end{tabular}
\end{table}

\begin{table}[h]
    \centering
    \caption{使用機材一覧}
    \label{tab:機材表}
    \begin{tabular}{|c|c|c|}
        \hline
        機材名 & 型番 & 個数  \\ \hline
        \hline
        炭素皮膜抵抗$330\Omega$ & - & 3  \\ \hline
        炭素皮膜抵抗$3.3k\Omega$ & - & 1  \\ \hline
        炭素皮膜抵抗$10k\Omega$ & - & 2  \\ \hline
        RGBフルカラーLED & OSTA5131A & 1  \\ \hline
        照度センサー(フォトトランジスタ) & NJL7302L-F3 & 1  \\ \hline
        タクトスイッチ(赤・青) & 1273HIM-160G-G & 2  \\ \hline
        ジャンパーワイヤ & BBJ-65 & 13 \\ \hline
        マイコンボード & Arduino UNO R4 WiFi & 1\\ \hline
        ブレッドボード & - & 1 \\ \hline 
    \end{tabular}
\end{table}

\begin{figure}[h]
    \centering
    \includegraphics[width=16cm]{回路図.pdf}
    \caption{回路図}
    \label{fig:回路図}
\end{figure}

\clearpage

\subsection{ソフトウェア構成}

ソフトウェアは，PC上で実行する学習フェーズと，Arduino上で実行するデプロイフェーズの2段階で構成される．
まずニューラルネットワークの構造を述べた後，各フェーズの処理内容について説明する．

\subsubsection{ニューラルネットワークの構造}
使用するニューラルネットワークは，RGB色補正を目的とした4層の全結合ネットワークである．
ネットワーク構造の詳細（各層の次元数，活性化関数，推論の数式）については，第3章の表\ref{tab:nn_structure}を参照する．

学習フェーズでは，隠れ層1および隠れ層2の次元数を40〜600の範囲で変化させて複数のモデルを訓練した．
デプロイフェーズでは，訓練済みモデルのパラメータをArduinoに組み込み，実機上で推論を実行する．

\subsubsection{学習フェーズ}

学習フェーズでは，PC上でPythonおよびPyTorchを用いてニューラルネットワークの学習を行う．
学習にはJupyter Notebook（\texttt{train\_L1\_normalization.ipynb}）を使用し，
L1正則化を適用したモデルの訓練，プルーニング，CSR形式への変換，およびArduino用パラメータファイルの生成を実行する．
学習フェーズの詳細な手順については，第\ref{sec:training_procedure}節で述べる．

\subsubsection{圧縮手法の実装}
\label{sec:compression_implementation}

第\ref{sec:compression_methods}節で述べた圧縮手法に基づき，本システムでは3種類の実装を用意した．

\begin{enumerate}
    \item \textbf{密行列形式（AI\_Model）}：圧縮なし．2次元配列で重み行列を格納し，標準的な行列ベクトル積で順伝播を行う．
    \item \textbf{CSR形式（AI\_CSR）}：プルーニング後にCSR形式へ変換．\texttt{data}，\texttt{indices}，\texttt{indptr}配列を用いて非ゼロ要素のみを計算する．
    \item \textbf{量子化CSR形式（AI\_CSR\_Quantized）}：CSR形式に加えてint8量子化を適用する．
\end{enumerate}

各実装はArduinoスケッチとして独立したディレクトリ（\texttt{AI\_Model/}，\texttt{AI\_CSR/}，\texttt{AI\_CSR\_Quantized/}）に配置される．
なお，圧縮処理は隠れ層の重み行列に対してのみ適用し，入力層・出力層の重みは密行列形式のまま保持する．

\subsubsection{デプロイフェーズ}
デプロイフェーズでは，学習フェーズで生成したパラメータファイルをArduinoに組み込み，実機上で推論を実行する．
Arduinoコードは，第\ref{sec:compression_implementation}節で述べた3種類の圧縮形式に対応しており，
それぞれ独立したディレクトリに配置される．

次節では，これらのニューラルネットワークを組み込んだRGB画像読み取りシステムの処理フローについて述べる．


\clearpage
\subsection{RGB画像読み取りシステムの処理フロー}
本システムでは，RGBセンサーから画素値を逐次読み取り，前節で述べたニューラルネットワークによってRGB値を補正した上で，PPM形式の画像として出力する．

処理は大きく，センサー入出力や画像バッファ管理を行う「共通部分」と，RGB補正を行う「NN部分」の2つに分けられる．
共通部分はニューラルネットワークの格納形式（密行列形式，CSR形式，量子化CSR形式）に依存しない処理であり，NN部分は格納形式に応じた推論処理を実装する．

\subsubsection{共通部分（センサー読み取りと画像バッファ管理）}
共通部分では，RGBセンサーの読み取り，画素値の正規化，NN出力の保存，PPM形式での画像出力などを実装する．
主に以下の5つの関数から構成される．

\paragraph{\texttt{allocateArray}関数}
画像の高さ $N$ と幅方向の要素数 $M$ を引数として受け取り，2次元配列（$N \times M$ の画素バッファ）をヒープ領域に動的確保する（図\ref{fig:scanner_allocateArray}）．
行ポインタの確保に失敗した場合や，途中の行の確保に失敗した場合には，確保済みメモリを解放して\texttt{NULL}を返すことで，メモリ不足に対処する．

\paragraph{\texttt{setup}関数}
シリアル通信の初期化，RGB LEDピンの出力設定および初期消灯，ボタン入力ピンの\texttt{INPUT\_PULLUP}設定，割り込みハンドラの登録を行う（図\ref{fig:scanner_setup}）．
続いてシリアルモニタから画像の高さ（Height）$N$ を読み取り，幅方向の要素数 $M=3N$ を計算し，\texttt{allocateArray}関数により画像バッファを動的確保する．
確保に成功した場合は，全要素を0で初期化する．

\paragraph{\texttt{read}関数}
ループ変数\texttt{count}に応じてR，G，Bの順にLEDを点灯しながらアナログ入力を行う（図\ref{fig:scanner_read}）．
すなわち，\texttt{count==0}のときはRのみ点灯して\texttt{rgb[0]}を読み取り，\texttt{count==1}ではGのみ点灯して\texttt{rgb[1]}を読み取り，それ以外（\texttt{count==2}）ではBのみ点灯して\texttt{rgb[2]}を読み取る．
3色の読み取り後にはすべてのLEDを消灯する．

\paragraph{\texttt{readAndProcess}関数}
まず\texttt{read}関数を呼び出し\texttt{rgb[]}に格納された生のセンサー値を取得し，事前にキャリブレーションされた最小値
（\texttt{r\_min}，\texttt{g\_min}，\texttt{b\_min}）と最大値（\texttt{r\_max}，\texttt{g\_max}，\texttt{b\_max}）を用いて0〜1に正規化した入力ベクトル\texttt{RGBInput[3]}を生成する（図\ref{fig:scanner_readAndProcess}）．
続いて\texttt{predict}関数を呼び出してニューラルネットワーク推論を行い，補正後のRGB値である\texttt{RGBOutput[3]}を得る．
ここで呼び出される\texttt{predict}関数が，入力層から隠れ層1，隠れ層2を経て出力層に至る順伝播計算を実行する．
最後に，出力値を0〜255にクリッピングし，B，R，Gの順でシリアル出力する．

\paragraph{\texttt{loop}関数}
処理を2つに分割して実行する．
1つ目は画素読み取りと保存を行う処理（図\ref{fig:scanner_loop_pixel}），2つ目はMin/Maxキャリブレーションを行う処理（図\ref{fig:scanner_loop_minmax}）である．

画素保存処理では，\texttt{buttonInputPressed}が真のとき，最新の\texttt{RGBOutput}を\texttt{array[n][m..m+2]}に書き込み，列インデックス\texttt{m}を3進める．
行が埋まれば\texttt{n}をインクリメントし，全行の読み取りが完了した場合にはPPM形式で全画素を出力し，\texttt{NVIC\_SystemReset()}によりリセットする．

キャリブレーション処理では，\texttt{buttonMinMaxPressed}が真のとき，変数\texttt{pushed}の偶奇に応じて最小値または最大値を更新する．
最小値は\texttt{rgb[]}そのものを保存し，最大値は\texttt{rgb[]}から最小値を引いた差分として設定する．

\begin{figure}[h]
  \centering
  \includegraphics[width=11cm]{フローチャート/Scanner共通/scanner_allocateArray.png}
  \caption{RGB画像バッファを動的確保する\texttt{allocateArray}関数のフローチャート}
  \label{fig:scanner_allocateArray}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=13cm]{フローチャート/Scanner共通/scanner_setup.png}
    \caption{RGB画像読み取りシステムの\texttt{setup}関数のフローチャート}
    \label{fig:scanner_setup}
  \end{figure}
  
  \begin{figure}[h]
    \centering
    \includegraphics[width=14cm]{フローチャート/Scanner共通/scanner_read.png}
    \caption{\texttt{read}関数（R/G/B順にLED点灯と読み取りを行う）のフローチャート}
    \label{fig:scanner_read}
  \end{figure}
  
  \begin{figure}[h]
    \centering
    \includegraphics[width=12cm]{フローチャート/Scanner共通/scanner_readAndProcess.png}
    \caption{\texttt{readAndProcess}関数（正規化およびNN推論処理）のフローチャート}
    \label{fig:scanner_readAndProcess}
  \end{figure}
  
  \begin{figure}[h]
    \centering
    \includegraphics[width=6cm]{フローチャート/Scanner共通/scanner_loop_pixel.png}
    \caption{\texttt{loop}関数における画素読み取り・保存処理のフローチャート}
    \label{fig:scanner_loop_pixel}
\end{figure}
  
\begin{figure}[h]
    \centering
    \includegraphics[width=13cm]{フローチャート/Scanner共通/scanner_loop_minmax.png}
    \caption{\texttt{loop}関数におけるMin/Maxキャリブレーション処理のフローチャート}
    \label{fig:scanner_loop_minmax}
\end{figure}


\clearpage
修正版を作成します。これまでの修正方針（冗長表現の削除、定義済み用語の活用、参照の統一）に沿って整理します。

latex\subsection{RGB画像読み取りシステムの処理フロー}

RGBセンサーから画素値を逐次読み取り，ニューラルネットワークによってRGB値を補正した上で，PPM形式の画像として出力する．

処理は，センサー入出力や画像バッファ管理を行う「共通部分」と，RGB補正を行う「NN部分」の2つに分けられる．
共通部分は第\ref{sec:compression_implementation}節で述べた3種類の圧縮形式に依存しない処理であり，NN部分は各形式に応じた推論処理を実装する．

\subsubsection{共通部分（センサー読み取りと画像バッファ管理）}

共通部分は，RGBセンサーの読み取り，画素値の正規化，NN出力の保存，PPM形式での画像出力を担当し，以下の5つの関数から構成される．

\paragraph{\texttt{allocateArray}関数}
画像の高さ$N$と幅方向の要素数$M$を引数として受け取り，2次元配列（$N \times M$の画素バッファ）をヒープ領域に動的確保する（図\ref{fig:scanner_allocateArray}）．
行ポインタの確保に失敗した場合や，途中の行の確保に失敗した場合には，確保済みメモリを解放して\texttt{NULL}を返すことで，メモリ不足に対処する．

\paragraph{\texttt{setup}関数}
シリアル通信の初期化，RGB LEDピンの出力設定および初期消灯，ボタン入力ピンの\texttt{INPUT\_PULLUP}設定，割り込みハンドラの登録を行う（図\ref{fig:scanner_setup}）．
続いてシリアルモニタから画像の高さ$N$を読み取り，幅方向の要素数$M=3N$を計算し，\texttt{allocateArray}関数により画像バッファを動的確保する．
確保に成功した場合は，全要素を0で初期化する．

\paragraph{\texttt{read}関数}
ループ変数\texttt{count}に応じてR，G，Bの順にLEDを点灯しながらアナログ入力を行う（図\ref{fig:scanner_read}）．
\texttt{count==0}のときはRのみ点灯して\texttt{rgb[0]}を読み取り，\texttt{count==1}ではGのみ点灯して\texttt{rgb[1]}を読み取り，それ以外ではBのみ点灯して\texttt{rgb[2]}を読み取る．
3色の読み取り後にはすべてのLEDを消灯する．

\paragraph{\texttt{readAndProcess}関数}
\texttt{read}関数を呼び出して\texttt{rgb[]}に格納されたセンサー値を取得し，事前にキャリブレーションされた最小値・最大値を用いて0〜1に正規化した入力ベクトル\texttt{RGBInput[3]}を生成する（図\ref{fig:scanner_readAndProcess}）．
続いて\texttt{predict}関数を呼び出してニューラルネットワーク推論を行い，補正後のRGB値である\texttt{RGBOutput[3]}を得る．
最後に，出力値を0〜255にクリッピングし，シリアル出力する．

\paragraph{\texttt{loop}関数}
画素読み取り・保存処理（図\ref{fig:scanner_loop_pixel}）とMin/Maxキャリブレーション処理（図\ref{fig:scanner_loop_minmax}）の2つを実行する．

画素保存処理では，\texttt{buttonInputPressed}が真のとき，最新の\texttt{RGBOutput}を画像バッファに書き込む．
全行の読み取りが完了した場合にはPPM形式で全画素を出力し，\texttt{NVIC\_SystemReset()}によりリセットする．

キャリブレーション処理では，\texttt{buttonMinMaxPressed}が真のとき，変数\texttt{pushed}の偶奇に応じて最小値または最大値を更新する．

\begin{figure}[h]
  \centering
  \includegraphics[width=11cm]{フローチャート/Scanner共通/scanner_allocateArray.png}
  \caption{\texttt{allocateArray}関数のフローチャート}
  \label{fig:scanner_allocateArray}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=13cm]{フローチャート/Scanner共通/scanner_setup.png}
  \caption{\texttt{setup}関数のフローチャート}
  \label{fig:scanner_setup}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=14cm]{フローチャート/Scanner共通/scanner_read.png}
  \caption{\texttt{read}関数のフローチャート}
  \label{fig:scanner_read}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=12cm]{フローチャート/Scanner共通/scanner_readAndProcess.png}
  \caption{\texttt{readAndProcess}関数のフローチャート}
  \label{fig:scanner_readAndProcess}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=6cm]{フローチャート/Scanner共通/scanner_loop_pixel.png}
  \caption{\texttt{loop}関数における画素読み取り・保存処理のフローチャート}
  \label{fig:scanner_loop_pixel}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=13cm]{フローチャート/Scanner共通/scanner_loop_minmax.png}
  \caption{\texttt{loop}関数におけるMin/Maxキャリブレーション処理のフローチャート}
  \label{fig:scanner_loop_minmax}
\end{figure}

\clearpage

%==================================================
\subsubsection{NN部分（RGB補正ニューラルネットワーク）}

NN部分では，共通部分で正規化された入力\texttt{RGBInput[3]}を受け取り，補正後RGBである\texttt{RGBOutput[3]}を推定する順伝播処理を実装する．
共通部分の\texttt{readAndProcess}関数からは，圧縮形式に依らず共通のインタフェースとして\texttt{predict}関数を呼び出す．

同一のネットワーク構造（入力3次元 → 隠れ層1: $H$次元 → 隠れ層2: $H$次元 → 出力3次元）を保ったまま，重みの保持方法を変えることで3種類の推論実装を比較した．
以下では，各方式の処理を説明する．

\paragraph{① 密行列形式 (非圧縮版)}

非圧縮版では，隠れ層の重み行列を密行列として保持し，全結合の積和演算をそのまま実行する．
図\ref{fig:scanner_forward_dense}に示すように，\texttt{predict}関数は\texttt{layer1\_dense\_relu}，\texttt{layer2\_dense\_relu}，\texttt{layer3\_dense}を順に呼び出し，入力から出力を得る．

実装が単純である一方，層ごとに全要素を走査するため，計算量は隠れ層次元に比例して増加する．
図\ref{fig:scanner_dense_layer_detail}に示す詳細では，各ニューロンについてバイアスから加算を開始し，入力との内積を計算した後，ReLUにより非線形変換する．

\begin{figure}[h]
  \centering
  \includegraphics[width=9cm]{フローチャート/ScannerNN/scanner_forward_dense.png}
  \caption{非圧縮版\texttt{predict}関数のフローチャート}
  \label{fig:scanner_forward_dense}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=8cm]{フローチャート/ScannerNN/scanner_dense_layer_detail.png}
  \caption{非圧縮版の隠れ層計算詳細フローチャート}
  \label{fig:scanner_dense_layer_detail}
\end{figure}

\paragraph{② CSR版（CSR形式）}

CSR版では，隠れ層の重み行列をCSR形式で保持し，非ゼロ要素のみを走査して積和演算を行う．
図\ref{fig:scanner_forward_csr}に示すように，\texttt{predict}関数は\texttt{layer1\_csr\_relu}，\texttt{layer2\_csr\_relu}を用いて隠れ層を計算し，最後に密行列の\texttt{layer3\_dense}を適用する．
ネットワーク構造は非圧縮版と同一のまま，ゼロ重み成分をスキップして計算量を削減できる．

図\ref{fig:scanner_csr_layer_detail}の詳細では，各行$r$について\texttt{indptr[r]}から\texttt{indptr[r+1]}までの非ゼロ要素のみをループし，列インデックス\texttt{indices[p]}を参照して積和を累積する．

\begin{figure}[h]
  \centering
  \includegraphics[width=9cm]{フローチャート/ScannerCSR/scanner_forward_csr.png}
  \caption{CSR版\texttt{predict}関数のフローチャート}
  \label{fig:scanner_forward_csr}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=6cm]{フローチャート/ScannerCSR/scanner_csr_layer_detail.png}
  \caption{CSR版の隠れ層計算詳細フローチャート}
  \label{fig:scanner_csr_layer_detail}
\end{figure}

\paragraph{③ CSR＋量子化版（量子化CSR形式）}

CSR＋量子化版では，CSR形式に加え，隠れ層の非ゼロ重みを8ビット整数（\texttt{int8\_t}）として保存し，推論時にスケール係数で浮動小数点へ復元しながら計算を行う．
図\ref{fig:scanner_forward_csr_quant}に示すように，\texttt{predict}関数は\texttt{layer1\_csr\_quantized\_relu}，\texttt{layer2\_csr\_quantized\_relu}，\texttt{layer3\_dense}を順に呼び出す．

図\ref{fig:scanner_csr_quant_layer_detail}の詳細では，CSR走査は非量子化版と同一である一方，各非ゼロ要素の重みが\texttt{int8\_t}として保持されている．
推論時には\texttt{(float)data\_quantized[p] / scale\_factor}として重みを復元し，積和を累積する．
演算はfloatで実行しつつ重みの格納コストを削減できるため，メモリ制約下でも大きな隠れ層次元を扱える．

\begin{figure}[h]
  \centering
  \includegraphics[width=9cm]{フローチャート/ScannerQuant/scanner_forward_csr_quant.png}
  \caption{CSR＋量子化版\texttt{predict}関数のフローチャート}
  \label{fig:scanner_forward_csr_quant}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=9cm]{フローチャート/ScannerQuant/scanner_csr_quant_layer_detail.png}
  \caption{CSR＋量子化版の隠れ層計算詳細フローチャート}
  \label{fig:scanner_csr_quant_layer_detail}
\end{figure}

\clearpage



\section{実験方法}
本章では，前章で述べた段階的圧縮アプローチの有効性を検証するために実施した実験について述べる．

\subsection{実験の目的と方針}

目的は，第\ref{sec:memory_constraint}節で述べたメモリ制約の下で，ニューラルネットワークの隠れ層次元を拡張しつつ，推論精度を維持することである．
具体的には，隠れ層次元を現行の40から600以上へ拡張可能とし，画像復元品質の向上を実現することを目指す．
この目的を達成するため，第\ref{sec:staged_compression}節で述べた段階的圧縮アプローチに基づき，CSR圧縮を第一優先とし，必要に応じて量子化を追加適用する方針で実験を行う．

\subsection{実験の全体フロー}
実験は，以下の3つのフェーズから構成される．

\begin{enumerate}
    \item \textbf{訓練・圧縮フェーズ}：PC上でPyTorchを用いてニューラルネットワークを訓練し，CSR形式への変換および量子化を適用してパラメータファイルを生成する
    \item \textbf{デプロイフェーズ}：生成したパラメータファイルをArduino Uno R4 WiFiに組み込み，実機へ書き込む
    \item \textbf{評価フェーズ}：センサーデータを用いて推論を実行し，出力画像と参照画像のMSEを計算して品質を評価する
\end{enumerate}

% 必要に応じて図を追加
% \begin{figure}[h]
%     \centering
%     \includegraphics[width=14cm]{experiment_flow.pdf}
%     \caption{実験の全体フロー}
%     \label{fig:experiment_flow}
% \end{figure}

\subsection{実験条件}
隠れ層次元を変化させながら，各圧縮手法の効果を評価した．
表\ref{tab:experiment_conditions}に実験条件を示す．

\begin{table}[h]
    \centering
    \caption{実験条件}
    \label{tab:experiment_conditions}
    \begin{tabular}{|l|l|}
        \hline
        \textbf{項目} & \textbf{設定値} \\
        \hline
        隠れ層次元 & 40, 50, 60, 70, 80, 120, 160, 200, 400, 600 \\
        \hline
        プルーニング閾値 & 0.01（固定） \\
        \hline
        正則化 & L1正則化（係数: $1 \times 10^{-6}$） \\
        \hline
        学習エポック数 & 50000 \\
        \hline
        最適化手法 & Adam（学習率: 0.01） \\
        \hline
        疎行列形式 & CSR形式 \\
        \hline
        量子化 & int8（必要に応じて適用） \\
        \hline
    \end{tabular}
\end{table}

プルーニング閾値を0.01に固定した理由は，予備実験において精度と圧縮率のバランスが良好であったためである．
また，L1正則化係数を$1 \times 10^{-6}$としたのは，重みの疎化を促進しつつ学習の収束性を維持するためである．


\subsection{実験手順}

\subsubsection{モデルの学習とパラメータ生成}
\label{sec:training_procedure}

モデルの学習およびパラメータ生成は，Jupyter Notebook（\texttt{train\_L1\_normalization.ipynb}）を用いて実施した．
各ステップの詳細を述べる．

\paragraph{ステップ1：環境セットアップとデータ準備}
まず，PyTorch，NumPy，Matplotlib等の必要なライブラリをインストールし，\texttt{cv2}，\texttt{torch}，\texttt{numpy}等をインポートした．

次に，PPM形式のカラーチャート画像を読み込み，参照画像（3$\times$3および6$\times$6のカラーチャート）を準備した．
推論用データ（$X$）と正解データ（$Y$）は0〜1の範囲に正規化し，\texttt{formatted\_arrays.txt}として保存した．

\paragraph{ステップ2：ニューラルネットワークの学習}
第3章で述べた4層全結合ニューラルネットワークを，L1正則化を適用して学習した．
学習パラメータを表\ref{tab:training_params}に示す．

\begin{table}[h]
    \centering
    \caption{学習パラメータ}
    \label{tab:training_params}
    \begin{tabular}{|l|l|}
        \hline
        \textbf{項目} & \textbf{設定値} \\
        \hline
        損失関数 & MSE + L1正則化 \\
        \hline
        L1正則化係数 & $1 \times 10^{-6}$ \\
        \hline
        最適化手法 & Adam \\
        \hline
        学習率 & 0.01 \\
        \hline
        エポック数 & 50000 \\
        \hline
        進捗表示間隔 & 500エポックごと \\
        \hline
    \end{tabular}
\end{table}

隠れ層次元（\texttt{HIDDEN\_DIM}）を40, 50, 60, 70, 80, 120, 160, 200, 400, 600と変化させて複数のモデルを学習した．
学習完了後，密行列形式のパラメータファイル（\texttt{model\_parameters.h}）が自動生成される．
このファイルには全層の重みとバイアスがC++配列として出力され，圧縮なしのベースラインモデルとして使用する．

\paragraph{ステップ3：CSR形式への変換}
学習済みモデルに対し，プルーニング閾値0.01でプルーニングを実施した後，隠れ層の重み行列をCSR形式に変換した．

変換処理は以下の手順で実施した．
\begin{enumerate}
    \item 重み行列を取得し，絶対値が0.01未満の要素を0に設定（プルーニング）
    \item 非ゼロ要素を抽出し，CSR形式の3つの配列に変換：
    \begin{itemize}
        \item \texttt{data}：非ゼロ要素の値配列（float32）
        \item \texttt{indices}：列インデックス配列（uint16\_t）
        \item \texttt{indptr}：行ポインタ配列（uint16\_t）
    \end{itemize}
    \item スパース性（非ゼロ率）と圧縮率を算出
\end{enumerate}

変換後のパラメータは，各隠れ層次元に応じて\texttt{model\_parameters\_csr40.h}，\texttt{model\_parameters\_csr80.h}等のファイル名で出力した．

\clearpage
\paragraph{ステップ4：量子化の適用（オプション）}
CSR圧縮のみではメモリ制約を満たせない場合，CSR形式のパラメータに対してint8量子化を追加適用した．

量子化処理は以下の手順で実施した
\begin{enumerate}
    \item CSR形式の値配列（\texttt{data}）に対してスケールファクタを計算：
    \begin{equation}
        \text{scale} = \frac{127.0}{\max(|\texttt{data}|)}
    \end{equation}
    \item 各要素を量子化し，$-128$〜$127$の範囲にクリッピング：
    \begin{equation}
        \texttt{quantized} = \text{clip}(\text{round}(\texttt{data} \times \text{scale}), -128, 127)
    \end{equation}
\end{enumerate}

量子化は隠れ層の重み行列に対して，各層ごとに独立したスケールファクタを用いて適用した．
量子化後のパラメータは，\texttt{model\_parameters\_csr\_quantized40.h}等のファイル名で出力した．

\paragraph{次元変更時の手順}
異なる次元で実験する場合は，以下の手順を実行した．
\begin{enumerate}
    \item Jupyter Notebookで\texttt{HIDDEN\_DIM}を変更
    \item 学習を実行し，密行列形式パラメータを生成
    \item CSR変換を実行し，CSR形式パラメータを生成
    \item 必要に応じて量子化を適用
    \item 生成ファイルをArduinoプロジェクトにコピー
    \item Arduinoコードの\texttt{HIDDEN\_DIM}を同じ値に設定
\end{enumerate}

\clearpage

\subsubsection{Arduinoへのデプロイ}

生成したパラメータファイルをArduinoプロジェクトに組み込み，実機へ書き込みを行った．

\paragraph{ステップ1：パラメータファイルの配置}
生成されたパラメータファイルを，表\ref{tab:parameter_files}に示す対応するArduinoプロジェクトフォルダにコピーした．

\begin{table}[h]
    \centering
    \caption{パラメータファイルの配置}
    \label{tab:parameter_files}
    \begin{tabular}{|l|l|l|}
        \hline
        \textbf{生成ファイル} & \textbf{コピー先} & \textbf{用途} \\
        \hline
        \texttt{model\_parameters*.h} & \texttt{Arduino/AI\_Model/} & 密行列形式 \\
        \hline
        \texttt{model\_parameters\_csr*.h} & \texttt{Arduino/AI\_CSR/} & CSR形式 \\
        \hline
        \texttt{model\_parameters\_csr\_quantized*.h} & \texttt{Arduino/AI\_CSR\_Quantized/} & CSR+量子化 \\
        \hline
    \end{tabular}
\end{table}

\paragraph{ステップ2：Arduinoコードの設定}
各Arduinoプロジェクト内の\texttt{.ino}ファイルにおいて，\texttt{HIDDEN\_DIM}マクロを学習時と同一の値に設定し，対応するパラメータファイルをインクルードした．

\begin{lstlisting}[language=C, caption=Arduinoコードの設定例（80次元の場合）]
#define HIDDEN_DIM 80  // 学習時と同じ値に設定
#include "model_parameters_csr80.h"  // 対応するファイルをインクルード
\end{lstlisting}

\texttt{HIDDEN\_DIM}の値とパラメータファイルの次元が一致していない場合，正常に動作しないため注意が必要である．

\paragraph{ステップ3：コンパイルとアップロード}
Arduino IDEを用いて，ボード設定を「Arduino UNO R4 WiFi」に設定し，コンパイル・アップロードを行った．
コンパイル時に表示されるSRAM使用量が32\,KBを超える場合はアップロードに失敗するため，その場合はより高い圧縮率の手法を適用する必要がある．

\clearpage
\subsubsection{スキャン実行とデータ取得}

Arduinoに接続したRGBカラーセンサを用いて参照画像をスキャンし，推論結果をPPM形式の画像ファイルとして出力した．

\paragraph{ステップ1：キャリブレーション}
センサの感度は環境光や個体差により変動するため，測定前にキャリブレーションを行った．
2つのタクトスイッチを用いて，黒色サンプルで最小値を，白色サンプルで最大値を記録し，これらを基準として読み取り範囲を正規化した．

\paragraph{ステップ2：カラーチャートの読み取り}
キャリブレーション完了後，3$\times$3のカラーチャートを1セルずつセンサで読み取った．
取得したRGB値はニューラルネットワークによる推論を経て補正され，全9セルの読み取りが完了するまで繰り返した．

\paragraph{ステップ3：PPM画像の出力}
取得したRGBデータは，シリアル通信を介してPC上のスキャナプログラム（\texttt{scanner.c}）に送信され，PPM形式の画像ファイルとして出力された．
出力ファイルは実験条件ごとにフォルダを分けて保存し，各条件につき10回程度のスキャンを実施した．


\subsection{評価方法}
推論精度の評価指標として，第2章で定義した平均二乗誤差（MSE）を用いた（式\ref{eq:mse_definition}，式\ref{eq:mse_rgb}参照）．
MSEの値が小さいほど，参照画像との差異が少なく，色補正の精度が高いことを示す．

評価には授業で配布されたMSE計算ツール（\texttt{mse\_calculator.html}）を使用した．
このツールはブラウザ上で動作し，参照画像とスキャン結果のPPMファイルをドラッグ＆ドロップすることでMSEを算出できる．
各実験条件のすべてのスキャン結果についてMSEを算出し，平均値・最小値・最大値を求めた．

コンパイル時間の計測については，Arduino IDEで各モデルをコンパイルする際に，コンパイル開始時と終了時に\texttt{micros()}関数を用いて時間を計測し，その差分をコンパイル時間として記録した．
これにより，各圧縮手法および隠れ層次元におけるコンパイル時間を比較し，圧縮手法がコンパイル効率に与える影響を評価した．

\subsection{比較対象}

本実験では，第\ref{sec:compression_implementation}節で述べた3種類のモデル（密行列形式，CSR圧縮，CSR＋量子化）を比較対象とした．
これらのモデルについて，各隠れ層次元におけるMSEとメモリ使用量を比較し，段階的圧縮アプローチの有効性を検証した．
最終的な目標は，MSEを許容範囲内に抑えつつ，隠れ層次元を600以上へ拡張可能とすることである．

\clearpage

\section{実験結果}
前章で述べた実験方法に基づいて実施した実験の結果を示す．
評価指標であるMSE，メモリ使用量，コンパイル時間の順に結果を述べ，最後に結果をまとめる．

\subsection{推論精度（MSE）}
各圧縮手法および隠れ層次元におけるMSE測定結果を表\ref{tab:results_mse_comparison}に示す．
各条件につき10回のスキャンを実施し，最小値・最大値・平均値を算出した．

\begin{table}[h]
    \centering
    \caption{圧縮手法別MSE比較}
    \label{tab:results_mse_comparison}
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{圧縮手法} & \textbf{隠れ層次元} & \textbf{MSE最小値} & \textbf{MSE最大値} & \textbf{MSE平均値} \\
        \hline
        \hline
        \multicolumn{5}{|c|}{\textbf{密行列形式}} \\
        \hline
        密行列形式 & 40 & 277.67 & 792.85 & 595.95 \\
        \hline
        密行列形式 & 50 & 231.11 & 535.59 & 406.93 \\
        \hline
        密行列形式 & 60 & 138.00 & 423.22 & 305.48 \\
        \hline
        密行列形式 & 70 & \multicolumn{3}{c|}{コンパイルエラー（メモリ不足）} \\
        \hline
        \multicolumn{5}{|c|}{\textbf{CSR圧縮}} \\
        \hline
        CSR圧縮 & 40 & 324.00 & 692.37 & 518.58 \\
        \hline
        CSR圧縮 & 80 & 225.19 & 729.26 & 464.86 \\
        \hline
        CSR圧縮 & 120 & 295.37 & 814.33 & 620.49 \\
        \hline
        CSR圧縮 & 160 & 295.52 & 1179.59 & 589.08 \\
        \hline
        CSR圧縮 & 200 & 291.41 & 979.85 & 493.35 \\
        \hline
        CSR圧縮 & 400 & 390.89 & 1978.81 & 864.40 \\
        \hline
        CSR圧縮 & 600 & 253.44 & 2143.81 & 670.69 \\
        \hline
        CSR圧縮 & 800 & \multicolumn{3}{c|}{コンパイルエラー（メモリ不足）} \\
        \hline
        \multicolumn{5}{|c|}{\textbf{CSR＋量子化}} \\
        \hline
        CSR＋量子化 & 40 & 278.78 & 588.15 & 408.97 \\
        \hline
        CSR＋量子化 & 80 & 200.22 & 323.96 & 270.68 \\
        \hline
        CSR＋量子化 & 120 & 169.37 & 310.63 & 244.83 \\
        \hline
        CSR＋量子化 & 160--600 & \multicolumn{3}{c|}{測定未実施} \\
        \hline
        CSR＋量子化 & 800 & \multicolumn{3}{c|}{コンパイルエラー（メモリ不足）} \\
        \hline
    \end{tabular}
\end{table}
同一次元における圧縮手法間の比較を表\ref{tab:results_by_dimension}に示す．

\begin{table}[h]
    \centering
    \caption{隠れ層次元別MSE比較（平均値）}
    \label{tab:results_by_dimension}
    \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{隠れ層次元} & \textbf{密行列形式} & \textbf{CSR圧縮} & \textbf{CSR＋量子化} \\
        \hline
        40 & 595.95 & 518.58 & 408.97 \\
        \hline
        50 & 406.93 & -- & -- \\
        \hline
        60 & 305.48 & -- & -- \\
        \hline
        80 & -- & 464.86 & 270.68 \\
        \hline
        120 & -- & 620.49 & 244.83 \\
        \hline
        160 & -- & 589.08 & -- \\
        \hline
        200 & -- & 493.35 & -- \\
        \hline
        400 & -- & 864.40 & -- \\
        \hline
        600 & -- & 670.69 & -- \\
        \hline
    \end{tabular}
\end{table}

\clearpage
図\ref{fig:mse_120dim}に隠れ層次元120までのMSE平均値の推移を，図\ref{fig:mse_600dim}に600次元までの推移を示す．

\begin{figure}[h]
    \centering
    \includegraphics[width=14cm]{結果/mse/mse_vs_dimension_120dim.png}
    \caption{隠れ層次元とMSE平均値の関係（120次元まで）}
    \label{fig:mse_120dim}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=14cm]{結果/mse/mse_vs_dimension_600dim.png}
    \caption{隠れ層次元とMSE平均値の関係（600次元まで）}
    \label{fig:mse_600dim}
\end{figure}

\clearpage
\subsection{メモリ使用量}

各条件におけるArduino Uno R4 WiFiのSRAM使用量を表\ref{tab:results_memory}に示す．
使用率は，利用可能なSRAM（32,768バイト）に対する割合である．

\begin{table}[h]
    \centering
    \caption{圧縮手法別メモリ使用量}
    \label{tab:results_memory}
    \begin{tabular}{|l|c|c|c|}
        \hline
        \textbf{圧縮手法} & \textbf{隠れ層次元} & \textbf{メモリ使用量} & \textbf{使用率} \\
        \hline
        \hline
        \multicolumn{4}{|c|}{\textbf{密行列形式}} \\
        \hline
        密行列形式 & 40 & 14,524バイト & 44\% \\
        \hline
        密行列形式 & 50 & 18,444バイト & 56\% \\
        \hline
        密行列形式 & 60 & 23,164バイト & 70\% \\
        \hline
        密行列形式 & 70 & \multicolumn{2}{c|}{コンパイルエラー} \\
        \hline
        \hline
        \multicolumn{4}{|c|}{\textbf{CSR圧縮}} \\
        \hline
        CSR圧縮 & 40 & 8,488バイト & 25\% \\
        \hline
        CSR圧縮 & 80 & 9,508バイト & 29\% \\
        \hline
        CSR圧縮 & 120 & 10,520バイト & 32\% \\
        \hline
        CSR圧縮 & 160 & 11,332バイト & 34\% \\
        \hline
        CSR圧縮 & 200 & 12,332バイト & 37\% \\
        \hline
        CSR圧縮 & 400 & 17,204バイト & 52\% \\
        \hline
        CSR圧縮 & 600 & 21,976バイト & 67\% \\
        \hline
        CSR圧縮 & 800 & \multicolumn{2}{c|}{コンパイルエラー} \\
        \hline
        \hline
        \multicolumn{4}{|c|}{\textbf{CSR＋量子化}} \\
        \hline
        CSR＋量子化 & 40 & 8,160バイト & 24\% \\
        \hline
        CSR＋量子化 & 80 & 9,148バイト & 27\% \\
        \hline
        CSR＋量子化 & 120 & 10,132バイト & 30\% \\
        \hline
        CSR＋量子化 & 160 & 12,000バイト & 36\% \\
        \hline
        CSR＋量子化 & 200 & 12,000バイト & 36\% \\
        \hline
        CSR＋量子化 & 400 & 16,836バイト & 51\% \\
        \hline
        CSR＋量子化 & 600 & 21,684バイト & 66\% \\
        \hline
        CSR＋量子化 & 800 & \multicolumn{2}{c|}{コンパイルエラー} \\
        \hline
    \end{tabular}
\end{table}


\clearpage
図\ref{fig:memory_120dim}に隠れ層次元120までのメモリ使用量の推移を，図\ref{fig:memory_600dim}に600次元までの推移を示す．

\begin{figure}[h]
    \centering
    \includegraphics[width=14cm]{結果/memory/memory_vs_dimension_120dim.png}
    \caption{隠れ層次元とメモリ使用量の関係（120次元まで）}
    \label{fig:memory_120dim}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=14cm]{結果/memory/memory_vs_dimension_600dim.png}
    \caption{隠れ層次元とメモリ使用量の関係（600次元まで）}
    \label{fig:memory_600dim}
\end{figure}

\clearpage
\subsection{コンパイル時間}
各条件におけるArduino IDEでのコンパイル時間を表\ref{tab:results_compile_time}に示す．

\begin{table}[h]
    \centering
    \caption{圧縮手法別コンパイル時間}
    \label{tab:results_compile_time}
    \begin{tabular}{|l|c|c|}
        \hline
        \textbf{圧縮手法} & \textbf{隠れ層次元} & \textbf{コンパイル時間} \\
        \hline
        \hline
        \multicolumn{3}{|c|}{\textbf{密行列形式}} \\
        \hline
        密行列形式 & 40 & 4.303秒 \\
        \hline
        密行列形式 & 50 & 4.589秒 \\
        \hline
        密行列形式 & 60 & 4.831秒 \\
        \hline
        密行列形式 & 70 & コンパイルエラー \\
        \hline
        \hline
        \multicolumn{3}{|c|}{\textbf{CSR圧縮}} \\
        \hline
        CSR圧縮 & 40 & 3.783秒 \\
        \hline
        CSR圧縮 & 80 & 4.037秒 \\
        \hline
        CSR圧縮 & 120 & 4.062秒 \\
        \hline
        CSR圧縮 & 160 & 4.042秒 \\
        \hline
        CSR圧縮 & 200 & 4.027秒 \\
        \hline
        CSR圧縮 & 400 & 4.316秒 \\
        \hline
        CSR圧縮 & 600 & 4.802秒 \\
        \hline
        CSR圧縮 & 800 & コンパイルエラー \\
        \hline
        \hline
        \multicolumn{3}{|c|}{\textbf{CSR＋量子化}} \\
        \hline
        CSR＋量子化 & 40 & 3.772秒 \\
        \hline
        CSR＋量子化 & 80 & 3.809秒 \\
        \hline
        CSR＋量子化 & 120 & 4.028秒 \\
        \hline
        CSR＋量子化 & 160 & 4.033秒 \\
        \hline
        CSR＋量子化 & 200 & 4.033秒 \\
        \hline
        CSR＋量子化 & 400 & 4.307秒 \\
        \hline
        CSR＋量子化 & 600 & 4.801秒 \\
        \hline
        CSR＋量子化 & 800 & コンパイルエラー \\
        \hline
    \end{tabular}
\end{table}

\clearpage

図\ref{fig:compile_time_120dim}に隠れ層次元120までのコンパイル時間の推移を，図\ref{fig:compile_time_600dim}に600次元までの推移を示す．

\begin{figure}[h]
    \centering
    \includegraphics[width=14cm]{結果/compile_time/compile_time_vs_dimension_120dim.png}
    \caption{隠れ層次元とコンパイル時間の関係（120次元まで）}
    \label{fig:compile_time_120dim}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=14cm]{結果/compile_time/compile_time_vs_dimension_600dim.png}
    \caption{隠れ層次元とコンパイル時間の関係（600次元まで）}
    \label{fig:compile_time_600dim}
\end{figure}

\clearpage
\subsection{結果のまとめ}

実験結果を，実験目的である「隠れ層次元の拡張」と「推論精度の維持」の観点からまとめる．

\subsubsection{隠れ層次元の拡張可能範囲}

各圧縮手法における動作可能な最大次元は以下のとおりであった．

\begin{itemize}
    \item 密行列形式：60次元（メモリ使用率70\%），70次元でコンパイルエラー
    \item CSR圧縮：600次元（メモリ使用率67\%），800次元でコンパイルエラー
    \item CSR＋量子化：600次元（メモリ使用率66\%），800次元でコンパイルエラー
\end{itemize}

CSR圧縮により，密行列形式と比較して約10倍の次元拡張が可能となり，目標である600次元以上の動作を達成した．

\subsubsection{推論精度（MSE）}

40次元における各手法のMSE平均値は，密行列形式が595.95，CSR圧縮が518.58，CSR＋量子化が408.97であった．
CSR＋量子化は密行列形式と比較して約31\%のMSE改善を達成した．

測定済みの範囲において最良のMSE平均値は，CSR＋量子化（120次元）の244.83であった．
一方，CSR圧縮では次元を増加させてもMSEが単調に減少せず，120次元で620.49，400次元で864.40とばらつきが見られた．


\subsubsection{メモリ効率}

40次元における各手法のメモリ使用量は，密行列形式が14,524バイト（44\%），CSR圧縮が8,488バイト（25\%），CSR＋量子化が8,160バイト（24\%）であった．
CSR圧縮により約42\%，CSR＋量子化により約44\%のメモリ削減を達成した．

\subsubsection{コンパイル時間}

コンパイル時間は全条件で3.7〜4.8秒の範囲であり，圧縮手法による顕著な差は見られなかった．
隠れ層次元の増加に伴いコンパイル時間は緩やかに増加したが，実用上の問題となる水準ではなかった．

詳細な考察は次章で述べる．
各実験条件における個別のスキャン結果は付録\ref{sec:appendix_detail}に示す．

\clearpage

\section{考察}

実験結果に基づき，各圧縮手法の特性と得られた知見について考察する．

\subsection{実験目的の達成度}

第\ref{sec:staged_compression}節で述べた段階的圧縮アプローチにより，以下の成果が得られた．

\subsubsection{隠れ層次元の拡張}

目標であった隠れ層次元600以上への拡張は，CSR圧縮およびCSR＋量子化の両手法で達成された．
表\ref{tab:results_memory}に示すように，密行列形式では60次元（メモリ使用率70\%）が限界であったのに対し，CSR圧縮では600次元（メモリ使用率67\%）まで動作可能となり，約10倍の次元拡張を実現した．

この結果は，L1正則化によるプルーニングとCSR形式の組み合わせが，メモリ制約の厳しいマイクロコントローラ環境において有効であることを示している．

\subsubsection{推論精度の維持}

表\ref{tab:results_mse_comparison}に示すMSE平均値の観点では，CSR＋量子化（120次元）が244.83で最良の結果を示した．
これは密行列形式（60次元）の305.48を約20\%上回る性能であり，圧縮によって次元拡張と精度向上の両立が可能であることが示された．

\subsection{各圧縮手法の特性分析}

\subsubsection{密行列形式の特性}

表\ref{tab:results_by_dimension}より，密行列形式では隠れ層次元の増加に伴いMSEが単調に減少した（40次元：595.95 → 60次元：305.48）．
これは，次元増加によりモデルの表現能力が向上し，RGB補正の精度が改善されたことを示している．
図\ref{fig:mse_120dim}においても，密行列形式のMSEが次元増加に伴い減少する傾向が確認できる．

一方，表\ref{tab:results_memory}に示すように，メモリ使用量は次元の2乗に比例して増加するため，70次元でメモリ制約を超過した．
この結果は，第\ref{sec:memory_constraint}節で述べたメモリ制約の影響を実験的に検証できた．

\subsubsection{CSR圧縮の特性}

CSR圧縮では，隠れ層次元を増加させてもMSEが単調に減少せず，大きなばらつきが観測された．
表\ref{tab:results_mse_comparison}より，MSE平均値は80次元で464.86，120次元で620.49，200次元で493.35と不規則に変動している．
図\ref{fig:mse_600dim}においても，CSR圧縮（青線）が次元増加に対して非単調な挙動を示していることが視覚的に確認できる．

さらに，表\ref{tab:results_mse_comparison}の最小値・最大値から算出した最大/最小比は，40次元で2.14，200次元で3.36，600次元で8.46と，次元が大きくなるほど増大している．
このばらつきの原因として，以下の要因が考えられる．

\paragraph{プルーニング閾値の固定による影響}

本実験ではプルーニング閾値を0.01に固定した．
しかし，隠れ層次元が増加すると，L1正則化により各重みの絶対値は相対的に小さくなる傾向がある．
これは，同じ出力を得るために多数のニューロンで負荷を分散するためである．

その結果，大きな次元のモデルでは，閾値0.01によって削除される重みの割合が増加し，本来保持すべき重要な接続が失われる可能性がある．
表\ref{tab:results_memory}より，CSR圧縮のメモリ使用量は40次元で8,488バイト，600次元で21,976バイトであり，次元が15倍になってもメモリは約2.6倍にしか増加していない．
これは，高次元モデルほどプルーニングにより多くの重みが削除されていることを示唆している．

\paragraph{疎行列構造の不均一性}

CSR形式では，行（ニューロン）ごとに非ゼロ要素数が異なる．
プルーニングにより一部のニューロンの接続が極端に少なくなると，そのニューロンの出力が不安定になり，後続の層に誤差が伝播する．

特に，入力層から隠れ層1への接続は3次元からの拡張であるため，プルーニングにより特定の入力チャネル（R, G, Bのいずれか）との接続が失われると，色補正の精度に大きな影響を与える可能性がある．

\paragraph{スキャンごとのばらつき増大}

表\ref{tab:results_mse_comparison}に示すように，次元が大きくなるほどMSEの最大値と最小値の差が拡大している．
600次元では最小値253.44に対し最大値2143.81と約8.5倍の開きがある．
これは，プルーニング後のネットワークが特定の入力パターンに対して脆弱になっていることを示唆する．
センサーのノイズや環境光の変動が，大次元モデルではより大きなMSE変動として現れていると考えられる．

\subsubsection{CSR＋量子化の特性}

表\ref{tab:results_mse_comparison}より，CSR＋量子化ではCSR圧縮と異なり，次元増加に伴いMSEが安定して減少した（40次元：408.97 → 120次元：244.83）．
図\ref{fig:mse_120dim}においても，CSR＋量子化（黄色線）が最も低いMSEを示し，次元増加に対して単調に減少していることが確認できる．

また，表\ref{tab:results_mse_comparison}より，スキャンごとのばらつきも小さく，120次元で最大/最小比は1.83（最小169.37，最大310.63）であった．
この安定性の要因として，以下が考えられる．

\paragraph{量子化による正則化効果}

int8量子化では，重みが$-128$〜$127$の離散値に制限される．
この離散化は，一種の正則化として機能し，過学習を抑制する効果がある．

具体的には，プルーニング後に残った小さな重み（例：0.02）が，量子化によって0または1に丸められることで，ノイズ的な重みが除去され，有意な重みのみが保持される．
この効果により，CSR圧縮単体で見られた高次元でのMSEばらつきが抑制されたと考えられる．

\paragraph{スケールファクタによる重みの正規化}

量子化では，各層ごとにスケールファクタを計算する：
\begin{equation}
    \text{scale} = \frac{127.0}{\max(|w|)}
\end{equation}

このスケーリングにより，極端に大きな重みや小さな重みが抑制され，重みの分布が均一化される効果がある．
結果として，特定のニューロンへの依存度が下がり，推論精度が向上した．

\paragraph{プルーニングと量子化の相乗効果}

Hanら\cite{han2016deep}は，プルーニングと量子化を組み合わせた「Deep Compression」により，精度を維持しながらAlexNetを35倍，VGG-16を49倍圧縮できることを示した．
同論文では，プルーニングのみまたは量子化のみでは8\%程度までしか圧縮できないと精度が急落するのに対し，両手法を組み合わせると3\%程度まで圧縮しても精度維持が可能になることが報告されている．

本実験においても，プルーニングで残った重みに量子化を適用することで，以下の相乗効果が生じたと考えられる．

\begin{enumerate}
    \item プルーニングにより量子化対象の重みが減少し，量子化誤差の総量が抑制される
    \item 量子化によりプルーニング境界付近の微小な重みが0に丸められ，実質的に追加のプルーニングが行われる
    \item 両手法の組み合わせにより，「重要な重みを高精度で保持し，不要な重みを徹底的に除去する」という効果が得られる
\end{enumerate}

表\ref{tab:results_by_dimension}において，同一の40次元で比較すると，密行列形式（595.95）→ CSR圧縮（518.58）→ CSR＋量子化（408.97）の順にMSEが改善している．
これは，圧縮手法を段階的に適用することで推論精度が向上するという，Hanらの報告と整合する結果である．
\clearpage
\section{終わりに}

本研究では，Arduino Uno R4 WiFiのメモリ制約下において，ニューラルネットワークの圧縮手法を段階的に適用し，
推論精度を維持しながら隠れ層次元を拡張できるかを検証した．

実験の結果，以下の知見が得られた．
L1正則化によるプルーニングとCSR形式を組み合わせることで，密行列形式では60次元が限界であった隠れ層を600次元まで拡張でき，約10倍の次元拡張を実現した．
さらに，CSR形式に量子化を追加適用することで，MSE平均値が密行列形式（60次元）の305.48からCSR＋量子化（120次元）の244.83へと約20\%改善し，圧縮と精度向上の両立が可能であることを示した．
また，Hanらが報告したプルーニングと量子化の相乗効果が，本実験のような小規模モデルにおいても有効であることを確認した．

一方，固定閾値によるプルーニングでは高次元モデルにおいてMSEのばらつきが増大する課題が明らかになった．
今後は，さらなる精度向上ができるように研究を進めたい．

本研究は，組込み機器やIoTデバイスのようなリソース制約の厳しい環境においても，適切な圧縮手法を用いることで実用的なニューラルネットワーク推論が可能であることを示せた．


\clearpage
\begin{thebibliography}{9}
\bibitem{han2015deep} Song Han et al., ``Learning both Weights and Connections for Efficient Neural Networks,'' NeurIPS, 2015.
\bibitem{jacob2018quantization} B. Jacob et al., ``Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference,'' CVPR, 2018.
\bibitem{han2016deep}
S. Han, H. Mao, and W. J. Dally,
``Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding,''
in Proc. International Conference on Learning Representations (ICLR), 2016.
\end{thebibliography}



\clearpage
\appendix
\section{詳細測定データ}
\label{sec:appendix_detail}
本付録では，各実験条件における個別のスキャン結果を示す．
各条件につき10回のスキャンを実施し，MSEを算出した．

\subsection{非圧縮（密行列形式）の詳細測定結果}
表\ref{tab:appendix_dense}に，密行列形式モデルの個別スキャン結果を示す．

\begin{table}[h]
    \centering
    \caption{密行列形式の詳細測定結果（MSE）}
    \label{tab:appendix_dense}
    \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{スキャン} & \textbf{40次元} & \textbf{50次元} & \textbf{60次元} \\
        \hline
        1 & 484.04 & 369.30 & 193.07 \\
        \hline
        2 & 713.74 & 486.26 & 138.00 \\
        \hline
        3 & 733.93 & 444.11 & 376.22 \\
        \hline
        4 & 277.67 & 472.78 & 227.26 \\
        \hline
        5 & 782.33 & 416.04 & 423.22 \\
        \hline
        6 & 715.63 & 231.11 & 332.41 \\
        \hline
        7 & 523.63 & 463.85 & 297.22 \\
        \hline
        8 & 792.85 & 307.26 & 417.44 \\
        \hline
        9 & 284.15 & 342.67 & 240.33 \\
        \hline
        10 & 651.52 & 535.59 & 409.30 \\
        \hline
        \hline
        \textbf{最小値} & 277.67 & 231.11 & 138.00 \\
        \hline
        \textbf{最大値} & 792.85 & 535.59 & 423.22 \\
        \hline
        \textbf{平均値} & 595.95 & 406.93 & 305.48 \\
        \hline
    \end{tabular}
\end{table}

各次元におけるメモリ使用量とコンパイル時間を以下に示す．

\begin{itemize}
    \item \textbf{40次元}：メモリ使用量 14,524バイト（44\%），コンパイル時間 4.303秒
    \item \textbf{50次元}：メモリ使用量 18,444バイト（56\%），コンパイル時間 4.589秒
    \item \textbf{60次元}：メモリ使用量 23,164バイト（70\%），コンパイル時間 4.831秒
    \item \textbf{70次元}：コンパイルエラー（メモリ不足）
\end{itemize}

\clearpage

\subsection{CSR圧縮の詳細測定結果}
表\ref{tab:appendix_csr}に，CSR圧縮モデルの個別スキャン結果を示す．

\begin{table}[h]
    \centering
    \caption{CSR圧縮の詳細測定結果（MSE）}
    \label{tab:appendix_csr}
    \begin{tabular}{|c|c|c|c|c|c|c|c|}
        \hline
        \textbf{スキャン} & \textbf{40次元} & \textbf{80次元} & \textbf{120次元} & \textbf{160次元} & \textbf{200次元} & \textbf{400次元} & \textbf{600次元} \\
        \hline
        1 & 600.00 & 644.59 & 724.67 & 394.30 & 563.52 & 390.89 & 740.33 \\
        \hline
        2 & 517.48 & 459.37 & 295.37 & 516.96 & 291.41 & 736.11 & 1427.52 \\
        \hline
        3 & 569.78 & 361.33 & 663.78 & 663.78 & 235.52 & 701.15 & 2143.81 \\
        \hline
        4 & 659.04 & 225.19 & 514.59 & 668.63 & 675.11 & 324.52 & 285.26 \\
        \hline
        5 & 324.00 & 729.26 & 694.22 & 1179.59 & 662.07 & 616.00 & 253.44 \\
        \hline
        6 & 365.07 & 408.15 & 710.96 & 353.07 & 714.96 & 1127.33 & 258.63 \\
        \hline
        7 & 522.59 & 380.59 & 656.44 & 686.56 & 678.93 & 421.78 & 292.15 \\
        \hline
        8 & 495.04 & 499.85 & 584.59 & 295.52 & 462.56 & 1913.30 & 384.85 \\
        \hline
        9 & 692.37 & 437.44 & 814.33 & 434.04 & 979.85 & 1978.81 & 326.15 \\
        \hline
        10 & 440.41 & 472.85 & 545.93 & 698.33 & 331.59 & 434.30 & 594.78 \\
        \hline
        \hline
        \textbf{最小値} & 324.00 & 225.19 & 295.37 & 295.52 & 291.41 & 390.89 & 253.44 \\
        \hline
        \textbf{最大値} & 692.37 & 729.26 & 814.33 & 1179.59 & 979.85 & 1978.81 & 2143.81 \\
        \hline
        \textbf{平均値} & 518.58 & 464.86 & 620.49 & 589.08 & 493.35 & 864.40 & 670.69 \\
        \hline
    \end{tabular}
\end{table}

各次元におけるメモリ使用量とコンパイル時間を以下に示す．

\begin{itemize}
    \item \textbf{40次元}：メモリ使用量 8,488バイト（25\%），コンパイル時間 3.783秒
    \item \textbf{80次元}：メモリ使用量 9,508バイト（29\%），コンパイル時間 4.037秒
    \item \textbf{120次元}：メモリ使用量 10,520バイト（32\%），コンパイル時間 4.062秒
    \item \textbf{160次元}：メモリ使用量 11,332バイト（34\%），コンパイル時間 4.042秒
    \item \textbf{200次元}：メモリ使用量 12,332バイト（37\%），コンパイル時間 4.027秒
    \item \textbf{400次元}：メモリ使用量 17,204バイト（52\%），コンパイル時間 4.316秒
    \item \textbf{600次元}：メモリ使用量 21,976バイト（67\%），コンパイル時間 4.802秒
    \item \textbf{800次元}：コンパイルエラー（メモリ不足）
\end{itemize}

\clearpage
\subsection{CSR＋量子化の詳細測定結果}
表\ref{tab:appendix_quantized}に，CSR＋量子化モデルの個別スキャン結果を示す．

\begin{table}[h]
    \centering
    \caption{CSR＋量子化の詳細測定結果（MSE）}
    \label{tab:appendix_quantized}
    \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{スキャン} & \textbf{40次元} & \textbf{80次元} & \textbf{120次元} \\
        \hline
        1 & 289.30 & 235.74 & 297.70 \\
        \hline
        2 & 304.44 & 237.63 & 180.11 \\
        \hline
        3 & 381.19 & 200.22 & 239.15 \\
        \hline
        4 & 588.15 & 292.22 & 310.63 \\
        \hline
        5 & 278.78 & 282.70 & 309.41 \\
        \hline
        6 & 471.30 & 268.26 & 169.37 \\
        \hline
        7 & 582.63 & 323.96 & 228.59 \\
        \hline
        8 & 324.44 & 270.19 & 257.85 \\
        \hline
        9 & 321.37 & 313.37 & 196.19 \\
        \hline
        10 & 548.11 & 282.48 & 259.30 \\
        \hline
        \hline
        \textbf{最小値} & 278.78 & 200.22 & 169.37 \\
        \hline
        \textbf{最大値} & 588.15 & 323.96 & 310.63 \\
        \hline
        \textbf{平均値} & 408.97 & 270.68 & 244.83 \\
        \hline
    \end{tabular}
\end{table}

各次元におけるメモリ使用量とコンパイル時間を以下に示す．

\begin{itemize}
    \item \textbf{40次元}：メモリ使用量 8,160バイト（24\%），コンパイル時間 3.772秒
    \item \textbf{80次元}：メモリ使用量 9,148バイト（27\%），コンパイル時間 3.809秒
    \item \textbf{120次元}：メモリ使用量 10,132バイト（30\%），コンパイル時間 4.028秒
    \item \textbf{160次元}：メモリ使用量 12,000バイト（36\%），コンパイル時間 4.033秒（MSE測定未実施）
    \item \textbf{200次元}：メモリ使用量 12,000バイト（36\%），コンパイル時間 4.033秒（MSE測定未実施）
    \item \textbf{400次元}：メモリ使用量 16,836バイト（51\%），コンパイル時間 4.307秒（MSE測定未実施）
    \item \textbf{600次元}：メモリ使用量 21,684バイト（66\%），コンパイル時間 4.801秒（MSE測定未実施）
    \item \textbf{800次元}：コンパイルエラー（メモリ不足）
\end{itemize}

\clearpage
\section{ソースコード}
\label{sec:appendix_code}

本付録では，実験で使用したソースコードを示す．

\subsection{AI\_Model.ino}
\label{sec:code_ai_model}

\begin{lstlisting}[language=C++,caption=AI\_Model.ino,label=code:ai_model]
#include <Arduino.h>
#include "model_parameters40.h"

// 隠れ層次元（パラメータファイルと一致させる）
#define HIDDEN_DIM 40

// RGB点灯遅延
#define RgbFlashDelay 50 

// ピン割り当て
#define PIN_IN A0
#define led_r_pin 8
#define led_g_pin 6
#define led_b_pin 7
#define buttonInputPin 3
#define buttonMinMaxPin 2

// ボタン押下を検知する変数 (余計な最適化を防ぐため、volatile宣言をしている)
volatile bool buttonInputPressed = false;
volatile bool buttonMinMaxPressed = false;

// RGB読み取り用変数
float r=0, g=0, b=0;
float r_max=512, g_max=512, b_max=512;
float r_min=0, g_min=0, b_min=0;

float rgb[3]{0, 0, 0};
float RGBInput[3]{0, 0, 0};
float RGBOutput[3]{0, 0, 0};

// RGBデータメモリ
int N, M;
float **array;
int n=0, m=0;

int pushed = 0;

void buttonInput() {
    buttonInputPressed = true;
}


void buttonMinMax() {
    buttonMinMaxPressed = true;
}


float **allocateArray(int N, int M) {
    float **array = (float **)malloc(N * sizeof(float *)); // 行ポインタの確保
    if (array == NULL) {
        Serial.println("メモリ確保失敗");
        return NULL;
    }

    for (int i = 0; i < N; i++) {
        array[i] = (float *)malloc(M * sizeof(float)); // 各行のメモリ確保
        if (array[i] == NULL) {
            Serial.println("メモリ確保失敗（部分的）");
            // 確保済みのメモリを解放して終了
            for (int j = 0; j < i; j++) {
                free(array[j]);
            }
            free(array);
            return NULL;
        }
    }
    return array;
}

void read(){
    for(int count = 0 ; count < 3 ; count++){
        if(count == 0){
            analogWrite(led_r_pin, 255);
            analogWrite(led_g_pin,   0);
            analogWrite(led_b_pin,   0);
            delay(RgbFlashDelay);
            rgb[0] = analogRead(PIN_IN);
        }else if(count == 1){
            analogWrite(led_r_pin,   0);
            analogWrite(led_g_pin, 255); 
            analogWrite(led_b_pin,   0);
            delay(RgbFlashDelay);
            rgb[1] = analogRead(PIN_IN);
        }else{
            analogWrite(led_r_pin,   0);
            analogWrite(led_g_pin,   0);
            analogWrite(led_b_pin, 255);
            delay(RgbFlashDelay);     
            rgb[2] = analogRead(PIN_IN);
        }
    }
    analogWrite(led_r_pin, 0);
    analogWrite(led_g_pin, 0);
    analogWrite(led_b_pin, 0);
}

static inline float relu(float x){ return x > 0 ? x : 0; }

void layer1_dense_relu(const float x[3], float h1[HIDDEN_DIM]){
	for(int j=0;j<HIDDEN_DIM;++j){
		float s = bias_1[j];
		for(int i=0;i<3;++i) s += weight_1[j*3 + i] * x[i];
		h1[j] = relu(s);
	}
}

void layer2_dense_relu(const float h1[HIDDEN_DIM], float h2[HIDDEN_DIM]){
	for(int r=0;r<HIDDEN_DIM;++r){
		float s = bias_2[r];
		for(int c=0;c<HIDDEN_DIM;++c) s += weight_2[r*HIDDEN_DIM + c] * h1[c];
		h2[r] = relu(s);
	}
}

void layer3_dense(const float h2[HIDDEN_DIM], float y[3]){
	for(int m=0;m<3;++m){
		float s = bias_3[m];
		for(int k=0;k<HIDDEN_DIM;++k) s += weight_3[m*HIDDEN_DIM + k] * h2[k];
		y[m] = s;
	}
}

// predict
static void predict(const float in_rgb[3], float out_rgb[3]){
	float h1[HIDDEN_DIM], h2[HIDDEN_DIM];
	layer1_dense_relu(in_rgb, h1);
	layer2_dense_relu(h1, h2);
	layer3_dense(h2, out_rgb);
}


// Arduino's analog input detects 0-5V with 10-bit values
// https://deviceplus.jp/arduino/arduino_f07/
void readAndProcess(){
    read();
    RGBInput[0] = (float(rgb[0])-r_min)/r_max;
    RGBInput[1] = (float(rgb[1])-g_min)/g_max;
    RGBInput[2] = (float(rgb[2])-b_min)/b_max;
    
    // Monitoring read value
    // Serial.print("Measured B, R, G: ");
    // Serial.println(String(RGBInput[2])+","+String(RGBInput[0])+","+String(RGBInput[1]));    

    // ニューラルネットで読み込み値を修正
    micros();
    predict(RGBInput, RGBOutput);
    micros();
    
    // 0-255でクリッピング
    RGBOutput[0] = min(max(RGBOutput[0]*255, 0), 255);
    RGBOutput[1] = min(max(RGBOutput[1]*255, 0), 255);
    RGBOutput[2] = min(max(RGBOutput[2]*255, 0), 255);

    // Serial.print("Predicted B, R, G: ");
    Serial.println("Blue:"+String((int)RGBOutput[2]) + ", Red:"+String((int)RGBOutput[0]) + ", Green:"+ String((int)RGBOutput[1]));
    // Serial.println("Red:"+String(RGBInput[0]) + ", Green:"+ String(RGBInput[1]) + ", Blue:"+String(RGBInput[2]));
}

// このリセットコードは旧版Arduino用、Arduino UNO R4 WiFiでは不要
// void softwareReset() {
//     asm volatile ("jmp 0");  // プログラムカウンタをリセット
// }


void setup() {
  // put your setup code here, to run once:
    Serial.begin(9600);
    pinMode(led_r_pin, OUTPUT);
    pinMode(led_g_pin, OUTPUT);
    pinMode(led_b_pin, OUTPUT);
    analogWrite(led_r_pin, 0);
    analogWrite(led_b_pin, 0);
    analogWrite(led_g_pin, 0);

    pinMode(buttonInputPin, INPUT_PULLUP);pinMode(buttonMinMaxPin, INPUT_PULLUP);

    attachInterrupt(digitalPinToInterrupt(buttonInputPin), buttonInput, FALLING);
    attachInterrupt(digitalPinToInterrupt(buttonMinMaxPin), buttonMinMax, FALLING);

    Serial.println("画像の Height（行数）を入力してください: ");
    while (Serial.available() == 0) {
        // 何もせずに待機
    }
    N = Serial.parseInt();
    M = N*3; // RGBの値を入れるために3倍しておく
    Serial.println("Height: " + String(N));
    Serial.println("Width: " + String((int)(M/3)));
    array = allocateArray(N, M);

    if (array == NULL) {
        Serial.println("配列の確保に失敗");
        return;
    }

    // 配列を初期化
    for (int i = 0; i < N; i++) {
        for (int j = 0; j < M; j++) {
            array[i][j] = 0;
        }
    }
}

void loop() {
  // put your main code here, to run repeatedly:
    readAndProcess();

    if (buttonInputPressed) {
        array[n][m]   = RGBOutput[0];
        array[n][m+1] = RGBOutput[1];
        array[n][m+2] = RGBOutput[2];

        Serial.println(String(n)+" 行目 "+String((int)(m/3))+" 列目 の画素を読み込みました。");

        if((m+=3)>=M){
            m = 0 ;
            if((n+=1)>=N){
                n = 0;
                Serial.println("画像の読み取りが完了しました。");
                Serial.println("以下のテキストを画像ファイル（.ppm）に貼り付けてください。");
                Serial.println("--------------------------------------------------");
                Serial.println("P3");
                Serial.println(String(N)+" "+String((int)(M/3)));
                Serial.println("255");
                for (int i = 0; i < N; i++) {
                    for (int j = 0; j < M; j++) {
                        Serial.print((int)array[i][j]);
                        Serial.print(" ");
                    }
                    Serial.println();
                }
                Serial.println("--------------------------------------------------");
                Serial.println();
                delay(500); 
                // softwareReset();
                NVIC_SystemReset();
            } 
        }
        buttonInputPressed = false;
    }

    if (buttonMinMaxPressed) {
        if(pushed%2==0){
            r_min=rgb[0], g_min=rgb[1], b_min=rgb[2];
            Serial.println("最小値が更新されました："+String(b_min)+","+String(r_min)+","+String(g_min));
        }
        else{
            r_max=rgb[0]-r_min, g_max=rgb[1]-g_min, b_max=rgb[2]-b_min;
            Serial.println("最大値が更新されました："+String(b_max)+","+String(r_max)+","+String(g_max));
        }
        buttonMinMaxPressed = false;  // フラグをリセット
        pushed++;
        delay(500);
    }
}
\end{lstlisting}

\clearpage
\subsection{AI\_CSR.ino}
\label{sec:code_ai_csr}

\begin{lstlisting}[language=C++,caption=AI\_CSR.ino,label=code:ai_csr]
#include <Arduino.h>
#include "model_parameters600.h"
#include "model_parameters_csr600.h"

// ========== モデル設定 ==========
// 注意: この値は学習時に使用したHIDDEN_DIMと一致させること
#ifndef HIDDEN_DIM
#define HIDDEN_DIM 600  // 隠れ層の次元（学習時の値と一致させる）
#endif
// =================================

// RGB点灯遅延
#define RgbFlashDelay 50

// ピン割り当て
#define PIN_IN A0
#define led_r_pin 8
#define led_g_pin 6
#define led_b_pin 7
#define buttonInputPin 3
#define buttonMinMaxPin 2

// ボタン押下を検知する変数 (余計な最適化を防ぐため、volatile宣言をしている)
volatile bool buttonInputPressed = false;
volatile bool buttonMinMaxPressed = false;

// RGB読み取り用変数
float r=0, g=0, b=0;
float r_max=512, g_max=512, b_max=512;
float r_min=0, g_min=0, b_min=0;

float rgb[3]{0, 0, 0};
float RGBInput[3]{0, 0, 0};
float RGBOutput[3]{0, 0, 0};

// RGBデータメモリ
int N, M;
float **array;
int n=0, m=0;

int pushed = 0;

void buttonInput() {
    buttonInputPressed = true;
}


void buttonMinMax() {
    buttonMinMaxPressed = true;
}


float **allocateArray(int N, int M) {
    float **array = (float **)malloc(N * sizeof(float *)); // 行ポインタの確保
    if (array == NULL) {
        Serial.println("メモリ確保失敗");
        return NULL;
    }

    for (int i = 0; i < N; i++) {
        array[i] = (float *)malloc(M * sizeof(float)); // 各行のメモリ確保
        if (array[i] == NULL) {
            Serial.println("メモリ確保失敗（部分的）");
            // 確保済みのメモリを解放して終了
            for (int j = 0; j < i; j++) {
                free(array[j]);
            }
            free(array);
            return NULL;
        }
    }
    return array;
}

void read(){
    for(int count = 0 ; count < 3 ; count++){
        if(count == 0){
            analogWrite(led_r_pin, 255);
            analogWrite(led_g_pin,   0);
            analogWrite(led_b_pin,   0);
            delay(RgbFlashDelay);
            rgb[0] = analogRead(PIN_IN);
        }else if(count == 1){
            analogWrite(led_r_pin,   0);
            analogWrite(led_g_pin, 255); 
            analogWrite(led_b_pin,   0);
            delay(RgbFlashDelay);
            rgb[1] = analogRead(PIN_IN);
        }else{
            analogWrite(led_r_pin,   0);
            analogWrite(led_g_pin,   0);
            analogWrite(led_b_pin, 255);
            delay(RgbFlashDelay);     
            rgb[2] = analogRead(PIN_IN);
        }
    }
    analogWrite(led_r_pin, 0);
    analogWrite(led_g_pin, 0);
    analogWrite(led_b_pin, 0);
}

static inline float relu(float x){ return x > 0 ? x : 0; }

void layer1_csr_relu(const float x[3], float h1[HIDDEN_DIM]){
	for(int r=0;r<HIDDEN_DIM;++r){
		float s = 0.0f;
		uint16_t start = indptr_1[r];
		uint16_t end   = indptr_1[r+1];
		for(uint16_t p=start;p<end;++p){
			uint16_t c = indices_1[p];
			s += data_1[p] * x[c];
		}
		s += bias_1[r];
		h1[r] = relu(s);
	}
}

void layer2_csr_relu(const float h1[HIDDEN_DIM], float h2[HIDDEN_DIM]){
	for(int r=0;r<HIDDEN_DIM;++r){
		float s = 0.0f;
		uint16_t start = indptr_2[r];
		uint16_t end   = indptr_2[r+1];
		for(uint16_t p=start;p<end;++p){
			uint16_t c = indices_2[p];
			s += data_2[p] * h1[c];
		}
		s += bias_2[r];
		h2[r] = relu(s);
	}
}

void layer3_dense(const float h2[HIDDEN_DIM], float y[3]){
	for(int m=0;m<3;++m){
		float s = bias_3[m];
		for(int k=0;k<HIDDEN_DIM;++k) s += weight_3[m*HIDDEN_DIM + k] * h2[k];
		y[m] = s;
	}
}

// predict
static void predict(const float in_rgb[3], float out_rgb[3]){
	float h1[HIDDEN_DIM], h2[HIDDEN_DIM];
	layer1_csr_relu(in_rgb, h1);
	layer2_csr_relu(h1, h2);
	layer3_dense(h2, out_rgb);
}


// Arduino's analog input detects 0-5V with 10-bit values
// https://deviceplus.jp/arduino/arduino_f07/
void readAndProcess(){
    read();
    RGBInput[0] = (float(rgb[0])-r_min)/r_max;
    RGBInput[1] = (float(rgb[1])-g_min)/g_max;
    RGBInput[2] = (float(rgb[2])-b_min)/b_max;
    
    // Monitoring read value
    // Serial.print("Measured B, R, G: ");
    // Serial.println(String(RGBInput[2])+","+String(RGBInput[0])+","+String(RGBInput[1]));    

    // ニューラルネットで読み込み値を修正
    micros();
    predict(RGBInput, RGBOutput);
    micros();
    
    // 0-255でクリッピング
    RGBOutput[0] = min(max(RGBOutput[0]*255, 0), 255);
    RGBOutput[1] = min(max(RGBOutput[1]*255, 0), 255);
    RGBOutput[2] = min(max(RGBOutput[2]*255, 0), 255);

    // Serial.print("Predicted B, R, G: ");
    Serial.println("Blue:"+String((int)RGBOutput[2]) + ", Red:"+String((int)RGBOutput[0]) + ", Green:"+ String((int)RGBOutput[1]));
    // Serial.println("Red:"+String(RGBInput[0]) + ", Green:"+ String(RGBInput[1]) + ", Blue:"+String(RGBInput[2]));
}

// このリセットコードは旧版Arduino用、Arduino UNO R4 WiFiでは不要
// void softwareReset() {
//     asm volatile ("jmp 0");  // プログラムカウンタをリセット
// }


void setup() {
  // put your setup code here, to run once:
    Serial.begin(9600);
    pinMode(led_r_pin, OUTPUT);
    pinMode(led_g_pin, OUTPUT);
    pinMode(led_b_pin, OUTPUT);
    analogWrite(led_r_pin, 0);
    analogWrite(led_b_pin, 0);
    analogWrite(led_g_pin, 0);

    pinMode(buttonInputPin, INPUT_PULLUP);pinMode(buttonMinMaxPin, INPUT_PULLUP);

    attachInterrupt(digitalPinToInterrupt(buttonInputPin), buttonInput, FALLING);
    attachInterrupt(digitalPinToInterrupt(buttonMinMaxPin), buttonMinMax, FALLING);

    Serial.println("画像の Height（行数）を入力してください: ");
    while (Serial.available() == 0) {
        // 何もせずに待機
    }
    N = Serial.parseInt();
    M = N*3; // RGBの値を入れるために3倍しておく
    Serial.println("Height: " + String(N));
    Serial.println("Width: " + String((int)(M/3)));
    array = allocateArray(N, M);

    if (array == NULL) {
        Serial.println("配列の確保に失敗");
        return;
    }

    // 配列を初期化
    for (int i = 0; i < N; i++) {
        for (int j = 0; j < M; j++) {
            array[i][j] = 0;
        }
    }
}

void loop() {
  // put your main code here, to run repeatedly:
    readAndProcess();

    if (buttonInputPressed) {
        array[n][m]   = RGBOutput[0];
        array[n][m+1] = RGBOutput[1];
        array[n][m+2] = RGBOutput[2];

        Serial.println(String(n)+" 行目 "+String((int)(m/3))+" 列目 の画素を読み込みました。");

        if((m+=3)>=M){
            m = 0 ;
            if((n+=1)>=N){
                n = 0;
                Serial.println("画像の読み取りが完了しました。");
                Serial.println("以下のテキストを画像ファイル（.ppm）に貼り付けてください。");
                Serial.println("--------------------------------------------------");
                Serial.println("P3");
                Serial.println(String(N)+" "+String((int)(M/3)));
                Serial.println("255");
                for (int i = 0; i < N; i++) {
                    for (int j = 0; j < M; j++) {
                        Serial.print((int)array[i][j]);
                        Serial.print(" ");
                    }
                    Serial.println();
                }
                Serial.println("--------------------------------------------------");
                Serial.println();
                delay(500); 
                // softwareReset();
                NVIC_SystemReset();
            } 
        }
        buttonInputPressed = false;
    }

    if (buttonMinMaxPressed) {
        if(pushed%2==0){
            r_min=rgb[0], g_min=rgb[1], b_min=rgb[2];
            Serial.println("最小値が更新されました："+String(b_min)+","+String(r_min)+","+String(g_min));
        }
        else{
            r_max=rgb[0]-r_min, g_max=rgb[1]-g_min, b_max=rgb[2]-b_min;
            Serial.println("最大値が更新されました："+String(b_max)+","+String(r_max)+","+String(g_max));
        }
        buttonMinMaxPressed = false;  // フラグをリセット
        pushed++;
        delay(500);
    }
}
\end{lstlisting}

\clearpage
\subsection{AI\_CSR\_Quantized.ino}
\label{sec:code_ai_csr_quantized}

\begin{lstlisting}[language=C++,caption=AI\_CSR\_Quantized.ino,label=code:ai_csr_quantized]
#include <Arduino.h>
#include "model_parameters40.h"
#include "model_parameters_csr_quantized40.h"

// ========== モデル設定 ==========
// 注意: この値は学習時に使用したHIDDEN_DIMと一致させること
#ifndef HIDDEN_DIM
#define HIDDEN_DIM 40  // 隠れ層の次元（学習時の値と一致させる）
#endif
// =================================

// RGB点灯遅延
#define RgbFlashDelay 50 

// ピン割り当て
#define PIN_IN A0
#define led_r_pin 8
#define led_g_pin 6
#define led_b_pin 7
#define buttonInputPin 3
#define buttonMinMaxPin 2

// ボタン押下を検知する変数 (余計な最適化を防ぐため、volatile宣言をしている)
volatile bool buttonInputPressed = false;
volatile bool buttonMinMaxPressed = false;

// RGB読み取り用変数
float r=0, g=0, b=0;
float r_max=512, g_max=512, b_max=512;
float r_min=0, g_min=0, b_min=0;

float rgb[3]{0, 0, 0};
float RGBInput[3]{0, 0, 0};
float RGBOutput[3]{0, 0, 0};

// RGBデータメモリ
int N, M;
float **array;
int n=0, m=0;

int pushed = 0;

void buttonInput() {
    buttonInputPressed = true;
}

void buttonMinMax() {
    buttonMinMaxPressed = true;
}

float **allocateArray(int N, int M) {
    float **array = (float **)malloc(N * sizeof(float *)); // 行ポインタの確保
    if (array == NULL) {
        Serial.println("メモリ確保失敗");
        return NULL;
    }

    for (int i = 0; i < N; i++) {
        array[i] = (float *)malloc(M * sizeof(float)); // 各行のメモリ確保
        if (array[i] == NULL) {
            Serial.println("メモリ確保失敗（部分的）");
            // 確保済みのメモリを解放して終了
            for (int j = 0; j < i; j++) {
                free(array[j]);
            }
            free(array);
            return NULL;
        }
    }
    return array;
}

void read(){
    for(int count = 0 ; count < 3 ; count++){
        if(count == 0){
            analogWrite(led_r_pin, 255);
            analogWrite(led_g_pin,   0);
            analogWrite(led_b_pin,   0);
            delay(RgbFlashDelay);
            rgb[0] = analogRead(PIN_IN);
        }else if(count == 1){
            analogWrite(led_r_pin,   0);
            analogWrite(led_g_pin, 255); 
            analogWrite(led_b_pin,   0);
            delay(RgbFlashDelay);
            rgb[1] = analogRead(PIN_IN);
        }else{
            analogWrite(led_r_pin,   0);
            analogWrite(led_g_pin,   0);
            analogWrite(led_b_pin, 255);
            delay(RgbFlashDelay);     
            rgb[2] = analogRead(PIN_IN);
        }
    }
    analogWrite(led_r_pin, 0);
    analogWrite(led_g_pin, 0);
    analogWrite(led_b_pin, 0);
}

static inline float relu(float x){ return x > 0 ? x : 0; }

// 量子化対応のCSR層（1層目、int8_tデータをfloatに逆量子化しながら計算）
void layer1_csr_quantized_relu(const float x[3], float h1[HIDDEN_DIM]){
	for(int r=0;r<HIDDEN_DIM;++r){
		float s = 0.0f;
		uint16_t start = indptr_1[r];
		uint16_t end   = indptr_1[r+1];
		for(uint16_t p=start;p<end;++p){
			uint16_t c = indices_1[p];
			// int8_tをfloatに逆量子化
			float weight_val = (float)data_1_quantized[p] / scale_factor_1;
			s += weight_val * x[c];
		}
		s += bias_1[r];
		h1[r] = relu(s);
	}
}

// 量子化対応のCSR層（2層目、int8_tデータをfloatに逆量子化しながら計算）
void layer2_csr_quantized_relu(const float h1[HIDDEN_DIM], float h2[HIDDEN_DIM]){
	for(int r=0;r<HIDDEN_DIM;++r){
		float s = 0.0f;
		uint16_t start = indptr_2[r];
		uint16_t end   = indptr_2[r+1];
		for(uint16_t p=start;p<end;++p){
			uint16_t c = indices_2[p];
			// int8_tをfloatに逆量子化
			float weight_val = (float)data_2_quantized[p] / scale_factor_2;
			s += weight_val * h1[c];
		}
		s += bias_2[r];
		h2[r] = relu(s);
	}
}

void layer3_dense(const float h2[HIDDEN_DIM], float y[3]){
	for(int m=0;m<3;++m){
		float s = bias_3[m];
		for(int k=0;k<HIDDEN_DIM;++k) s += weight_3[m*HIDDEN_DIM + k] * h2[k];
		y[m] = s;
	}
}

// predict
static void predict(const float in_rgb[3], float out_rgb[3]){
	float h1[HIDDEN_DIM], h2[HIDDEN_DIM];
	layer1_csr_quantized_relu(in_rgb, h1);
	layer2_csr_quantized_relu(h1, h2);
	layer3_dense(h2, out_rgb);
}

// Arduino's analog input detects 0-5V with 10-bit values
// https://deviceplus.jp/arduino/arduino_f07/
void readAndProcess(){
    read();
    RGBInput[0] = (float(rgb[0])-r_min)/r_max;
    RGBInput[1] = (float(rgb[1])-g_min)/g_max;
    RGBInput[2] = (float(rgb[2])-b_min)/b_max;
    
    // ニューラルネットで読み込み値を修正
    micros();
    predict(RGBInput, RGBOutput);
    micros();
    
    // 0-255でクリッピング
    RGBOutput[0] = min(max(RGBOutput[0]*255, 0), 255);
    RGBOutput[1] = min(max(RGBOutput[1]*255, 0), 255);
    RGBOutput[2] = min(max(RGBOutput[2]*255, 0), 255);

    Serial.println("Blue:"+String((int)RGBOutput[2]) + ", Red:"+String((int)RGBOutput[0]) + ", Green:"+ String((int)RGBOutput[1]));
}

void setup() {
  // put your setup code here, to run once:
    Serial.begin(9600);
    pinMode(led_r_pin, OUTPUT);
    pinMode(led_g_pin, OUTPUT);
    pinMode(led_b_pin, OUTPUT);
    analogWrite(led_r_pin, 0);
    analogWrite(led_b_pin, 0);
    analogWrite(led_g_pin, 0);

    pinMode(buttonInputPin, INPUT_PULLUP);pinMode(buttonMinMaxPin, INPUT_PULLUP);

    attachInterrupt(digitalPinToInterrupt(buttonInputPin), buttonInput, FALLING);
    attachInterrupt(digitalPinToInterrupt(buttonMinMaxPin), buttonMinMax, FALLING);

    Serial.println("画像の Height（行数）を入力してください: ");
    while (Serial.available() == 0) {
        // 何もせずに待機
    }
    N = Serial.parseInt();
    M = N*3; // RGBの値を入れるために3倍しておく
    Serial.println("Height: " + String(N));
    Serial.println("Width: " + String((int)(M/3)));
    array = allocateArray(N, M);

    if (array == NULL) {
        Serial.println("配列の確保に失敗");
        return;
    }

    // 配列を初期化
    for (int i = 0; i < N; i++) {
        for (int j = 0; j < M; j++) {
            array[i][j] = 0;
        }
    }
}

void loop() {
  // put your main code here, to run repeatedly:
    readAndProcess();

    if (buttonInputPressed) {
        array[n][m]   = RGBOutput[0];
        array[n][m+1] = RGBOutput[1];
        array[n][m+2] = RGBOutput[2];

        Serial.println(String(n)+" 行目 "+String((int)(m/3))+" 列目 の画素を読み込みました。");

        if((m+=3)>=M){
            m = 0 ;
            if((n+=1)>=N){
                n = 0;
                Serial.println("画像の読み取りが完了しました。");
                Serial.println("以下のテキストを画像ファイル（.ppm）に貼り付けてください。");
                Serial.println("--------------------------------------------------");
                Serial.println("P3");
                Serial.println(String(N)+" "+String((int)(M/3)));
                Serial.println("255");
                for (int i = 0; i < N; i++) {
                    for (int j = 0; j < M; j++) {
                        Serial.print((int)array[i][j]);
                        Serial.print(" ");
                    }
                    Serial.println();
                }
                Serial.println("--------------------------------------------------");
                Serial.println();
                delay(500); 
                NVIC_SystemReset();
            } 
        }
        buttonInputPressed = false;
    }

    if (buttonMinMaxPressed) {
        if(pushed%2==0){
            r_min=rgb[0], g_min=rgb[1], b_min=rgb[2];
            Serial.println("最小値が更新されました："+String(b_min)+","+String(r_min)+","+String(g_min));
        }
        else{
            r_max=rgb[0]-r_min, g_max=rgb[1]-g_min, b_max=rgb[2]-b_min;
            Serial.println("最大値が更新されました："+String(b_max)+","+String(r_max)+","+String(g_max));
        }
        buttonMinMaxPressed = false;  // フラグをリセット
        pushed++;
        delay(500);
    }
}
\end{lstlisting}

\clearpage
\subsection{train\_L1\_normalization.ipynb}
\label{sec:code_train}

ノートブックファイルの主要なPythonコードセルを示す．

\begin{lstlisting}[language=Python,caption=train\_L1\_normalization.ipynb,label=code:train]
import cv2
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

# 推論データ
X = np.array([[...]], dtype=np.float32)

# 正解データ
Y = np.array([[...]], dtype=np.float32)

X_tensor = torch.tensor(X, dtype=torch.float32)
Y_tensor = torch.tensor(Y, dtype=torch.float32)

# ========== モデル設定（次元を変更する場合はここを編集） ==========
HIDDEN_DIM = 40  # 隠れ層の次元（40, 100, 200などに変更可能）
# ================================================================

# モデル定義
class ColorNet(nn.Module):
    def __init__(self, hidden_dim=40):
        super(ColorNet, self).__init__()
        self.hidden_dim = hidden_dim
        self.model = nn.Sequential(
            nn.Linear(3, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, 3),
        )

    def forward(self, x):
        return self.model(x)

model = ColorNet(hidden_dim=HIDDEN_DIM)
print(f"モデル定義完了: 隠れ層次元 = {HIDDEN_DIM}")

# 損失関数（MSE）
criterion = nn.MSELoss()

# 最適化手法
optimizer = optim.Adam(model.parameters(), lr=0.01)

# L1正則化の係数
lambda_l1 = 1e-6

# 学習ループ
epochs = 50000
for epoch in range(epochs):
    optimizer.zero_grad()

    outputs = model(X_tensor)
    mse = criterion(outputs, Y_tensor)

    # --- L1 正則化-----------------------------
    l1 = torch.tensor(0.0, requires_grad=False)
    for name, p in model.named_parameters():
        if 'weight' in name:
            l1 = l1 + p.abs().sum()
    loss = mse + lambda_l1 * l1
    # -----------------------------------------

    loss.backward()
    optimizer.step()

    if epoch % 500 == 0:
        print(f'Epoch [{epoch}/{epochs}]  MSE: {mse.item():.6f}  L1: {l1.item():.2f}  Loss: {loss.item():.6f}')

with torch.no_grad():
    predictions = model(X_tensor)
    print("\n予測結果：")
    print(predictions.numpy())

def convert_to_cpp_array(tensor: torch.Tensor, name: str, dtype: str = "float"):
    flat = tensor.detach().numpy().flatten()
    array_str = f"{dtype} {name}[] = {{"
    array_str += ", ".join(map(str, flat))
    array_str += "};"
    return array_str

cpp_code = f"// モデルパラメータ (隠れ層次元: {HIDDEN_DIM})\n"

layer_idx = 1
for layer in model.model:
    if isinstance(layer, torch.nn.Linear):
        cpp_code += convert_to_cpp_array(layer.weight, f"weight_{layer_idx}") + "\n"
        cpp_code += convert_to_cpp_array(layer.bias,   f"bias_{layer_idx}") + "\n"
        layer_idx += 1

with open("model_parameters.h", "w") as f:
    f.write(cpp_code)

print(f"\nC++ 用のパラメータファイル (model_parameters.h) を作成しました。")
print(f"隠れ層次元: {HIDDEN_DIM}")
\end{lstlisting}


\end{document}